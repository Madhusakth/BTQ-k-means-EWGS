dataset: cifar10	arch: resnet20_quant	num_workers: 4	seed: None	batch_size: 32	epochs: 500	optimizer_m: Adam	optimizer_q: Adam	lr_m: 0.001	lr_q: 1e-05	lr_m_end: 0.0	lr_q_end: 0.0	decay_schedule_m: 150-300	decay_schedule_q: 150-300	momentum: 0.9	weight_decay: 0.0001	lr_scheduler_m: cosine	lr_scheduler_q: cosine	gamma: 0.1	QWeightFlag: True	QActFlag: False	weight_levels: 256	act_levels: 2	baseline: False	bkwd_scaling_factorW: 0.0	bkwd_scaling_factorA: 0.0	use_hessian: True	update_every: 10	gpu_id: 1	log_dir: ../results/CIFAR10_ResNet50/W8A32_kmeans_weighted_comp_decomp/	load_pretrain: True	pretrain_path: ../results/CIFAR10_ResNet50/W8A32_kmeans_weighted_comp_decomp/checkpoint/last_checkpoint.pth	btq: True	training_flag: False	eval: False	weighted: True	
Files already downloaded and verified
The number of parameters :  269904
Pretrained full precision weights are initialized
# total params: 269904
# model params: 269850
# quantizer params: 54
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): QBasicBlock(
      (conv1): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): QBasicBlock(
      (conv1): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 000 	 Test accuracy: 72.96000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 001 	 Test accuracy: 64.42999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 002 	 Test accuracy: 70.12 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 003 	 Test accuracy: 52.839999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 004 	 Test accuracy: 67.24 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 005 	 Test accuracy: 53.839999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 006 	 Test accuracy: 62.529999999999994 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 007 	 Test accuracy: 68.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 008 	 Test accuracy: 64.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 009 	 Test accuracy: 68.47 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:10<00:20, 10.24s/it] 67%|██████▋   | 2/3 [00:24<00:12, 12.32s/it]100%|██████████| 3/3 [00:44<00:00, 15.90s/it]100%|██████████| 3/3 [00:44<00:00, 14.74s/it]
scaleW
 [0.0848456453431119, 0.0846634243232347, 0.10712478422934839, 0.06226813299436459, 0.08998656108995136, 0.05632395643937812, 0.0557791236037684, 0.035562527213633406, 0.030926370677944157, 0.02072697517576833, 0.040008404136372154, 0.013297953306335847, 0.01992302653138157, 0.01182190195201868, 0.018932102389163683, 0.015058425120559682, 0.019168489791738772, 0.010759898884750893]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 010 	 Test accuracy: 62.849999999999994 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 011 	 Test accuracy: 57.120000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 012 	 Test accuracy: 76.62 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 013 	 Test accuracy: 69.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 014 	 Test accuracy: 70.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 015 	 Test accuracy: 72.21 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 016 	 Test accuracy: 29.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 017 	 Test accuracy: 68.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 018 	 Test accuracy: 74.3 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 019 	 Test accuracy: 67.30000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:11<00:23, 11.53s/it] 67%|██████▋   | 2/3 [00:25<00:12, 12.95s/it]100%|██████████| 3/3 [00:37<00:00, 12.44s/it]100%|██████████| 3/3 [00:37<00:00, 12.45s/it]
scaleW
 [0.09595168602456589, 0.08423677172184403, 0.10716180838650513, 0.062022632100086524, 0.06290719050926556, 0.030053097533111806, 0.05175428174106598, 0.03279617595334273, 0.033509690092145945, 0.020110310662745646, 0.02522552582175792, 0.012470145689649097, 0.023643672157515252, 0.014608224279386996, 0.017125407916609048, 0.01395366093218785, 0.01632429156469757, 0.010793975696882452]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 020 	 Test accuracy: 66.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 021 	 Test accuracy: 73.24000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 022 	 Test accuracy: 70.55 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 023 	 Test accuracy: 75.07000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 024 	 Test accuracy: 67.19000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 025 	 Test accuracy: 55.279999999999994 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 026 	 Test accuracy: 68.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 027 	 Test accuracy: 66.34 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 028 	 Test accuracy: 72.3 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 029 	 Test accuracy: 59.709999999999994 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:12<00:24, 12.28s/it] 67%|██████▋   | 2/3 [00:28<00:14, 14.73s/it]100%|██████████| 3/3 [00:40<00:00, 13.59s/it]100%|██████████| 3/3 [00:40<00:00, 13.67s/it]
scaleW
 [0.08894990919930552, 0.08402047569243916, 0.11475646644091102, 0.07087502537476813, 0.07032083448579314, 0.03137575939230965, 0.051723389795372755, 0.036503702565484325, 0.04249584811070505, 0.027058084710142826, 0.0344409937721682, 0.015861243545448007, 0.020081992897640816, 0.016612741843564875, 0.0180440098149327, 0.0148976323289419, 0.017423766059832452, 0.007262859656326642]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 030 	 Test accuracy: 65.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 031 	 Test accuracy: 65.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 032 	 Test accuracy: 69.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 033 	 Test accuracy: 77.27000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 034 	 Test accuracy: 49.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 035 	 Test accuracy: 58.15 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 036 	 Test accuracy: 62.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 037 	 Test accuracy: 75.22999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 038 	 Test accuracy: 68.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 039 	 Test accuracy: 54.35 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:31, 15.71s/it] 67%|██████▋   | 2/3 [00:29<00:14, 14.75s/it]100%|██████████| 3/3 [00:45<00:00, 15.26s/it]100%|██████████| 3/3 [00:45<00:00, 15.24s/it]
scaleW
 [0.09174483424131015, 0.07381208810596586, 0.08740749562556678, 0.04571847544709071, 0.05198857053208119, 0.027028985550436025, 0.04524688100227056, 0.030324519278258844, 0.026435614522177492, 0.016213722125550837, 0.024449666830398665, 0.011281882108923266, 0.0199812043904326, 0.018292470384761006, 0.00777077268765465, 0.007834358777818943, 0.0067264831832256275, 0.0]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 040 	 Test accuracy: 68.55 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 041 	 Test accuracy: 73.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 042 	 Test accuracy: 69.57 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 043 	 Test accuracy: 71.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 044 	 Test accuracy: 80.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 045 	 Test accuracy: 62.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 046 	 Test accuracy: 77.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 047 	 Test accuracy: 56.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 048 	 Test accuracy: 71.16 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 049 	 Test accuracy: 71.05 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:14<00:28, 14.44s/it] 67%|██████▋   | 2/3 [00:23<00:11, 11.27s/it]100%|██████████| 3/3 [00:37<00:00, 12.53s/it]100%|██████████| 3/3 [00:37<00:00, 12.52s/it]
scaleW
 [0.10376875288525361, 0.0961413992140384, 0.0960339342628051, 0.08139609364400592, 0.08197473517878277, 0.04588107630697071, 0.0674201323874654, 0.03783309980937623, 0.04912516782324727, 0.041385359967308834, 0.042467717579442725, 0.026147350562802135, 0.022902993665014193, 0.017548724388870184, 0.017529097924803803, 0.015384510194194697, 0.018213109619077465, 0.007303265072967494]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 050 	 Test accuracy: 78.82000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 051 	 Test accuracy: 68.91000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 052 	 Test accuracy: 74.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 053 	 Test accuracy: 73.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 054 	 Test accuracy: 65.67 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 055 	 Test accuracy: 69.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 056 	 Test accuracy: 71.54 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 057 	 Test accuracy: 72.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 058 	 Test accuracy: 62.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 059 	 Test accuracy: 79.86999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:11<00:22, 11.00s/it] 67%|██████▋   | 2/3 [00:25<00:13, 13.08s/it]100%|██████████| 3/3 [00:37<00:00, 12.40s/it]100%|██████████| 3/3 [00:37<00:00, 12.39s/it]
scaleW
 [0.0960088719569917, 0.0913338820200232, 0.10533316047618257, 0.06607791598143918, 0.10985915264097808, 0.07227455866000525, 0.04462415326997617, 0.029311219717213382, 0.02126808535942364, 0.012278290429687573, 0.04009708847321434, 0.021144108879586797, 0.022310576288876827, 0.02153687183653701, 0.011640268571391997, 0.01147548770433929, 0.01438720510967601, 0.010377391815259335]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 060 	 Test accuracy: 59.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 061 	 Test accuracy: 71.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 062 	 Test accuracy: 74.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 063 	 Test accuracy: 69.15 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 064 	 Test accuracy: 76.34 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 065 	 Test accuracy: 63.959999999999994 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 066 	 Test accuracy: 72.11999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 067 	 Test accuracy: 76.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 068 	 Test accuracy: 76.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 069 	 Test accuracy: 72.23 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:31, 15.76s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.91s/it]100%|██████████| 3/3 [00:48<00:00, 15.99s/it]100%|██████████| 3/3 [00:48<00:00, 16.31s/it]
scaleW
 [0.12324235513914818, 0.10717009553611852, 0.12797468407006177, 0.07977348988710468, 0.12586000311970594, 0.08240249973731834, 0.05488056998064183, 0.04277282308449063, 0.03731393729140974, 0.021432115002541205, 0.030839340154306328, 0.012691131383887881, 0.022014282966816488, 0.01139445500170635, 0.016917866855523263, 0.012479976577960872, 0.015348201583874671, 0.00993287776291508]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 070 	 Test accuracy: 79.96 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 071 	 Test accuracy: 75.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 072 	 Test accuracy: 78.8 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 073 	 Test accuracy: 76.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 074 	 Test accuracy: 80.87 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 075 	 Test accuracy: 73.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 076 	 Test accuracy: 79.34 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 077 	 Test accuracy: 66.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 078 	 Test accuracy: 79.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 079 	 Test accuracy: 79.12 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:30, 15.06s/it] 67%|██████▋   | 2/3 [00:30<00:15, 15.25s/it]100%|██████████| 3/3 [00:40<00:00, 12.79s/it]100%|██████████| 3/3 [00:40<00:00, 13.45s/it]
scaleW
 [0.11893945924413651, 0.10870652831668666, 0.12116106396316677, 0.08974869432541333, 0.06458140282081734, 0.04620907783400143, 0.07058086119881925, 0.05080191451764068, 0.0432899139721539, 0.028122317091454577, 0.045837543085619714, 0.034668573259039444, 0.029704058261224003, 0.021827438883477615, 0.016627829212592756, 0.011546331537286536, 0.010041786565237852, 0.005708188417743541]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 080 	 Test accuracy: 75.32 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 081 	 Test accuracy: 73.94 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 082 	 Test accuracy: 76.64999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 083 	 Test accuracy: 72.78999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 084 	 Test accuracy: 75.71 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 085 	 Test accuracy: 60.309999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 086 	 Test accuracy: 74.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 087 	 Test accuracy: 81.32000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 088 	 Test accuracy: 66.49000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 089 	 Test accuracy: 76.42 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:31, 15.78s/it] 67%|██████▋   | 2/3 [00:27<00:13, 13.58s/it]100%|██████████| 3/3 [00:42<00:00, 14.26s/it]100%|██████████| 3/3 [00:42<00:00, 14.31s/it]
scaleW
 [0.1066978704664666, 0.08470222213252038, 0.09513603929468105, 0.06286768940087725, 0.0718075453203798, 0.06043629187603546, 0.050253735504797135, 0.03476515221436193, 0.026622384818501942, 0.015278538942882468, 0.03597126618650734, 0.02169162718453564, 0.026973466528218675, 0.018978311871897736, 0.019114220678004338, 0.01618438423474868, 0.015781931214738223, 0.006229173873156219]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 090 	 Test accuracy: 76.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 091 	 Test accuracy: 77.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 092 	 Test accuracy: 74.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 093 	 Test accuracy: 80.33 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 094 	 Test accuracy: 78.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 095 	 Test accuracy: 79.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 096 	 Test accuracy: 79.39 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 097 	 Test accuracy: 81.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 098 	 Test accuracy: 71.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 099 	 Test accuracy: 76.44999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:10<00:21, 10.66s/it] 67%|██████▋   | 2/3 [00:27<00:14, 14.41s/it]100%|██████████| 3/3 [00:42<00:00, 14.57s/it]100%|██████████| 3/3 [00:42<00:00, 14.16s/it]
scaleW
 [0.09967584873510589, 0.1087382144036943, 0.143169443997038, 0.08414570681393341, 0.11597758380419687, 0.05577295471461464, 0.06674684729129453, 0.06341751100100196, 0.04654337012649954, 0.03351113624549971, 0.0494012337911238, 0.018408030485368567, 0.025723654363545474, 0.026546819090881132, 0.023153811602497992, 0.012321051417533098, 0.019058337126372324, 0.011886023898551973]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 100 	 Test accuracy: 79.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 101 	 Test accuracy: 78.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 102 	 Test accuracy: 79.82000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 103 	 Test accuracy: 78.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 104 	 Test accuracy: 79.32000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 105 	 Test accuracy: 70.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 106 	 Test accuracy: 79.33 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 107 	 Test accuracy: 75.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 108 	 Test accuracy: 65.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 109 	 Test accuracy: 78.57 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:12<00:24, 12.29s/it] 67%|██████▋   | 2/3 [00:24<00:12, 12.36s/it]100%|██████████| 3/3 [00:39<00:00, 13.34s/it]100%|██████████| 3/3 [00:39<00:00, 13.09s/it]
scaleW
 [0.09904395320806207, 0.08231347230960918, 0.11816417817332249, 0.07967654208934628, 0.08688843888772678, 0.04777044947558878, 0.04440055278862647, 0.032754075156096574, 0.040210673358402144, 0.01999473599996805, 0.046156076822942156, 0.01753147905034812, 0.02404874132567519, 0.0218168312280842, 0.018373376819805946, 0.01501235227809562, 0.015323544122029817, 0.012641240154533398]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 110 	 Test accuracy: 78.94 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 111 	 Test accuracy: 74.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 112 	 Test accuracy: 68.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 113 	 Test accuracy: 80.32000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 114 	 Test accuracy: 81.45 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 115 	 Test accuracy: 72.33000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 116 	 Test accuracy: 76.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 117 	 Test accuracy: 79.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 118 	 Test accuracy: 77.92999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 119 	 Test accuracy: 79.63 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:39, 19.94s/it] 67%|██████▋   | 2/3 [00:31<00:14, 14.74s/it]100%|██████████| 3/3 [00:42<00:00, 13.42s/it]100%|██████████| 3/3 [00:42<00:00, 14.31s/it]
scaleW
 [0.09223390309160968, 0.06345928670728629, 0.08590868637127035, 0.06253376763250153, 0.06779499624513174, 0.042634892043661304, 0.05302303101670916, 0.04389650572646836, 0.027013189262961295, 0.012011288960461816, 0.04213281794750517, 0.021632530667852992, 0.01681527080835826, 0.013710394163400806, 0.014117064694879637, 0.010851266800974346, 0.010553165462590046, 0.005200676466755101]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 120 	 Test accuracy: 76.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 121 	 Test accuracy: 73.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 122 	 Test accuracy: 81.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 123 	 Test accuracy: 72.13000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 124 	 Test accuracy: 83.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 125 	 Test accuracy: 76.29 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 126 	 Test accuracy: 63.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 127 	 Test accuracy: 79.9 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 128 	 Test accuracy: 72.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 129 	 Test accuracy: 75.1 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:14<00:28, 14.19s/it] 67%|██████▋   | 2/3 [00:28<00:14, 14.13s/it]100%|██████████| 3/3 [00:45<00:00, 15.31s/it]100%|██████████| 3/3 [00:45<00:00, 15.01s/it]
scaleW
 [0.08226383991614626, 0.06574178138826904, 0.0823621153567804, 0.051559710964802365, 0.10904560526347189, 0.06178280234591451, 0.05636019655406799, 0.04404581516630049, 0.027668063078671132, 0.015691455563374094, 0.04787352187069315, 0.02156489277324818, 0.02374029539842851, 0.019617518713127696, 0.021835045106535028, 0.014230315085592624, 0.020173015860098845, 0.010332266947419918]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 191
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 130 	 Test accuracy: 78.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 131 	 Test accuracy: 74.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 132 	 Test accuracy: 77.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 133 	 Test accuracy: 79.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 134 	 Test accuracy: 78.24 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 135 	 Test accuracy: 77.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 136 	 Test accuracy: 77.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 137 	 Test accuracy: 75.38 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 138 	 Test accuracy: 77.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 139 	 Test accuracy: 75.67 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:12<00:24, 12.14s/it] 67%|██████▋   | 2/3 [00:28<00:14, 14.76s/it]100%|██████████| 3/3 [00:42<00:00, 14.18s/it]100%|██████████| 3/3 [00:42<00:00, 14.10s/it]
scaleW
 [0.13931882584271968, 0.11769377741947314, 0.14077580600154838, 0.08596126344029054, 0.10241810772364324, 0.05760907872056579, 0.07146505179570688, 0.059164658428517536, 0.05577252750592256, 0.03808189013261092, 0.042600495040120034, 0.026037661806928476, 0.03337261239844059, 0.02534165332581295, 0.021756370335064168, 0.019646978976526466, 0.023430263454365118, 0.01201728341037501]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 140 	 Test accuracy: 81.52000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 141 	 Test accuracy: 78.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 142 	 Test accuracy: 79.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 143 	 Test accuracy: 71.02000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 144 	 Test accuracy: 80.78999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 145 	 Test accuracy: 80.01 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 146 	 Test accuracy: 80.34 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 147 	 Test accuracy: 79.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 148 	 Test accuracy: 80.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 149 	 Test accuracy: 79.35 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:31, 15.92s/it] 67%|██████▋   | 2/3 [00:36<00:18, 18.52s/it]100%|██████████| 3/3 [00:51<00:00, 17.18s/it]100%|██████████| 3/3 [00:51<00:00, 17.30s/it]
scaleW
 [0.07172878765042492, 0.07906620152969418, 0.0894393227164882, 0.06422348254617767, 0.08142106500950895, 0.05217771278268831, 0.049925039369747494, 0.038646950470216934, 0.03661606792472825, 0.026737287937558585, 0.03006279442460523, 0.013511946275044137, 0.019019959094710367, 0.010577731055569946, 0.012836316788015598, 0.009857199206755096, 0.008808960147840949, 0.005477768917793246]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 150 	 Test accuracy: 84.15 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 151 	 Test accuracy: 80.16 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 152 	 Test accuracy: 80.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 153 	 Test accuracy: 83.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 154 	 Test accuracy: 75.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 155 	 Test accuracy: 74.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 156 	 Test accuracy: 75.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 157 	 Test accuracy: 81.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 158 	 Test accuracy: 83.85000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 159 	 Test accuracy: 78.11 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:12<00:25, 12.94s/it] 67%|██████▋   | 2/3 [00:28<00:14, 14.30s/it]100%|██████████| 3/3 [00:38<00:00, 12.38s/it]100%|██████████| 3/3 [00:38<00:00, 12.78s/it]
scaleW
 [0.042610607298276405, 0.04169604345644224, 0.09407462454390103, 0.06036190386358662, 0.06241374557293711, 0.04156647719810303, 0.035117017709033894, 0.03500715437713236, 0.03259142778403636, 0.02658891862391613, 0.029866644093145604, 0.017125676003112753, 0.018185962125355545, 0.01646034482713123, 0.015684683326478377, 0.015209036347493767, 0.01813279627781059, 0.008237406433342575]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 160 	 Test accuracy: 81.84 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 161 	 Test accuracy: 82.35 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 162 	 Test accuracy: 71.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 163 	 Test accuracy: 84.8 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 164 	 Test accuracy: 81.52000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 165 	 Test accuracy: 74.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 166 	 Test accuracy: 76.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 167 	 Test accuracy: 78.36999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 168 	 Test accuracy: 82.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 169 	 Test accuracy: 83.08 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:10<00:21, 11.00s/it] 67%|██████▋   | 2/3 [00:25<00:13, 13.18s/it]100%|██████████| 3/3 [00:45<00:00, 16.21s/it]100%|██████████| 3/3 [00:45<00:00, 15.19s/it]
scaleW
 [0.13809990056092455, 0.11880129341173222, 0.1353735764621915, 0.0796793186237807, 0.1234302608864487, 0.08592226437530505, 0.06888482003863465, 0.0545410110359984, 0.04559475188891676, 0.029119442569111153, 0.047856059604336976, 0.02773210878863519, 0.03118367869711745, 0.025128818127319052, 0.021215928931478053, 0.013855124770290115, 0.016447757430325092, 0.0069003029871254305]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 170 	 Test accuracy: 82.32000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 171 	 Test accuracy: 72.89999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 172 	 Test accuracy: 83.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 173 	 Test accuracy: 77.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 174 	 Test accuracy: 81.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 175 	 Test accuracy: 81.89999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 176 	 Test accuracy: 75.99000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 177 	 Test accuracy: 81.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 178 	 Test accuracy: 77.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 179 	 Test accuracy: 80.73 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:14<00:28, 14.22s/it] 67%|██████▋   | 2/3 [00:33<00:17, 17.08s/it]100%|██████████| 3/3 [00:51<00:00, 17.59s/it]100%|██████████| 3/3 [00:51<00:00, 17.19s/it]
scaleW
 [0.06514589533510136, 0.06653275650305436, 0.08119829608098866, 0.04775992827320186, 0.07335418825657729, 0.054260978654013574, 0.0516515524214477, 0.028252275191450116, 0.03020020325259612, 0.024736884810001806, 0.026873824279418323, 0.007802377783215492, 0.02727778279002876, 0.018185821007545257, 0.00409143909513529, 0.003217716428130003, 0.011681948449110512, 0.0070390629585936225]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 180 	 Test accuracy: 81.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 181 	 Test accuracy: 82.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 182 	 Test accuracy: 81.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 183 	 Test accuracy: 83.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 184 	 Test accuracy: 77.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 185 	 Test accuracy: 83.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 186 	 Test accuracy: 80.85 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 187 	 Test accuracy: 81.99 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 188 	 Test accuracy: 82.50999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 189 	 Test accuracy: 78.7 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:36, 18.22s/it] 67%|██████▋   | 2/3 [00:34<00:16, 16.89s/it]100%|██████████| 3/3 [00:48<00:00, 15.61s/it]100%|██████████| 3/3 [00:48<00:00, 16.11s/it]
scaleW
 [0.08098427764481106, 0.09529913080678913, 0.131966631372627, 0.08365666082682884, 0.08742350940984704, 0.03168614027557963, 0.058041310976263395, 0.044344271796304256, 0.04350375354746144, 0.0252169465679852, 0.04169043775961422, 0.01759365575564335, 0.027359931927158188, 0.021943092969847183, 0.018585204750629, 0.012908320633516731, 0.01583931493255167, 0.009074297554996922]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 190 	 Test accuracy: 83.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 191 	 Test accuracy: 81.69 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 192 	 Test accuracy: 80.21000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 193 	 Test accuracy: 81.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 194 	 Test accuracy: 82.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 195 	 Test accuracy: 77.25999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 196 	 Test accuracy: 83.93 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 197 	 Test accuracy: 80.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 198 	 Test accuracy: 80.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 199 	 Test accuracy: 80.4 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:35, 17.92s/it] 67%|██████▋   | 2/3 [00:34<00:17, 17.24s/it]100%|██████████| 3/3 [00:48<00:00, 15.81s/it]100%|██████████| 3/3 [00:48<00:00, 16.28s/it]
scaleW
 [0.10214030849768785, 0.0929474194332464, 0.11812669569075814, 0.08225998081447715, 0.08924402613148787, 0.051590774742657275, 0.07628372073807954, 0.05058743748538219, 0.05131331246909515, 0.03285365478465333, 0.04750843281285134, 0.02816660913931686, 0.02891541109673092, 0.0163506495423321, 0.017250695761820242, 0.013527766139352797, 0.023070462229863947, 0.011486792291321912]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 200 	 Test accuracy: 80.84 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 201 	 Test accuracy: 83.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 202 	 Test accuracy: 78.10000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 203 	 Test accuracy: 79.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 204 	 Test accuracy: 80.01 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 205 	 Test accuracy: 76.57000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 206 	 Test accuracy: 82.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 207 	 Test accuracy: 83.04 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 208 	 Test accuracy: 81.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 209 	 Test accuracy: 83.61 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:11<00:22, 11.45s/it] 67%|██████▋   | 2/3 [00:29<00:15, 15.14s/it]100%|██████████| 3/3 [00:46<00:00, 16.31s/it]100%|██████████| 3/3 [00:46<00:00, 15.64s/it]
scaleW
 [0.1126165299271719, 0.08816465055565958, 0.08639161218165016, 0.06071591259543418, 0.09666368898177034, 0.059209556385006155, 0.060664607259992565, 0.0428002184455879, 0.02854297011877953, 0.024653904340694838, 0.03298831205169992, 0.01639750786439943, 0.02492274414105231, 0.017684871190260243, 0.017734420488242704, 0.01644547159623477, 0.014669186657486991, 0.0057562904487776165]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 210 	 Test accuracy: 79.35 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 211 	 Test accuracy: 83.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 212 	 Test accuracy: 80.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 213 	 Test accuracy: 77.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 214 	 Test accuracy: 85.45 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 215 	 Test accuracy: 80.87 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 216 	 Test accuracy: 85.39999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 217 	 Test accuracy: 85.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 218 	 Test accuracy: 74.66000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 219 	 Test accuracy: 79.92 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:39, 19.78s/it] 67%|██████▋   | 2/3 [00:33<00:15, 15.93s/it]100%|██████████| 3/3 [00:50<00:00, 16.69s/it]100%|██████████| 3/3 [00:50<00:00, 16.88s/it]
scaleW
 [0.07035718162648087, 0.045549849887736776, 0.06865033109826107, 0.071733691879483, 0.06153624441885756, 0.030385572385447507, 0.03764241978138242, 0.02530518973420307, 0.026800200486624435, 0.014810429104319548, 0.024337614855816564, 0.01733758649051732, 0.015921998406376054, 0.008557699299521833, 0.007042819317399002, 0.00778806738369751, 0.008126934513165237, 0.003171792834934607]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 220 	 Test accuracy: 84.28999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 221 	 Test accuracy: 83.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 222 	 Test accuracy: 79.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 223 	 Test accuracy: 80.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 224 	 Test accuracy: 82.07 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 225 	 Test accuracy: 79.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 226 	 Test accuracy: 79.4 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 227 	 Test accuracy: 84.89999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 228 	 Test accuracy: 84.57000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 229 	 Test accuracy: 82.57 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:10<00:20, 10.44s/it] 67%|██████▋   | 2/3 [00:24<00:12, 12.71s/it]100%|██████████| 3/3 [00:38<00:00, 13.31s/it]100%|██████████| 3/3 [00:38<00:00, 12.94s/it]
scaleW
 [0.09121595139337746, 0.08843378516313273, 0.10441129763478092, 0.08270298693065668, 0.07950606626874014, 0.03810014464448687, 0.04452653660912969, 0.04040869025012706, 0.03005665394275279, 0.0216444103739595, 0.032264423149189626, 0.01446813960123134, 0.023690699602020453, 0.017837217825979714, 0.023503973758290973, 0.015456925233149378, 0.009116966543058519, 0.0049495731754723845]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 230 	 Test accuracy: 81.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 231 	 Test accuracy: 81.52000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 232 	 Test accuracy: 78.55 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 233 	 Test accuracy: 85.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 234 	 Test accuracy: 80.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 235 	 Test accuracy: 82.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 236 	 Test accuracy: 81.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 237 	 Test accuracy: 83.89999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 238 	 Test accuracy: 84.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 239 	 Test accuracy: 82.55 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:35, 17.54s/it] 67%|██████▋   | 2/3 [00:34<00:17, 17.16s/it]100%|██████████| 3/3 [00:51<00:00, 17.27s/it]100%|██████████| 3/3 [00:51<00:00, 17.29s/it]
scaleW
 [0.07440591941554063, 0.1014098820884961, 0.13539144031009612, 0.07738103259447869, 0.12413091682646464, 0.057870471826574434, 0.06938251703424926, 0.046929042514717134, 0.04713315014596744, 0.03697021904275002, 0.04892189595461604, 0.03650974958221925, 0.031547543408440466, 0.028207082303666604, 0.013831779619893085, 0.017607900316289962, 0.019684752671587064, 0.01124717109130289]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 240 	 Test accuracy: 81.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 241 	 Test accuracy: 81.57 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 242 	 Test accuracy: 79.57 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 243 	 Test accuracy: 74.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 244 	 Test accuracy: 83.39999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 245 	 Test accuracy: 87.07000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 246 	 Test accuracy: 83.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 247 	 Test accuracy: 85.46000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 248 	 Test accuracy: 80.60000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 249 	 Test accuracy: 78.94 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:31, 15.51s/it] 67%|██████▋   | 2/3 [00:30<00:15, 15.09s/it]100%|██████████| 3/3 [00:47<00:00, 15.97s/it]100%|██████████| 3/3 [00:47<00:00, 15.79s/it]
scaleW
 [0.1227511013490279, 0.08881410947061937, 0.09553039573778223, 0.07377660714090442, 0.11464111746691441, 0.047971445357757804, 0.06577551409219941, 0.041795874273079126, 0.035225747098122207, 0.013942550180547299, 0.025000457261209003, 0.011420880624372763, 0.019061077564467732, 0.014349527323189325, 0.013174945741096775, 0.009485260221316362, 0.016485127951065895, 0.010594803125220284]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 250 	 Test accuracy: 81.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 251 	 Test accuracy: 86.1 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 252 	 Test accuracy: 85.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 253 	 Test accuracy: 85.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 254 	 Test accuracy: 84.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 255 	 Test accuracy: 84.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 256 	 Test accuracy: 84.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 257 	 Test accuracy: 84.8 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 258 	 Test accuracy: 83.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 259 	 Test accuracy: 85.1 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:35, 17.52s/it] 67%|██████▋   | 2/3 [00:32<00:16, 16.04s/it]100%|██████████| 3/3 [00:51<00:00, 17.37s/it]100%|██████████| 3/3 [00:51<00:00, 17.18s/it]
scaleW
 [0.0568391918920787, 0.05158897374717244, 0.05836116376820133, 0.06586535070867836, 0.10153013133464461, 0.03152235687749599, 0.037410399794338106, 0.027863711734185937, 0.01574390235259771, 0.007398354482449014, 0.018176283592107313, 0.006896398049862623, 0.024308426024308546, 0.02398052960274776, 0.007585912265015297, 0.008168630078673302, 0.014852060611977283, 0.006970541243767207]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 260 	 Test accuracy: 85.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 261 	 Test accuracy: 81.38 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 262 	 Test accuracy: 84.77 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 263 	 Test accuracy: 82.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 264 	 Test accuracy: 82.39 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 265 	 Test accuracy: 85.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 266 	 Test accuracy: 83.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 267 	 Test accuracy: 84.34 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 268 	 Test accuracy: 87.92999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 269 	 Test accuracy: 86.92 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:34, 17.47s/it] 67%|██████▋   | 2/3 [00:31<00:15, 15.20s/it]100%|██████████| 3/3 [00:46<00:00, 15.37s/it]100%|██████████| 3/3 [00:46<00:00, 15.57s/it]
scaleW
 [0.08550512288979957, 0.09235035916313306, 0.12979299298789557, 0.06329400439095673, 0.07024422757211131, 0.04262823794413831, 0.05179201261481567, 0.041068767315024235, 0.035211570291652165, 0.02574401886658902, 0.037882128240936876, 0.022618589098962808, 0.02657952012961982, 0.018687465105456966, 0.018477503370285583, 0.017388332053239846, 0.019349700751491714, 0.011393019999116238]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 270 	 Test accuracy: 85.92999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 271 	 Test accuracy: 82.84 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 272 	 Test accuracy: 80.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 273 	 Test accuracy: 85.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 274 	 Test accuracy: 88.29 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 275 	 Test accuracy: 86.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 276 	 Test accuracy: 84.04 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 277 	 Test accuracy: 87.69 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 278 	 Test accuracy: 85.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 279 	 Test accuracy: 85.68 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:13<00:26, 13.49s/it] 67%|██████▋   | 2/3 [00:29<00:14, 14.71s/it]100%|██████████| 3/3 [00:47<00:00, 16.59s/it]100%|██████████| 3/3 [00:47<00:00, 15.98s/it]
scaleW
 [0.10906930713322216, 0.11299239993231656, 0.14500007575034432, 0.08952858749398025, 0.11488846162922016, 0.06689052368519474, 0.07038481158713594, 0.055623802644292696, 0.06389511326489501, 0.03899254669606433, 0.054924212308268, 0.029241029876842465, 0.03496277468237444, 0.02896527097843743, 0.02416897610220639, 0.018500928404919504, 0.026469697282844862, 0.011775584160908412]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 280 	 Test accuracy: 83.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 281 	 Test accuracy: 84.84 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 282 	 Test accuracy: 85.5 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 283 	 Test accuracy: 83.8 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 284 	 Test accuracy: 85.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 285 	 Test accuracy: 86.4 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 286 	 Test accuracy: 85.9 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 287 	 Test accuracy: 87.77000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 288 	 Test accuracy: 87.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 289 	 Test accuracy: 86.56 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:12<00:24, 12.46s/it] 67%|██████▋   | 2/3 [00:22<00:11, 11.02s/it]100%|██████████| 3/3 [00:41<00:00, 14.50s/it]100%|██████████| 3/3 [00:41<00:00, 13.72s/it]
scaleW
 [0.12878340706489141, 0.12522216014264906, 0.16080556184973238, 0.11921823191534359, 0.10345454638713492, 0.04736745531587889, 0.07530645697756383, 0.06380923293076506, 0.05040079863965305, 0.028813777792766403, 0.06028024142214563, 0.029327333495398494, 0.0367041003522406, 0.03870363967567788, 0.027112488185576034, 0.027384454013617162, 0.026125167109391795, 0.01370380436922866]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 290 	 Test accuracy: 87.36 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 291 	 Test accuracy: 86.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 292 	 Test accuracy: 86.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 293 	 Test accuracy: 83.71 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 294 	 Test accuracy: 86.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 295 	 Test accuracy: 86.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 296 	 Test accuracy: 86.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 297 	 Test accuracy: 84.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 298 	 Test accuracy: 87.46000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 299 	 Test accuracy: 83.67 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:36, 18.07s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.54s/it]100%|██████████| 3/3 [00:47<00:00, 15.31s/it]100%|██████████| 3/3 [00:47<00:00, 15.98s/it]
scaleW
 [0.09171826583820293, 0.0834065201235421, 0.10151056673865201, 0.06768965706435236, 0.1062576152692507, 0.057709998613575224, 0.0677083777301339, 0.04956425929724525, 0.04490926167210298, 0.02816206294771435, 0.03428671733917912, 0.013053712281012689, 0.028055238853105013, 0.018116898067459298, 0.017217169323041136, 0.011683618805066492, 0.014350338422094641, 0.006708213087742286]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 300 	 Test accuracy: 83.3 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 301 	 Test accuracy: 87.35000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 302 	 Test accuracy: 87.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 303 	 Test accuracy: 86.53 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 304 	 Test accuracy: 86.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 305 	 Test accuracy: 86.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 306 	 Test accuracy: 86.3 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 307 	 Test accuracy: 83.39999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 308 	 Test accuracy: 84.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 309 	 Test accuracy: 86.63 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:13<00:26, 13.39s/it] 67%|██████▋   | 2/3 [00:33<00:17, 17.35s/it]100%|██████████| 3/3 [00:49<00:00, 16.63s/it]100%|██████████| 3/3 [00:49<00:00, 16.44s/it]
scaleW
 [0.09717104359990432, 0.09086768784879078, 0.10622832977392217, 0.07017495675768541, 0.11774768245215632, 0.08763984736121183, 0.06907397323192603, 0.04144046030246328, 0.04717122654284933, 0.036864202891749735, 0.04830130013592368, 0.027275825463048724, 0.026790968398412423, 0.015266859490059787, 0.022611672209322017, 0.01972338830697631, 0.017072973782849575, 0.007693195419730954]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 310 	 Test accuracy: 87.92999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 311 	 Test accuracy: 84.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 312 	 Test accuracy: 87.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 313 	 Test accuracy: 88.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 314 	 Test accuracy: 86.96000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 315 	 Test accuracy: 86.04 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 316 	 Test accuracy: 86.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 317 	 Test accuracy: 86.33999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 318 	 Test accuracy: 85.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 319 	 Test accuracy: 85.92999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:16<00:32, 16.50s/it] 67%|██████▋   | 2/3 [00:31<00:15, 15.88s/it]100%|██████████| 3/3 [00:53<00:00, 18.40s/it]100%|██████████| 3/3 [00:53<00:00, 17.80s/it]
scaleW
 [0.10595108352886713, 0.080099546487182, 0.134128163234958, 0.09756631096713503, 0.0848867691397408, 0.06385227900956149, 0.06417962692249148, 0.05658957941974501, 0.055710205065675776, 0.031044793572260868, 0.04814346090512132, 0.027240122482652535, 0.030011398537419947, 0.025249242819686917, 0.03281479691678163, 0.021216444229456264, 0.024628502726410113, 0.013808752902707737]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 320 	 Test accuracy: 87.42999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 321 	 Test accuracy: 86.61999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 322 	 Test accuracy: 86.67 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 323 	 Test accuracy: 86.5 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 324 	 Test accuracy: 85.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 325 	 Test accuracy: 88.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 326 	 Test accuracy: 84.55 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 327 	 Test accuracy: 85.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 328 	 Test accuracy: 84.78999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 329 	 Test accuracy: 85.6 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:30, 15.14s/it] 67%|██████▋   | 2/3 [00:35<00:18, 18.21s/it]100%|██████████| 3/3 [00:48<00:00, 15.99s/it]100%|██████████| 3/3 [00:48<00:00, 16.29s/it]
scaleW
 [0.10704263043487, 0.10073433758265256, 0.14129103754993197, 0.09772139611153212, 0.09084295209574844, 0.062286398377180675, 0.07291103076061338, 0.052894975991568026, 0.0468496135639096, 0.02689386890188285, 0.05477750103679004, 0.03527449298523732, 0.03700629062275044, 0.025607051994699162, 0.02195593533918196, 0.015539831583173154, 0.022851585071034224, 0.009071069650913866]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 330 	 Test accuracy: 87.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 331 	 Test accuracy: 87.57000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 332 	 Test accuracy: 83.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 333 	 Test accuracy: 85.69 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 334 	 Test accuracy: 87.77000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 335 	 Test accuracy: 86.69 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 191
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 336 	 Test accuracy: 86.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 337 	 Test accuracy: 85.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 338 	 Test accuracy: 86.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 339 	 Test accuracy: 86.92999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.80s/it] 67%|██████▋   | 2/3 [00:32<00:15, 15.72s/it]100%|██████████| 3/3 [00:46<00:00, 14.93s/it]100%|██████████| 3/3 [00:46<00:00, 15.46s/it]
scaleW
 [0.09374457161784887, 0.08178035816073631, 0.12156606086481207, 0.08924874451300142, 0.11231906591954828, 0.06030949126166748, 0.058208694696641146, 0.040717010793029, 0.05438940291308505, 0.029241304034004986, 0.02679490427971153, 0.014139727195758095, 0.025695119989977522, 0.018003802421163857, 0.019849849022653587, 0.01647364512956005, 0.013691805268946143, 0.006248746211686849]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 340 	 Test accuracy: 87.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 341 	 Test accuracy: 88.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 342 	 Test accuracy: 84.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 343 	 Test accuracy: 85.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 344 	 Test accuracy: 87.21 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 345 	 Test accuracy: 87.99 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 346 	 Test accuracy: 87.99 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 347 	 Test accuracy: 87.82 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 348 	 Test accuracy: 87.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 349 	 Test accuracy: 87.01 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:34, 17.20s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.65s/it]100%|██████████| 3/3 [00:54<00:00, 18.61s/it]100%|██████████| 3/3 [00:54<00:00, 18.32s/it]
scaleW
 [0.11811329951962445, 0.11506723688890426, 0.12509487249204465, 0.06898340772706724, 0.13207066420329694, 0.06650396083718542, 0.06106463287974887, 0.052133241633052683, 0.04066719651882184, 0.033660643419422015, 0.06067552745598237, 0.026352670278279967, 0.0314909670506969, 0.025104504947819545, 0.022761559367838653, 0.020556464087522614, 0.018692179737964647, 0.006729261333941753]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 350 	 Test accuracy: 86.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 351 	 Test accuracy: 88.23 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 352 	 Test accuracy: 85.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 353 	 Test accuracy: 84.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 354 	 Test accuracy: 86.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 355 	 Test accuracy: 85.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 356 	 Test accuracy: 87.96000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 357 	 Test accuracy: 86.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 358 	 Test accuracy: 87.94 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 359 	 Test accuracy: 88.39 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:12<00:24, 12.48s/it] 67%|██████▋   | 2/3 [00:27<00:13, 13.94s/it]100%|██████████| 3/3 [00:46<00:00, 16.10s/it]100%|██████████| 3/3 [00:46<00:00, 15.40s/it]
scaleW
 [0.0927295777753178, 0.08328211037905707, 0.12721716061961966, 0.05052363929329138, 0.08990836441210076, 0.064523615461489, 0.058799369847733825, 0.048909491200893385, 0.045608392028245424, 0.020244596240783747, 0.03913618879712891, 0.019025357940553114, 0.02717757017809321, 0.022711753756767882, 0.01399734996427474, 0.009131702355261112, 0.022156245188689094, 0.011085285352281824]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 360 	 Test accuracy: 88.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 361 	 Test accuracy: 87.74 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 362 	 Test accuracy: 88.27000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 363 	 Test accuracy: 87.03999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 364 	 Test accuracy: 87.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 365 	 Test accuracy: 87.39 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 366 	 Test accuracy: 87.94 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 367 	 Test accuracy: 87.36 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 368 	 Test accuracy: 87.99 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 369 	 Test accuracy: 87.0 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.95s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.76s/it]100%|██████████| 3/3 [00:51<00:00, 16.92s/it]100%|██████████| 3/3 [00:51<00:00, 17.28s/it]
scaleW
 [0.0937180962090003, 0.09855505812433622, 0.1551939844730762, 0.10978357307162985, 0.13673944121386836, 0.08010690203656405, 0.08975494802464491, 0.06442556658313242, 0.06749094973774296, 0.048435469233737705, 0.06068539045307129, 0.026849883724730877, 0.041005252888155014, 0.03343018889516617, 0.04109517127630447, 0.03129591661712878, 0.030160385825281102, 0.017413325552725078]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 370 	 Test accuracy: 88.13 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 371 	 Test accuracy: 89.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 372 	 Test accuracy: 87.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 373 	 Test accuracy: 86.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 374 	 Test accuracy: 87.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 375 	 Test accuracy: 88.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 376 	 Test accuracy: 88.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 377 	 Test accuracy: 88.85 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 378 	 Test accuracy: 87.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 379 	 Test accuracy: 88.12 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:24<00:48, 24.10s/it] 67%|██████▋   | 2/3 [00:48<00:24, 24.30s/it]100%|██████████| 3/3 [01:06<00:00, 21.45s/it]100%|██████████| 3/3 [01:06<00:00, 22.22s/it]
scaleW
 [0.1243403354568875, 0.12161917767643186, 0.12768134187693916, 0.08040464043163224, 0.14278696530110646, 0.08808209472883738, 0.08777235617286495, 0.05703581455996471, 0.06804392609337993, 0.051925659976076045, 0.06232313936191521, 0.03803887833943142, 0.035744523279509055, 0.025666474113831064, 0.03010525746615129, 0.028703687547455645, 0.026830465678948635, 0.015423642708407972]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 380 	 Test accuracy: 87.51 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 381 	 Test accuracy: 86.29 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 382 	 Test accuracy: 88.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 383 	 Test accuracy: 89.14999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 384 	 Test accuracy: 88.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 385 	 Test accuracy: 89.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 386 	 Test accuracy: 87.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 387 	 Test accuracy: 87.72999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 388 	 Test accuracy: 88.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 389 	 Test accuracy: 88.92 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:35, 17.64s/it] 67%|██████▋   | 2/3 [00:38<00:19, 19.31s/it]100%|██████████| 3/3 [01:00<00:00, 20.77s/it]100%|██████████| 3/3 [01:00<00:00, 20.22s/it]
scaleW
 [0.08882585013122431, 0.08312332527729434, 0.12276627754205628, 0.09160677347837719, 0.1285581325006352, 0.08081245158148159, 0.0805297039505478, 0.055137403538558026, 0.051527195436539865, 0.03734576981506856, 0.030519680961284473, 0.016013019908718007, 0.03230773801806625, 0.026154618443811613, 0.03545526514329675, 0.02657519674509905, 0.023979403585629232, 0.010498159428317522]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 390 	 Test accuracy: 87.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 391 	 Test accuracy: 88.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 392 	 Test accuracy: 87.85 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 393 	 Test accuracy: 88.24 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 394 	 Test accuracy: 89.5 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 395 	 Test accuracy: 89.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 396 	 Test accuracy: 88.96 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 397 	 Test accuracy: 88.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 398 	 Test accuracy: 88.49000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 399 	 Test accuracy: 88.77000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.30s/it] 67%|██████▋   | 2/3 [00:38<00:18, 18.86s/it]100%|██████████| 3/3 [00:57<00:00, 18.93s/it]100%|██████████| 3/3 [00:57<00:00, 19.07s/it]
scaleW
 [0.09275126559585493, 0.06985086843596156, 0.10352802459111948, 0.09108655399220977, 0.12388371129629205, 0.07431348536903364, 0.06449348465847332, 0.03450025055395423, 0.04992662394640305, 0.0306702024493806, 0.03497631768702712, 0.018325825859938742, 0.029294829766096254, 0.019209256387221808, 0.027174769725026388, 0.022605782813435057, 0.02685274203117415, 0.014864670892500003]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 400 	 Test accuracy: 89.23 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 401 	 Test accuracy: 89.32 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 402 	 Test accuracy: 89.27000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 403 	 Test accuracy: 89.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 404 	 Test accuracy: 88.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 405 	 Test accuracy: 88.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 406 	 Test accuracy: 88.57000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 407 	 Test accuracy: 88.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 408 	 Test accuracy: 89.66 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 409 	 Test accuracy: 88.89 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:13<00:27, 13.96s/it] 67%|██████▋   | 2/3 [00:30<00:15, 15.50s/it]100%|██████████| 3/3 [00:46<00:00, 15.72s/it]100%|██████████| 3/3 [00:46<00:00, 15.53s/it]
scaleW
 [0.15711035207075344, 0.14051756650771619, 0.17634786782534814, 0.12193219814275198, 0.1336403645476556, 0.07472775241780528, 0.1028056581404654, 0.06681190195224872, 0.05683518391828404, 0.029402497061543853, 0.09107459377193326, 0.030752886379935524, 0.04320660002694734, 0.038516337925789276, 0.03813401897824237, 0.029091593095601834, 0.0224432939789128, 0.007605158322740386]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 410 	 Test accuracy: 89.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 411 	 Test accuracy: 89.62 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 412 	 Test accuracy: 89.53999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 413 	 Test accuracy: 89.03999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 414 	 Test accuracy: 89.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 415 	 Test accuracy: 89.38000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 416 	 Test accuracy: 89.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 417 	 Test accuracy: 89.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 418 	 Test accuracy: 89.46 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 419 	 Test accuracy: 89.39 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:13<00:26, 13.21s/it] 67%|██████▋   | 2/3 [00:28<00:14, 14.62s/it]100%|██████████| 3/3 [00:43<00:00, 14.73s/it]100%|██████████| 3/3 [00:43<00:00, 14.57s/it]
scaleW
 [0.13029232054776452, 0.1170594593392501, 0.18203394182927443, 0.11160057774881597, 0.15262873623955525, 0.11031337519716361, 0.10328332865027463, 0.08003787213383261, 0.0698758531325967, 0.048038598458435305, 0.07363041695761967, 0.03707905864765107, 0.03912242548458595, 0.03311222494690212, 0.024366991353077738, 0.022352484508557063, 0.026460617739257564, 0.012924770558910177]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 420 	 Test accuracy: 88.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 421 	 Test accuracy: 89.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 422 	 Test accuracy: 89.75999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 423 	 Test accuracy: 89.45 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 424 	 Test accuracy: 89.23 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 425 	 Test accuracy: 89.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 426 	 Test accuracy: 89.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 427 	 Test accuracy: 89.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 428 	 Test accuracy: 89.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 429 	 Test accuracy: 89.67 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:12<00:24, 12.34s/it] 67%|██████▋   | 2/3 [00:30<00:15, 15.54s/it]100%|██████████| 3/3 [00:43<00:00, 14.58s/it]100%|██████████| 3/3 [00:43<00:00, 14.54s/it]
scaleW
 [0.14642612624570572, 0.13810325074316337, 0.18978765227873218, 0.12818992576269025, 0.19190442027135393, 0.10544039941515988, 0.08732055051293146, 0.06197060257223338, 0.05134795338068978, 0.03709853729805571, 0.051347641971479396, 0.03480072484493816, 0.03508389327558039, 0.027107169907665457, 0.029366710870186677, 0.02497586185099591, 0.029720570273618543, 0.011926600694220336]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 430 	 Test accuracy: 89.39 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 431 	 Test accuracy: 90.02 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 432 	 Test accuracy: 89.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 433 	 Test accuracy: 89.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 434 	 Test accuracy: 89.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 435 	 Test accuracy: 89.4 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 191
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 436 	 Test accuracy: 90.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 437 	 Test accuracy: 90.02 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 438 	 Test accuracy: 89.98 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 439 	 Test accuracy: 89.42 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:14<00:28, 14.24s/it] 67%|██████▋   | 2/3 [00:28<00:14, 14.43s/it]100%|██████████| 3/3 [00:44<00:00, 15.13s/it]100%|██████████| 3/3 [00:44<00:00, 14.94s/it]
scaleW
 [0.15562896977943558, 0.15347334951416644, 0.16392508358138888, 0.08664672703956526, 0.11944329984228952, 0.08280140254536238, 0.09257577188918287, 0.06797920751407766, 0.0637708147617481, 0.04236189785158256, 0.035926719039828, 0.022934328448940843, 0.04005353431708659, 0.032442621962786265, 0.0281089724843623, 0.017531376304971192, 0.03012832962427724, 0.014031582325392403]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 440 	 Test accuracy: 89.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 441 	 Test accuracy: 89.36 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 442 	 Test accuracy: 89.8 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 443 	 Test accuracy: 89.84 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 444 	 Test accuracy: 89.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 445 	 Test accuracy: 90.10000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 446 	 Test accuracy: 90.16 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 447 	 Test accuracy: 89.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 448 	 Test accuracy: 89.87 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 449 	 Test accuracy: 89.92 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:16<00:32, 16.22s/it] 67%|██████▋   | 2/3 [00:29<00:14, 14.73s/it]100%|██████████| 3/3 [00:46<00:00, 15.72s/it]100%|██████████| 3/3 [00:46<00:00, 15.61s/it]
scaleW
 [0.09456865605375901, 0.11104731013352072, 0.144897652142289, 0.1055673099946814, 0.16137535704135206, 0.1104818206576713, 0.09189361107159233, 0.06059770351024357, 0.05114269788868555, 0.030154588852385467, 0.05209330951601999, 0.03166632360622531, 0.04084819636605418, 0.030978337843756032, 0.03032309114419136, 0.018585451396176293, 0.02964861647777538, 0.010469727555618593]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 450 	 Test accuracy: 89.85 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 451 	 Test accuracy: 89.92999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 452 	 Test accuracy: 90.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 453 	 Test accuracy: 90.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 454 	 Test accuracy: 89.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 455 	 Test accuracy: 90.10000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 456 	 Test accuracy: 90.16 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 457 	 Test accuracy: 90.10000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 458 	 Test accuracy: 90.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 459 	 Test accuracy: 90.12 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:34, 17.07s/it] 67%|██████▋   | 2/3 [00:34<00:17, 17.36s/it]100%|██████████| 3/3 [00:51<00:00, 17.12s/it]100%|██████████| 3/3 [00:51<00:00, 17.17s/it]
scaleW
 [0.13961383857130835, 0.13434659666068416, 0.16219872525371581, 0.08414097455481068, 0.15770086247287327, 0.07697573515201356, 0.08328893696994626, 0.0574605953614589, 0.06603547329563618, 0.04797958771528434, 0.07987147374171844, 0.0511059151345, 0.04211372806046101, 0.030343436635413598, 0.024556997455877996, 0.02317813786459283, 0.030977949761940543, 0.016562944447776468]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 460 	 Test accuracy: 89.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 461 	 Test accuracy: 90.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 462 	 Test accuracy: 90.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 463 	 Test accuracy: 90.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 464 	 Test accuracy: 90.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 465 	 Test accuracy: 90.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 466 	 Test accuracy: 90.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 467 	 Test accuracy: 90.03999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 468 	 Test accuracy: 90.16999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 469 	 Test accuracy: 89.98 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:14<00:29, 14.91s/it] 67%|██████▋   | 2/3 [00:34<00:17, 17.63s/it]100%|██████████| 3/3 [00:54<00:00, 18.60s/it]100%|██████████| 3/3 [00:54<00:00, 18.09s/it]
scaleW
 [0.1387691524690756, 0.10912971926751525, 0.1643623830720307, 0.0836224765821637, 0.12020666893064857, 0.0531208002321051, 0.06686613740857937, 0.053085538948267535, 0.0399995820426045, 0.036553858712145434, 0.06791076939994715, 0.023310785013814995, 0.037213158540538936, 0.030268404123870916, 0.023345686280714862, 0.02381665460923094, 0.024560312051067276, 0.007632599958491745]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 470 	 Test accuracy: 90.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 471 	 Test accuracy: 90.21000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 472 	 Test accuracy: 90.21000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 473 	 Test accuracy: 90.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 474 	 Test accuracy: 90.12 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 475 	 Test accuracy: 90.13 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 476 	 Test accuracy: 90.23 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 477 	 Test accuracy: 90.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 191
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 478 	 Test accuracy: 90.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 479 	 Test accuracy: 90.16 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:16<00:33, 16.75s/it] 67%|██████▋   | 2/3 [00:36<00:18, 18.75s/it]100%|██████████| 3/3 [00:48<00:00, 15.62s/it]100%|██████████| 3/3 [00:48<00:00, 16.28s/it]
scaleW
 [0.08797168457480058, 0.08030112745474788, 0.12720935389780744, 0.07838048388537945, 0.0859996452605037, 0.058403252335768784, 0.06366576899404831, 0.043043852359507064, 0.03969853104310653, 0.021376460266567827, 0.05346823617612482, 0.01880582946633465, 0.02646845665356269, 0.02003715160697911, 0.020784270500477767, 0.022858419367165494, 0.020603852321960464, 0.005854277544309428]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 480 	 Test accuracy: 90.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 481 	 Test accuracy: 90.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 482 	 Test accuracy: 90.36 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 483 	 Test accuracy: 90.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 484 	 Test accuracy: 90.32 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 485 	 Test accuracy: 90.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 486 	 Test accuracy: 90.21000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 487 	 Test accuracy: 90.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 488 	 Test accuracy: 90.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 489 	 Test accuracy: 90.21000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.27s/it] 67%|██████▋   | 2/3 [00:39<00:19, 19.59s/it]100%|██████████| 3/3 [00:53<00:00, 17.12s/it]100%|██████████| 3/3 [00:53<00:00, 17.77s/it]
scaleW
 [0.0714491369860451, 0.06799228343830366, 0.12487222869774246, 0.07182880599630119, 0.1060434270464633, 0.03356287071088201, 0.06071536508342925, 0.04605245450574019, 0.019113454667167403, 0.025468656860462204, 0.056439637472133736, 0.034557016399487134, 0.027014033836919082, 0.025786599720995052, 0.016684762469321723, 0.015786489133469084, 0.010787389990960064, 0.006564574036088057]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 490 	 Test accuracy: 90.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 491 	 Test accuracy: 90.25999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 492 	 Test accuracy: 90.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 493 	 Test accuracy: 90.16 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 494 	 Test accuracy: 90.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 495 	 Test accuracy: 90.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 496 	 Test accuracy: 90.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 497 	 Test accuracy: 90.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 498 	 Test accuracy: 90.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.0.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.1.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv1.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer1.2.conv2.weight
torch.Size([6, 384]) (384, 6) 192
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv1.weight
torch.Size([6, 768]) (768, 6) 192
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.0.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.1.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv1.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer2.2.conv2.weight
torch.Size([6, 1536]) (1536, 6) 192
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv1.weight
torch.Size([6, 3072]) (3072, 6) 192
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.0.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.1.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv1.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  6 layer3.2.conv2.weight
torch.Size([6, 6144]) (6144, 6) 192
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.903432331495643
Current epoch: 499 	 Test accuracy: 90.29 %
The best checkpoint is loaded
Test accuracy: 90.36%
