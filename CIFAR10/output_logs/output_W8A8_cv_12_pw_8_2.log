dataset: cifar10	arch: resnet20_quant	num_workers: 4	seed: None	batch_size: 32	epochs: 400	optimizer_m: Adam	optimizer_q: Adam	lr_m: 0.001	lr_q: 1e-05	lr_m_end: 0.0	lr_q_end: 0.0	decay_schedule_m: 150-300	decay_schedule_q: 150-300	momentum: 0.9	weight_decay: 0.0001	lr_scheduler_m: cosine	lr_scheduler_q: cosine	gamma: 0.1	QWeightFlag: True	QActFlag: True	weight_levels: 256	act_levels: 256	baseline: False	bkwd_scaling_factorW: 0.0	bkwd_scaling_factorA: 0.0	use_hessian: True	update_every: 10	gpu_id: 1	log_dir: ../results/CIFAR10_ResNet50/W8A8_kmeans_comp_decomp_cv_12_pw_8_2/	load_pretrain: True	pretrain_path: ../results/ResNet20_CIFAR10/fp/checkpoint/best_checkpoint.pth	btq: True	training_flag: False	eval: False	weighted: False	cv_block_size: 12	pw_fc_block_size: 8	
Files already downloaded and verified
The number of parameters :  269940
Pretrained full precision weights are initialized
# total params: 269940
# model params: 269850
# quantizer params: 90
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): QBasicBlock(
      (conv1): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): QBasicBlock(
      (conv1): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 000 	 Test accuracy: 14.940000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 001 	 Test accuracy: 20.84 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 002 	 Test accuracy: 13.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 003 	 Test accuracy: 15.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 004 	 Test accuracy: 21.13 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 383
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 005 	 Test accuracy: 26.479999999999997 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 006 	 Test accuracy: 21.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 007 	 Test accuracy: 27.38 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 008 	 Test accuracy: 24.740000000000002 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 009 	 Test accuracy: 28.23 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:16<00:32, 16.19s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.77s/it]100%|██████████| 3/3 [00:58<00:00, 20.18s/it]100%|██████████| 3/3 [00:58<00:00, 19.39s/it]


scaleA
 [0.013080101047679192, 0.008252451653265106, 0.006524775052862753, 0.008711469735466732, 0.00438244380640914, 0.0047892619381707255, 0.005176224132609782, 0.00841783480606546, 0.007819671121092229, 0.00585914151730402, 0.0022370485260367573, 0.0058780402196681, 0.007378935574207972, 0.015510440806293558, 0.010856264943716573, 0.01328856360104516, 0.00872038170522046, 0.008599471666018788]
scaleW
 [0.1001431033876908, 0.0997550037751125, 0.13405518116158888, 0.09255422307018785, 0.07949150655554128, 0.058904371445554236, 0.07388494804349693, 0.046301896585103385, 0.052124364885166335, 0.018785304715026707, 0.021901271983183767, 0.014395949204501027, 0.02782606742149078, 0.025081525205305415, 0.027618370251520075, 0.019726068972471814, 0.01976727515168714, 0.008867535634700165]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 010 	 Test accuracy: 26.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 011 	 Test accuracy: 32.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 012 	 Test accuracy: 41.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 013 	 Test accuracy: 30.759999999999998 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 014 	 Test accuracy: 29.13 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 015 	 Test accuracy: 36.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 016 	 Test accuracy: 35.74 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 017 	 Test accuracy: 37.730000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 018 	 Test accuracy: 33.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 019 	 Test accuracy: 38.769999999999996 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:36, 18.28s/it] 67%|██████▋   | 2/3 [00:34<00:17, 17.30s/it]100%|██████████| 3/3 [00:50<00:00, 16.47s/it]100%|██████████| 3/3 [00:50<00:00, 16.81s/it]


scaleA
 [0.013238776391567291, 0.007412213607205585, 0.0061815954697727014, 0.010097090399259103, 0.0037705643177198115, 0.007468336481347843, 0.005510956467316522, 0.012378951203453706, 0.009264694083594835, 0.009970079103892485, 0.005872814029843496, 0.011085698864348377, 0.010480654152490684, 0.02233865141942681, 0.012441289791593445, 0.014788536943738939, 0.012824385346726733, 0.012713662696726217]
scaleW
 [0.08219293764185137, 0.08554645329905482, 0.1200865201823003, 0.0827248910867368, 0.09231669991412056, 0.06422913529242569, 0.06022662423839459, 0.05489058286101004, 0.048078749877603265, 0.02837727656007756, 0.047871976530115316, 0.029226612460179397, 0.03348303384323872, 0.030163113562998268, 0.02390726636041679, 0.020394845181947476, 0.02351835988595891, 0.013470664727391696]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 020 	 Test accuracy: 38.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 021 	 Test accuracy: 39.839999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 022 	 Test accuracy: 36.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 023 	 Test accuracy: 27.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 024 	 Test accuracy: 27.38 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 025 	 Test accuracy: 45.32 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 026 	 Test accuracy: 41.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 027 	 Test accuracy: 45.23 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 028 	 Test accuracy: 48.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 029 	 Test accuracy: 37.44 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:41, 20.66s/it] 67%|██████▋   | 2/3 [00:43<00:21, 21.71s/it]100%|██████████| 3/3 [00:57<00:00, 18.20s/it]100%|██████████| 3/3 [00:57<00:00, 19.06s/it]


scaleA
 [0.013736168832621869, 0.00813326784154073, 0.0036400916650550057, 0.0070340463572287635, 0.006024524801020968, 0.0076160145865388105, 0.005742561985983272, 0.009109418199624847, 0.005537684877986955, 0.008067754946930843, 0.0071229290614954295, 0.010942723750687833, 0.009855434454413815, 0.022230863855576915, 0.012056088844477437, 0.012999081570918733, 0.007731851964644595, 0.009155148703954232]
scaleW
 [0.09892634249061115, 0.10123018049741546, 0.08156638907296117, 0.059445607205627006, 0.10878938079490978, 0.06584468869838106, 0.05452912589874646, 0.03854665820603496, 0.03367838547632351, 0.01996020814264554, 0.04577171599438165, 0.025364034760039195, 0.031080806688084328, 0.02896179353877576, 0.023127939938202016, 0.016265333120930654, 0.015031287004954237, 0.006728225427500802]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 030 	 Test accuracy: 37.980000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 031 	 Test accuracy: 46.5 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 032 	 Test accuracy: 42.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 033 	 Test accuracy: 45.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 034 	 Test accuracy: 36.13 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 035 	 Test accuracy: 36.3 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 036 	 Test accuracy: 48.089999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 037 	 Test accuracy: 33.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 038 	 Test accuracy: 37.019999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 039 	 Test accuracy: 32.82 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.49s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.60s/it]100%|██████████| 3/3 [00:52<00:00, 17.38s/it]100%|██████████| 3/3 [00:52<00:00, 17.64s/it]


scaleA
 [0.011481796364850165, 0.006276871858902379, 0.005207692483490913, 0.00811646987911098, 0.004705413145399558, 0.005366087243426358, 0.0034182988100895473, 0.007472765177868275, 0.007574670332925481, 0.007039578674886694, 0.002668957108906088, 0.006933032729284655, 0.007848787059100457, 0.019331808666219308, 0.009160068025366732, 0.00869905403060456, 0.003626148585697124, 0.003566122787124813]
scaleW
 [0.0701648594471966, 0.07866411279730613, 0.10245657381393207, 0.06729431978455475, 0.08966318726492085, 0.04155674121793515, 0.037325662832693486, 0.030907233776244932, 0.04179637449826609, 0.019411364766976667, 0.023266600775356777, 0.01495087975008405, 0.026419388674092742, 0.024917630934811943, 0.018373605452858068, 0.012235456874995165, 0.00465700242836702, 0.0033124111461842413]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 040 	 Test accuracy: 36.96 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 041 	 Test accuracy: 45.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 042 	 Test accuracy: 45.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 043 	 Test accuracy: 36.15 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 044 	 Test accuracy: 43.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 045 	 Test accuracy: 28.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 046 	 Test accuracy: 33.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 047 	 Test accuracy: 35.730000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 048 	 Test accuracy: 40.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 049 	 Test accuracy: 35.72 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:34, 17.04s/it] 67%|██████▋   | 2/3 [00:36<00:18, 18.62s/it]100%|██████████| 3/3 [00:56<00:00, 19.11s/it]100%|██████████| 3/3 [00:56<00:00, 18.83s/it]


scaleA
 [0.01783193126902507, 0.009569047131545312, 0.008111137258635473, 0.011885062237927582, 0.006215976395377044, 0.006073299632936977, 0.004565584618794055, 0.009126294262114563, 0.005458115588725466, 0.003456622136590429, 0.009221217438832516, 0.01231589475085515, 0.00675284024201336, 0.01488551309271102, 0.009897760555117366, 0.011632566702131834, 0.011350307115618003, 0.016281192899547072]
scaleW
 [0.13967494941277941, 0.10719458307185299, 0.12366079533745063, 0.08946476812216449, 0.11617017034371685, 0.040285025537059115, 0.042850854876491824, 0.03760939903869196, 0.03147687744907052, 0.005813638952745008, 0.04504447780764642, 0.029676038454775445, 0.02081936119820715, 0.015630177759196746, 0.018153071267000356, 0.014575559602022488, 0.0184014068624313, 0.013470921704377123]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 050 	 Test accuracy: 39.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 051 	 Test accuracy: 33.910000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 052 	 Test accuracy: 51.019999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 053 	 Test accuracy: 37.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 054 	 Test accuracy: 40.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 055 	 Test accuracy: 44.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 056 	 Test accuracy: 46.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 057 	 Test accuracy: 54.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 058 	 Test accuracy: 50.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 059 	 Test accuracy: 41.8 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:16<00:32, 16.03s/it] 67%|██████▋   | 2/3 [00:37<00:19, 19.22s/it]100%|██████████| 3/3 [00:50<00:00, 16.61s/it]100%|██████████| 3/3 [00:51<00:00, 17.01s/it]


scaleA
 [0.013355433766853905, 0.0072888397464418, 0.006813601942139345, 0.008856979289670613, 0.005152384222456447, 0.007678590132442671, 0.005931945963576452, 0.010096791375228108, 0.008147173116859419, 0.00981438635066193, 0.007437775064189064, 0.00833821938036852, 0.00941451847815978, 0.020779044137414073, 0.008691629444439667, 0.013609683688055518, 0.005461961613504947, 0.005985384746546613]
scaleW
 [0.09414587299797694, 0.0994251563879238, 0.11386752708703712, 0.06436650974592922, 0.0892695269073155, 0.059244722051949396, 0.058754085745472084, 0.044701004364628205, 0.045987939127077666, 0.029296174509301515, 0.04387739092613163, 0.019675319754044733, 0.028354012435842096, 0.02848667876962173, 0.01591492672545006, 0.014369892605656897, 0.010388902023501576, 0.0019500675282314148]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 060 	 Test accuracy: 36.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 061 	 Test accuracy: 37.85 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 062 	 Test accuracy: 56.67 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 063 	 Test accuracy: 29.53 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 064 	 Test accuracy: 44.7 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 065 	 Test accuracy: 52.300000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 066 	 Test accuracy: 40.62 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 067 	 Test accuracy: 41.010000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 068 	 Test accuracy: 50.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 069 	 Test accuracy: 44.71 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:34, 17.14s/it] 67%|██████▋   | 2/3 [00:34<00:17, 17.49s/it]100%|██████████| 3/3 [00:52<00:00, 17.50s/it]100%|██████████| 3/3 [00:52<00:00, 17.48s/it]


scaleA
 [0.011575789125707047, 0.005620965252430741, 0.006136142599608772, 0.008028133820713374, 0.0038615853304757655, 0.006681703751015618, 0.0047980207736194715, 0.008660764092238114, 0.006250839156254211, 0.007848990194004422, 0.005931943104433654, 0.00953263891383792, 0.006920721658212656, 0.016766914270690905, 0.010160056796209018, 0.01074330710809846, 0.009652437970201258, 0.009481502754139714]
scaleW
 [0.07761859178532327, 0.07814190186858953, 0.09406763638838771, 0.0422287984610246, 0.0697543234616929, 0.048035997340357434, 0.050373944431435703, 0.032201470907174505, 0.031481762720965846, 0.021665344979170942, 0.033670584215948415, 0.023075109655188563, 0.0212685718009171, 0.020066071413886246, 0.017601898532029106, 0.012789898658974487, 0.018300216917672075, 0.007094462114319806]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 070 	 Test accuracy: 51.800000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 071 	 Test accuracy: 45.36 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 072 	 Test accuracy: 37.54 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 073 	 Test accuracy: 42.230000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 383
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 074 	 Test accuracy: 47.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 075 	 Test accuracy: 49.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 076 	 Test accuracy: 49.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 077 	 Test accuracy: 48.9 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 078 	 Test accuracy: 47.71 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 079 	 Test accuracy: 37.56 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:34, 17.36s/it] 67%|██████▋   | 2/3 [00:31<00:15, 15.36s/it]100%|██████████| 3/3 [00:51<00:00, 17.48s/it]100%|██████████| 3/3 [00:51<00:00, 17.12s/it]


scaleA
 [0.016162811108208632, 0.00892890194349794, 0.006194385807785779, 0.00933980288467552, 0.006905416635771361, 0.00742970929031365, 0.0054965824915064534, 0.00793974027558046, 0.006359542223040473, 0.009012020214537361, 0.006795192533324015, 0.007225944685991211, 0.005184292776527404, 0.010821073662541833, 0.009477123371315638, 0.01407894530409192, 0.013625634517909482, 0.010859496130892739]
scaleW
 [0.11482822845105663, 0.11143899074003537, 0.10362684951038348, 0.056955395250284015, 0.08463215153336141, 0.04877572887300289, 0.04830434327349121, 0.034636891671891115, 0.03388698165018784, 0.01771346053655762, 0.03895543199298618, 0.0168486014310625, 0.01589544940212199, 0.01355254656505552, 0.01652571051621007, 0.016611155760890117, 0.021374013543469253, 0.008458368844627183]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 080 	 Test accuracy: 45.5 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 081 	 Test accuracy: 46.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 082 	 Test accuracy: 47.099999999999994 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 083 	 Test accuracy: 39.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 084 	 Test accuracy: 29.160000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 085 	 Test accuracy: 50.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 086 	 Test accuracy: 52.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 087 	 Test accuracy: 46.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 088 	 Test accuracy: 43.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 089 	 Test accuracy: 41.199999999999996 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:21<00:43, 21.73s/it] 67%|██████▋   | 2/3 [00:34<00:16, 16.43s/it]100%|██████████| 3/3 [00:52<00:00, 17.24s/it]100%|██████████| 3/3 [00:52<00:00, 17.57s/it]


scaleA
 [0.021586978547683957, 0.010037913627091477, 0.009920784501168999, 0.01196416304196545, 0.005147643266910422, 0.008073805581962195, 0.005965450737628459, 0.011071655196202844, 0.006216960200627771, 0.010594987936046261, 0.010714058450818941, 0.018159592343756376, 0.008457660626080457, 0.018721627984181397, 0.008116389104129408, 0.013527630637212235, 0.010055137587802796, 0.011556858635494235]
scaleW
 [0.10024400817986769, 0.09754862872172436, 0.1370932082709844, 0.06971781840259524, 0.08408623800410579, 0.057562944866264586, 0.059510861335495185, 0.04611282097784486, 0.03165601994065309, 0.02581550131402727, 0.05984969456132017, 0.04246497903836061, 0.024926157064723703, 0.021277852296925994, 0.010975778460626607, 0.012264507525192661, 0.014957880775639745, 0.007935144586016721]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 090 	 Test accuracy: 54.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 091 	 Test accuracy: 44.629999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 092 	 Test accuracy: 53.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 093 	 Test accuracy: 46.150000000000006 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 094 	 Test accuracy: 33.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 095 	 Test accuracy: 37.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 096 	 Test accuracy: 55.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 097 	 Test accuracy: 52.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 098 	 Test accuracy: 49.309999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 099 	 Test accuracy: 39.95 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:35, 17.93s/it] 67%|██████▋   | 2/3 [00:36<00:18, 18.32s/it]100%|██████████| 3/3 [00:55<00:00, 18.84s/it]100%|██████████| 3/3 [00:56<00:00, 18.67s/it]


scaleA
 [0.019495841271713915, 0.009640084378551296, 0.009502925474400502, 0.013555994668515897, 0.003924740888729562, 0.0069857379825896335, 0.00542913850953666, 0.011373701156246287, 0.012785875782967355, 0.010814330558459635, 0.00885419126822976, 0.011110648051193722, 0.008788862636876045, 0.019482736915640644, 0.013586019291922921, 0.015622592063073662, 0.01585810112790108, 0.01779401130162937]
scaleW
 [0.1304667396890766, 0.11446717491648344, 0.13222755704327724, 0.09154019171159598, 0.08202796721262795, 0.057518063860383, 0.05527086184047497, 0.04666058976427104, 0.0632613139287893, 0.02766605182511531, 0.04757658265915363, 0.025499453145584994, 0.025396600729360553, 0.025695381325275185, 0.025320294894387693, 0.015507180678716028, 0.025674927525321384, 0.01580109844196247]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 100 	 Test accuracy: 47.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 101 	 Test accuracy: 48.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 102 	 Test accuracy: 36.24 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 103 	 Test accuracy: 41.21 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 104 	 Test accuracy: 50.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 105 	 Test accuracy: 45.5 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 106 	 Test accuracy: 55.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 107 	 Test accuracy: 56.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 108 	 Test accuracy: 46.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 109 	 Test accuracy: 51.4 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:21<00:42, 21.14s/it] 67%|██████▋   | 2/3 [00:36<00:17, 17.68s/it]100%|██████████| 3/3 [00:53<00:00, 17.48s/it]100%|██████████| 3/3 [00:53<00:00, 17.89s/it]


scaleA
 [0.012957917051161125, 0.006628261484627879, 0.00773088263401641, 0.011111345857272482, 0.000503333541305824, 0.006092475878232453, 0.0046797866018756, 0.008442794596703187, 0.010723606056408028, 0.012504353835144874, 0.00716524386288217, 0.010813629022652482, 0.0076878878415640485, 0.014992853516474239, 0.012286178757228096, 0.017718112090113824, 0.01738326446206601, 0.016576512985761484]
scaleW
 [0.0777157074149099, 0.08213138082526507, 0.1284951593672786, 0.091158639289807, 0.04698155576104801, 0.04055641206702207, 0.05230479606715039, 0.03825373771836221, 0.06082618337134991, 0.03185610682713646, 0.044974473546059525, 0.028086732640740908, 0.027322993048475196, 0.019481477850956185, 0.023849267575941236, 0.02067316406307261, 0.028217820119832215, 0.014726286257718746]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 110 	 Test accuracy: 47.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 111 	 Test accuracy: 46.089999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 112 	 Test accuracy: 52.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 113 	 Test accuracy: 49.01 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 114 	 Test accuracy: 48.24 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 115 	 Test accuracy: 61.050000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 116 	 Test accuracy: 61.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 117 	 Test accuracy: 58.379999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 118 	 Test accuracy: 52.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 119 	 Test accuracy: 49.84 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:14<00:29, 14.74s/it] 67%|██████▋   | 2/3 [00:28<00:14, 14.02s/it]100%|██████████| 3/3 [00:46<00:00, 16.04s/it]100%|██████████| 3/3 [00:46<00:00, 15.58s/it]


scaleA
 [0.016864413589795364, 0.007218418232966863, 0.006369643640825453, 0.009604828183934853, 0.006925072626521817, 0.007132951108055976, 0.0052968508697384745, 0.00871820771517024, 0.009753614790347734, 0.0110377715085696, 0.005623213408042601, 0.008938772442820172, 0.006711033398405921, 0.014649384442505105, 0.008235872319178689, 0.011117502379966171, 0.00954276862769606, 0.010215322308498712]
scaleW
 [0.08466627317192525, 0.07275356924387828, 0.09888218957867789, 0.06997117749585735, 0.09982893259146074, 0.056065444231867274, 0.052439468769101716, 0.031413369822834464, 0.04888753375406104, 0.03637605092907281, 0.035274194145127516, 0.01952780967394285, 0.020027061732287316, 0.016634044584388996, 0.014097543656944168, 0.00859990137257213, 0.012874818513250022, 0.006952690588168893]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 120 	 Test accuracy: 62.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 121 	 Test accuracy: 52.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 122 	 Test accuracy: 66.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 123 	 Test accuracy: 51.9 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 124 	 Test accuracy: 59.31999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 125 	 Test accuracy: 48.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 126 	 Test accuracy: 51.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 127 	 Test accuracy: 50.019999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 128 	 Test accuracy: 51.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 129 	 Test accuracy: 56.32 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:35, 17.55s/it] 67%|██████▋   | 2/3 [00:34<00:17, 17.07s/it]100%|██████████| 3/3 [00:52<00:00, 17.52s/it]100%|██████████| 3/3 [00:52<00:00, 17.46s/it]


scaleA
 [0.018746158283388315, 0.007269333204090883, 0.005952471833842651, 0.011590654875055858, 0.006105525929724873, 0.00683256988295966, 0.005822325983157931, 0.009646133470784125, 0.007129931989861983, 0.009771519866021728, 0.004463134436387266, 0.00632041591054357, 0.008525080830257496, 0.01919443156084236, 0.014122292645352613, 0.019480351211709105, 0.017066662361001905, 0.014562438242816916]
scaleW
 [0.09784665523340126, 0.10285850798298317, 0.11798039609982636, 0.08439659056784538, 0.1006740775696661, 0.06071872563540198, 0.062415250335721366, 0.03939363167561835, 0.05270681054487331, 0.02483093226700982, 0.036632437818385745, 0.010816452695951549, 0.0251076569837129, 0.022238914814506506, 0.024415806482445623, 0.021274319821975363, 0.02871930044538017, 0.011169995221353486]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 130 	 Test accuracy: 62.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 131 	 Test accuracy: 57.50999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 132 	 Test accuracy: 54.02 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 133 	 Test accuracy: 60.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 134 	 Test accuracy: 56.87 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 135 	 Test accuracy: 48.980000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 136 	 Test accuracy: 61.050000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 137 	 Test accuracy: 55.06999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 138 	 Test accuracy: 58.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 139 	 Test accuracy: 61.86000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:13<00:26, 13.43s/it] 67%|██████▋   | 2/3 [00:33<00:17, 17.16s/it]100%|██████████| 3/3 [00:47<00:00, 15.91s/it]100%|██████████| 3/3 [00:47<00:00, 15.89s/it]


scaleA
 [0.02038078347520421, 0.009043618292363395, 0.00716798505413804, 0.010930399681857996, 0.010111807440247754, 0.007265417653574468, 0.0046446665241390616, 0.009261610482408034, 0.006047831820136791, 0.008074751509134554, 0.008141237423415507, 0.013910724257548905, 0.0070631797068899695, 0.0178670685242773, 0.007949721913119967, 0.013078022200852435, 0.011298128147714826, 0.014211269821830574]
scaleW
 [0.11089446654006736, 0.09996700490499433, 0.10362605254329323, 0.08154901054832668, 0.11046062918809009, 0.056206048074402305, 0.05091655082337104, 0.03639670655592855, 0.036304148335536246, 0.024749045812914972, 0.05294507416765274, 0.03463434133446131, 0.026067979071200453, 0.021496063627407896, 0.014019356209368478, 0.013073834628339276, 0.018299073333128336, 0.011235015331423771]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 140 	 Test accuracy: 58.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 141 	 Test accuracy: 54.230000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 142 	 Test accuracy: 56.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 143 	 Test accuracy: 62.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 144 	 Test accuracy: 59.519999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 145 	 Test accuracy: 53.269999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 146 	 Test accuracy: 56.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 147 	 Test accuracy: 57.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 148 	 Test accuracy: 53.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 149 	 Test accuracy: 66.94 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:34, 17.02s/it] 67%|██████▋   | 2/3 [00:40<00:20, 20.85s/it]100%|██████████| 3/3 [00:59<00:00, 19.80s/it]100%|██████████| 3/3 [00:59<00:00, 19.71s/it]


scaleA
 [0.011800210106293132, 0.006565382653402046, 0.00483531438404979, 0.005023239561908412, 0.004792512518860942, 0.005178750206051793, 0.002915710972831336, 0.006227566775446616, 0.007677971958468831, 0.008076124058880347, 0.008026403713396439, 0.009360109030226695, 0.004702391271913522, 0.008666606406527883, 0.0068716767602835065, 0.006494892754968972, 0.0036561012439445873, 0.006130003307907593]
scaleW
 [0.09438474299393584, 0.08611208915969155, 0.1012484483065383, 0.02808198089263617, 0.058666122738158244, 0.032650504877973864, 0.037898116705504505, 0.023268843649824206, 0.03366637121884972, 0.02495387334630313, 0.043292246427530455, 0.022487125652712363, 0.01461109155179268, 0.010389504351201605, 0.01084479671011962, 0.006602614027052871, 0.004613707945438099, 0.0018300452221374638]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 150 	 Test accuracy: 67.67999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 151 	 Test accuracy: 57.830000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 152 	 Test accuracy: 58.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 153 	 Test accuracy: 56.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 154 	 Test accuracy: 61.01 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 155 	 Test accuracy: 59.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 156 	 Test accuracy: 62.970000000000006 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 157 	 Test accuracy: 53.5 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 158 	 Test accuracy: 62.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 159 	 Test accuracy: 66.53999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:16<00:32, 16.30s/it] 67%|██████▋   | 2/3 [00:35<00:18, 18.00s/it]100%|██████████| 3/3 [00:53<00:00, 17.96s/it]100%|██████████| 3/3 [00:53<00:00, 17.82s/it]


scaleA
 [0.018939819910762493, 0.007256672569924509, 0.007121090151316865, 0.010683996140123943, 0.0031501464622677596, 0.007660937201399908, 0.006951605669900084, 0.012444517035789276, 0.009152792486653814, 0.013154738152746643, 0.009217669894181794, 0.013135959832574663, 0.010380674866468279, 0.02550781420295689, 0.011697709991445556, 0.015756032127919983, 0.01269059057192952, 0.012536972814322334]
scaleW
 [0.10444351686431035, 0.10927195093723574, 0.13664761007089155, 0.07226181164039551, 0.07989542970381587, 0.05878986999852742, 0.07426630549772872, 0.05296709919875523, 0.05810734269698756, 0.034733837108806516, 0.0564597122303653, 0.037653537533019574, 0.03540953350763749, 0.029175812843768304, 0.02161789700795609, 0.016994941925548335, 0.01996793681199678, 0.007363559956122117]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 383
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 160 	 Test accuracy: 53.769999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 161 	 Test accuracy: 64.32 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 162 	 Test accuracy: 60.36 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 163 	 Test accuracy: 66.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 164 	 Test accuracy: 61.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 165 	 Test accuracy: 68.74 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 166 	 Test accuracy: 73.32 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 167 	 Test accuracy: 65.99000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 168 	 Test accuracy: 66.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 169 	 Test accuracy: 67.46 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:22<00:45, 22.72s/it] 67%|██████▋   | 2/3 [00:41<00:20, 20.37s/it]100%|██████████| 3/3 [01:02<00:00, 20.86s/it]100%|██████████| 3/3 [01:02<00:00, 20.97s/it]


scaleA
 [0.012908942637396162, 0.004369769855890607, 0.004737107943246505, 0.007316500841725355, 0.0042515849758239825, 0.007496975741766799, 0.0052155667843845925, 0.00972547936488584, 0.006655740618486328, 0.006287321661473705, 0.004975432209524143, 0.008692157539493607, 0.007513167565409422, 0.014914608304453505, 0.013685429001220308, 0.015068672678972031, 0.007761190091232263, 0.009988763015562003]
scaleW
 [0.07923082374944034, 0.06462427435301286, 0.07215797052060312, 0.04795411218145847, 0.09501260798538637, 0.06136470402186178, 0.05576506671516596, 0.04548429256958714, 0.04053820643750149, 0.02194253749156939, 0.031936443406021385, 0.020226117086396645, 0.026930455039757314, 0.020623912725246548, 0.024422970485049777, 0.015794979523309775, 0.014154056942808108, 0.007383501993252009]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 170 	 Test accuracy: 68.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 171 	 Test accuracy: 66.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 172 	 Test accuracy: 61.029999999999994 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 173 	 Test accuracy: 68.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 383
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 174 	 Test accuracy: 65.57 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 175 	 Test accuracy: 66.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 383
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 176 	 Test accuracy: 72.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 177 	 Test accuracy: 63.629999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 178 	 Test accuracy: 72.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 179 	 Test accuracy: 64.3 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:41, 20.73s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.19s/it]100%|██████████| 3/3 [00:51<00:00, 16.84s/it]100%|██████████| 3/3 [00:51<00:00, 17.31s/it]


scaleA
 [0.017848904847864517, 0.008993239579121806, 0.009417594273974737, 0.011756542386816698, 0.009039312198999972, 0.00838129422829333, 0.006396320968072705, 0.010688729376349666, 0.007848263249552331, 0.01027677757973111, 0.005356670148687718, 0.009027643478054676, 0.00995092431312502, 0.02444407408228612, 0.011942586329560382, 0.013044885326374546, 0.012375135297749147, 0.01664014132689567]
scaleW
 [0.11389326361496806, 0.11458400861386593, 0.140781163124335, 0.09136820893351603, 0.13182927032635147, 0.06904982981502093, 0.07336724700081576, 0.05012716083041832, 0.050596452640156754, 0.030363353275425567, 0.03997744618338287, 0.02057599061653581, 0.033900358734473036, 0.032830405199221264, 0.022529400641160147, 0.014808923710510255, 0.020739986377232015, 0.009389404944616375]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 180 	 Test accuracy: 56.769999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 181 	 Test accuracy: 64.51 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 182 	 Test accuracy: 69.91000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 183 	 Test accuracy: 69.21000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 184 	 Test accuracy: 70.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 185 	 Test accuracy: 68.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 186 	 Test accuracy: 72.7 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 187 	 Test accuracy: 65.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 188 	 Test accuracy: 71.89999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 189 	 Test accuracy: 65.05 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:31, 15.66s/it] 67%|██████▋   | 2/3 [00:38<00:19, 19.74s/it]100%|██████████| 3/3 [01:00<00:00, 21.04s/it]100%|██████████| 3/3 [01:00<00:00, 20.30s/it]


scaleA
 [0.017223532112297244, 0.007639190560893005, 0.010099890365655529, 0.013833110162743157, 0.0011440196401875972, 0.005968322172643634, 0.00498568075979082, 0.01086903991830035, 0.010824387070957448, 0.011284121998900276, 0.00599692453829759, 0.005926717872493247, 0.010666760523497793, 0.0266933409905236, 0.014393250727358956, 0.017216601822591687, 0.009444666148894, 0.01152272628151683]
scaleW
 [0.0943180326168912, 0.11200965201356372, 0.1448655815861246, 0.10226558150719188, 0.07842102346360856, 0.0557331641703313, 0.06760001919651666, 0.05022895757742002, 0.05610623574327441, 0.03444234575217275, 0.0461115884401462, 0.013302123614648087, 0.038679811136958585, 0.03311050333459672, 0.025853917993248016, 0.01971846549431901, 0.01820341143940632, 0.007389006794917237]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 190 	 Test accuracy: 73.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 191 	 Test accuracy: 67.53 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 192 	 Test accuracy: 72.15 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 193 	 Test accuracy: 72.24000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 194 	 Test accuracy: 71.54 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 195 	 Test accuracy: 74.33999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 196 	 Test accuracy: 63.849999999999994 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 383
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 197 	 Test accuracy: 70.23 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 198 	 Test accuracy: 75.33999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 199 	 Test accuracy: 72.32 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:36, 18.30s/it] 67%|██████▋   | 2/3 [00:37<00:18, 18.62s/it]100%|██████████| 3/3 [00:54<00:00, 18.12s/it]100%|██████████| 3/3 [00:54<00:00, 18.23s/it]


scaleA
 [0.014959459307851669, 0.005775456868056646, 0.006238751598503733, 0.01259615701935917, 0.005198594928348528, 0.007416114820239746, 0.005446188540302005, 0.011029071057453252, 0.00823744600098588, 0.010180850100438342, 0.005738311231483137, 0.010025817101958831, 0.00901458806164192, 0.019851137590751314, 0.010314365133980187, 0.015650518190103675, 0.008398435404148863, 0.009737327068236249]
scaleW
 [0.06993378158995671, 0.07254045472965422, 0.10520240301794297, 0.1118542540649239, 0.11978503014475143, 0.07965284544635486, 0.06650113453988814, 0.05491015371332262, 0.051653075273019954, 0.034478239671144446, 0.043751302690335524, 0.02674069633237937, 0.031123106573457248, 0.02562715745298226, 0.022791052162187717, 0.01685100101064516, 0.014634385721756661, 0.008138394435865793]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 200 	 Test accuracy: 67.45 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 201 	 Test accuracy: 71.67 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 202 	 Test accuracy: 72.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 203 	 Test accuracy: 72.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 204 	 Test accuracy: 73.33 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 205 	 Test accuracy: 70.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 206 	 Test accuracy: 72.7 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 207 	 Test accuracy: 68.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 208 	 Test accuracy: 69.04 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 209 	 Test accuracy: 73.92999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.40s/it] 67%|██████▋   | 2/3 [00:39<00:19, 19.64s/it]100%|██████████| 3/3 [00:56<00:00, 18.62s/it]100%|██████████| 3/3 [00:56<00:00, 18.99s/it]


scaleA
 [0.016868433113063488, 0.00684156500507526, 0.007457530964603721, 0.011263506715403273, 0.005129995340782552, 0.006687526186050476, 0.0038395445596508203, 0.008108232195162395, 0.0060957725857484326, 0.0053413015807492305, 0.0027122986303663166, 0.006414860498423142, 0.0062737170757673245, 0.014998023936536847, 0.014619902886647497, 0.015240843534040352, 0.005070848130166138, 0.003403177621973619]
scaleW
 [0.07496954157142903, 0.09199665337188319, 0.13394814989000914, 0.0971846016925727, 0.09488417043285058, 0.06603848608532957, 0.04455745470984996, 0.039553684452448286, 0.03919470760304351, 0.014234726994950854, 0.031948195080554624, 0.011465456559678252, 0.02084854132539271, 0.021743230984271916, 0.025257563249771613, 0.0171604629182039, 0.00324863788185752, 0.0012182316327883304]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 210 	 Test accuracy: 77.62 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 211 	 Test accuracy: 74.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 212 	 Test accuracy: 72.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 213 	 Test accuracy: 76.03999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 214 	 Test accuracy: 69.99 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 215 	 Test accuracy: 77.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 216 	 Test accuracy: 71.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 217 	 Test accuracy: 71.7 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 218 	 Test accuracy: 73.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 219 	 Test accuracy: 75.01 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.02s/it] 67%|██████▋   | 2/3 [00:40<00:20, 20.43s/it]100%|██████████| 3/3 [00:57<00:00, 18.62s/it]100%|██████████| 3/3 [00:57<00:00, 19.08s/it]


scaleA
 [0.020560637285507447, 0.00905831926571636, 0.010605607331341901, 0.012736848937407508, 0.005573934571944154, 0.008979135352289967, 0.006402404933805901, 0.012665595761478868, 0.012394884912982922, 0.012191980425314254, 0.012873287961063781, 0.015648149263812652, 0.007602224036565702, 0.01545947592798716, 0.007827918772582173, 0.009788794310909425, 0.007122417836661819, 0.01073178377976638]
scaleW
 [0.1319175005899991, 0.10793770747675828, 0.13113236148084303, 0.09787941441615298, 0.11614426556845599, 0.07022381466917617, 0.06812473105737486, 0.0533705081142144, 0.06180510711324041, 0.04079344979238195, 0.06656613241403192, 0.03602373905119366, 0.028228782927221332, 0.019612821550666563, 0.013489943457012432, 0.01283971791027668, 0.011993271164532514, 0.0075454282313470915]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 220 	 Test accuracy: 77.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 221 	 Test accuracy: 72.23 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 222 	 Test accuracy: 73.82 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 223 	 Test accuracy: 77.39 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 224 	 Test accuracy: 79.34 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 225 	 Test accuracy: 72.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 226 	 Test accuracy: 78.38000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 227 	 Test accuracy: 71.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 228 	 Test accuracy: 73.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 229 	 Test accuracy: 71.63000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:39, 19.57s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.27s/it]100%|██████████| 3/3 [00:52<00:00, 17.31s/it]100%|██████████| 3/3 [00:52<00:00, 17.55s/it]


scaleA
 [0.018756580451194802, 0.0077577496894935165, 0.007813325805746285, 0.011973843333206391, 0.0041726974281522874, 0.005577531202695486, 0.004918862313829218, 0.010013341985436217, 0.003006181232712579, 0.0026214884039011655, 0.010879926865656262, 0.01565452911772072, 0.00794417707272467, 0.021950173629011447, 0.013314647829258244, 0.018909697705141847, 0.010833892307511125, 0.014943435124380735]
scaleW
 [0.1195284366333574, 0.101261306456982, 0.11944643438500423, 0.10345933834977793, 0.07368041388657885, 0.04299491847767776, 0.055456031395319794, 0.04655039653054562, 0.02742266346906183, 0.0019160055823658744, 0.06568697763630967, 0.04535008886707792, 0.02757182782072229, 0.028160712315564867, 0.02759491549376351, 0.022953364050838875, 0.02052695796464248, 0.011972371977997808]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 230 	 Test accuracy: 76.53 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 231 	 Test accuracy: 78.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 232 	 Test accuracy: 76.39 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 233 	 Test accuracy: 75.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 234 	 Test accuracy: 77.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 235 	 Test accuracy: 75.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 236 	 Test accuracy: 72.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 237 	 Test accuracy: 77.35 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 238 	 Test accuracy: 77.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 239 	 Test accuracy: 75.33999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:21<00:42, 21.05s/it] 67%|██████▋   | 2/3 [00:42<00:21, 21.23s/it]100%|██████████| 3/3 [01:04<00:00, 21.46s/it]100%|██████████| 3/3 [01:04<00:00, 21.40s/it]


scaleA
 [0.01224564914281224, 0.004423262610289142, 0.006364287823537044, 0.006246912036392112, 0.003388183105572778, 0.006016683783343388, 0.0033585605755411907, 0.010063829212695753, 0.008110878878394269, 0.012956873442704506, 0.005618039488505822, 0.008516750740576885, 0.009203150655969647, 0.023785820422550497, 0.013522241446829286, 0.016942976878929466, 0.008157136033601986, 0.00858116047697957]
scaleW
 [0.08223563571771432, 0.10622789981095625, 0.12322919270909354, 0.030590283570255075, 0.0842575485899932, 0.050261652008392575, 0.044427752294395544, 0.04826950893638877, 0.05724566984728974, 0.043575330069248096, 0.046983838434997004, 0.023667589641317988, 0.03177966955511924, 0.03235974362775131, 0.02711933857591044, 0.02165822503062793, 0.014047706827538411, 0.006901888281103306]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 240 	 Test accuracy: 75.46000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 241 	 Test accuracy: 71.54 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 242 	 Test accuracy: 76.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 243 	 Test accuracy: 80.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 244 	 Test accuracy: 67.4 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 245 	 Test accuracy: 75.85 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 246 	 Test accuracy: 77.46 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 247 	 Test accuracy: 76.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 248 	 Test accuracy: 79.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 249 	 Test accuracy: 77.86999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:22<00:45, 22.72s/it] 67%|██████▋   | 2/3 [00:41<00:20, 20.39s/it]100%|██████████| 3/3 [01:01<00:00, 20.00s/it]100%|██████████| 3/3 [01:01<00:00, 20.35s/it]


scaleA
 [0.01519347711815367, 0.006261326137516489, 0.0075467787039972395, 0.010227259639188831, 0.005575264624269403, 0.005904400810354707, 0.004916518286981009, 0.008417371652166602, 0.003249226257929455, 0.0070499563049982, 0.004519362170013736, 0.006081900089243527, 0.00650981938778572, 0.015301616453882156, 0.010408024907978167, 0.012791922943877515, 0.007408039557758074, 0.01263804104087137]
scaleW
 [0.09102433108934908, 0.08680619710649018, 0.13104680807535232, 0.07460819032949569, 0.07966115026047213, 0.054039703202555245, 0.04399782259144127, 0.03990119906979266, 0.028471590322788027, 0.015311302239812766, 0.02760333746120543, 0.013861019883608898, 0.018783706976163852, 0.019954538719572132, 0.0211313736742408, 0.015847472973416606, 0.011770131086040773, 0.009713091883886022]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 250 	 Test accuracy: 75.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 251 	 Test accuracy: 76.55999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 252 	 Test accuracy: 78.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 253 	 Test accuracy: 78.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 254 	 Test accuracy: 75.71 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 255 	 Test accuracy: 82.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 256 	 Test accuracy: 78.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 257 	 Test accuracy: 80.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 258 	 Test accuracy: 69.3 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 259 	 Test accuracy: 79.84 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:39, 19.69s/it] 67%|██████▋   | 2/3 [00:37<00:18, 18.71s/it]100%|██████████| 3/3 [01:01<00:00, 20.98s/it]100%|██████████| 3/3 [01:01<00:00, 20.48s/it]


scaleA
 [0.02089120982850731, 0.007649826752241895, 0.008631321775278927, 0.01286907727415531, 0.007842518428977067, 0.00730120511230549, 0.007312121238556099, 0.012658432806614169, 0.008096740264451447, 0.010529356581892689, 0.008737223914898562, 0.01062210864175519, 0.008166232621808614, 0.02297314329330741, 0.010545254599697936, 0.01469850919130943, 0.009907563944143568, 0.012911317741996714]
scaleW
 [0.14659551237697646, 0.12299941650645392, 0.137587891662293, 0.09290001737113229, 0.11024902549166941, 0.06678793708725018, 0.08187223452945704, 0.05720969644744112, 0.04732401771536995, 0.03217889162198074, 0.06614418072740563, 0.03331148228435802, 0.031013109471112566, 0.031449032143034274, 0.02227650684415024, 0.019650245319137897, 0.018489478041490374, 0.012536931188539852]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 260 	 Test accuracy: 80.36999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 261 	 Test accuracy: 80.85 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 262 	 Test accuracy: 77.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 263 	 Test accuracy: 78.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 264 	 Test accuracy: 79.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 265 	 Test accuracy: 82.67 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 266 	 Test accuracy: 79.03999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 267 	 Test accuracy: 78.66 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 268 	 Test accuracy: 77.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 269 	 Test accuracy: 78.9 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:39, 19.99s/it] 67%|██████▋   | 2/3 [00:40<00:20, 20.27s/it]100%|██████████| 3/3 [00:56<00:00, 18.35s/it]100%|██████████| 3/3 [00:56<00:00, 18.85s/it]


scaleA
 [0.017984984976861736, 0.00794219037122798, 0.011411440508824484, 0.012615811826148819, 0.002857112445179936, 0.0035142251421538344, 0.004715848439896805, 0.008218605876219079, 0.009684593478708056, 0.011363325680867231, 0.005116307760499081, 0.007343680952418588, 0.009503324787825753, 0.018858218250730852, 0.009948624046074975, 0.01114153665175884, 0.009920594092532849, 0.013626584601970857]
scaleW
 [0.09760837287321704, 0.09492920233306752, 0.13957452274611643, 0.09857937328245452, 0.08546937292069706, 0.03711669800972182, 0.05942087165433398, 0.04042844774981808, 0.06039372008124544, 0.04132547354789532, 0.04157467126043909, 0.013663495522322615, 0.03792618515817604, 0.031254121564480174, 0.022230773638510292, 0.01637160301169302, 0.021389766354491687, 0.011783613902080133]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 270 	 Test accuracy: 77.07000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 271 	 Test accuracy: 79.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 272 	 Test accuracy: 80.39 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 273 	 Test accuracy: 81.82000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 274 	 Test accuracy: 79.67 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 275 	 Test accuracy: 80.21000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 276 	 Test accuracy: 80.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 277 	 Test accuracy: 82.35 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 278 	 Test accuracy: 82.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 279 	 Test accuracy: 82.8 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:30, 15.31s/it] 67%|██████▋   | 2/3 [00:31<00:15, 15.82s/it]100%|██████████| 3/3 [00:51<00:00, 17.92s/it]100%|██████████| 3/3 [00:51<00:00, 17.32s/it]


scaleA
 [0.028948052305266137, 0.010674309589168464, 0.013152687383786771, 0.01728122545172529, 0.010785038520142584, 0.012363690762762808, 0.008873286260957, 0.015707211517463803, 0.012765800679935336, 0.014588008366513514, 0.010767110996091206, 0.014148956546541814, 0.009057027270364509, 0.021498755406946807, 0.019698560791103385, 0.023327325512003384, 0.016069974664017363, 0.019160220491085653]
scaleW
 [0.19682385523065618, 0.1634566047264077, 0.19705875335749326, 0.1656614228077423, 0.15557392115741683, 0.12980281005447922, 0.0980216647091647, 0.08135368565942692, 0.08022587268349635, 0.0523217810145564, 0.07656584514689879, 0.04775879962481472, 0.038007326464319806, 0.031472026606400215, 0.04021171118201023, 0.029195122356939742, 0.03536835321081471, 0.014433360817941185]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 280 	 Test accuracy: 81.6 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 281 	 Test accuracy: 82.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 282 	 Test accuracy: 83.04 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 283 	 Test accuracy: 78.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 284 	 Test accuracy: 82.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 285 	 Test accuracy: 83.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 286 	 Test accuracy: 82.35 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 287 	 Test accuracy: 82.62 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 288 	 Test accuracy: 81.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 289 	 Test accuracy: 81.23 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.04s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.55s/it]100%|██████████| 3/3 [00:52<00:00, 17.34s/it]100%|██████████| 3/3 [00:52<00:00, 17.66s/it]


scaleA
 [0.030355881994285575, 0.011923718739222012, 0.014866435632072869, 0.017918405198231332, 0.00787385886449026, 0.010283695941888597, 0.008999648346179402, 0.013716452993690722, 0.007551617419049417, 0.008805800684103788, 0.0117114398159691, 0.014698163754451423, 0.010852105101767678, 0.026198013264630504, 0.015816104026687258, 0.0190091722914492, 0.012324210232107216, 0.0166736897267613]
scaleW
 [0.18925137079386525, 0.18389726349215632, 0.1960375228658723, 0.14667361404499207, 0.1138270847183371, 0.11509760583663665, 0.1089728180409207, 0.06378750566890339, 0.05748086924913665, 0.02526709241514243, 0.06998910877086047, 0.045915165589755634, 0.0445900249220082, 0.04089547431384546, 0.03411149632403935, 0.02792916309061888, 0.030576226613338513, 0.01073500828068273]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 290 	 Test accuracy: 83.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 291 	 Test accuracy: 79.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 292 	 Test accuracy: 82.52000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 293 	 Test accuracy: 84.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 294 	 Test accuracy: 83.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 295 	 Test accuracy: 84.39999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 296 	 Test accuracy: 85.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 297 	 Test accuracy: 81.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 298 	 Test accuracy: 79.46 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 299 	 Test accuracy: 83.36 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:21<00:43, 21.67s/it] 67%|██████▋   | 2/3 [00:40<00:19, 19.93s/it]100%|██████████| 3/3 [00:59<00:00, 19.46s/it]100%|██████████| 3/3 [00:59<00:00, 19.77s/it]


scaleA
 [0.017523665775570477, 0.006867116100107772, 0.008464477226713148, 0.009356039502056273, 0.006661563743992509, 0.006572339150023244, 0.00516807300561859, 0.008251227611630852, 0.008148773782118318, 0.009846335668580088, 0.008374323273765671, 0.009760449111784718, 0.0063559896869487325, 0.017439983222128266, 0.01141430175831977, 0.019395625772174532, 0.0166787908516158, 0.014661495995551152]
scaleW
 [0.11053920903575266, 0.1110689127143843, 0.1480694823910757, 0.0632957542063039, 0.11125054611640077, 0.06858422968619132, 0.051568592842667155, 0.04670313029499613, 0.04971130118559871, 0.028780831358651986, 0.056097800633953844, 0.02912002913275556, 0.02734005360205703, 0.02832975742017321, 0.02936152043695961, 0.02709812732741194, 0.03539417662750181, 0.012504601224309762]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 300 	 Test accuracy: 81.55 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 301 	 Test accuracy: 83.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 302 	 Test accuracy: 82.15 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 303 	 Test accuracy: 83.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 304 	 Test accuracy: 83.57 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 305 	 Test accuracy: 84.34 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 306 	 Test accuracy: 83.91999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 307 	 Test accuracy: 83.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 308 	 Test accuracy: 84.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 309 	 Test accuracy: 84.88 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.04s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.59s/it]100%|██████████| 3/3 [00:56<00:00, 19.01s/it]100%|██████████| 3/3 [00:56<00:00, 18.78s/it]


scaleA
 [0.018963308071089778, 0.00695744995859773, 0.00646349694811145, 0.00952838842963989, 0.00497447079486306, 0.0067850232639621415, 0.0045564877707181956, 0.007772370238274449, 0.008916165402038254, 0.00858142400997044, 0.0029359814425421256, 0.005744167862429474, 0.007177627938868509, 0.013638582963522904, 0.009750159935369923, 0.011597802050612569, 0.007354625633258455, 0.008972269837031444]
scaleW
 [0.1037868995550544, 0.09494488115118811, 0.11277858866264212, 0.07810852078806081, 0.1327229591599569, 0.0717558992024643, 0.05816248521439734, 0.05127947743164501, 0.06160572234034656, 0.03507604307479668, 0.03552168065574257, 0.021511478547882722, 0.03309635084645308, 0.025527620303853565, 0.02328705715585534, 0.016652809102473732, 0.013429232135551477, 0.007521902870195821]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 310 	 Test accuracy: 84.93 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 311 	 Test accuracy: 84.17999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 312 	 Test accuracy: 85.04 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 313 	 Test accuracy: 83.04 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 314 	 Test accuracy: 83.46000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 315 	 Test accuracy: 85.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 316 	 Test accuracy: 85.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 317 	 Test accuracy: 85.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 318 	 Test accuracy: 83.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 319 	 Test accuracy: 85.8 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:26<00:53, 27.00s/it] 67%|██████▋   | 2/3 [00:48<00:23, 23.85s/it]100%|██████████| 3/3 [01:04<00:00, 20.35s/it]100%|██████████| 3/3 [01:04<00:00, 21.63s/it]


scaleA
 [0.023233453334733506, 0.007380218669160611, 0.00994768003738639, 0.00858321486222192, 0.010109365036029284, 0.008224626702376949, 0.005957929558643976, 0.01036480036060982, 0.011187987386049952, 0.009757104590970992, 0.007870289087778383, 0.008142503400458634, 0.007862896832798763, 0.01612697485731637, 0.016752385386239885, 0.02257646398606232, 0.007765531421924152, 0.010535803800397583]
scaleW
 [0.12365453940476438, 0.1166750668639683, 0.13491112315256173, 0.08101782288457303, 0.1610714421787981, 0.08655355454772395, 0.07379107231096065, 0.05543143140832644, 0.058736889254446645, 0.04023831493558629, 0.05230362316937879, 0.030304332770468064, 0.032080708750530144, 0.026329926570553063, 0.040915539843214256, 0.03512453832340933, 0.019609671312031077, 0.009014204093045696]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 320 	 Test accuracy: 84.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 321 	 Test accuracy: 85.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 322 	 Test accuracy: 83.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 323 	 Test accuracy: 85.38 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 324 	 Test accuracy: 85.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 325 	 Test accuracy: 85.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 326 	 Test accuracy: 86.38 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 327 	 Test accuracy: 84.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 328 	 Test accuracy: 86.00999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 329 	 Test accuracy: 84.99 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:09<00:18,  9.35s/it] 67%|██████▋   | 2/3 [00:27<00:14, 14.30s/it]100%|██████████| 3/3 [00:45<00:00, 16.39s/it]100%|██████████| 3/3 [00:46<00:00, 15.35s/it]


scaleA
 [0.016090973226538238, 0.00537628513086152, 0.006461551845436358, 0.007005831640161215, 0.005942357203872796, 0.003629695786788413, 0.0041831018059595715, 0.007958974505738094, 0.005526970179752216, 0.004466913993185787, 0.00223208474255497, 0.001109153909247788, 0.006365312189195633, 0.009312454421247564, 0.0061191797779662814, 0.008703503800120917, 0.004022284554465776, 0.007569984476487619]
scaleW
 [0.1219854685515394, 0.11229709382083723, 0.1334609064471033, 0.06805014513000586, 0.09477434926328714, 0.06275069090343832, 0.06309130416922328, 0.04709364523866855, 0.03937396157219676, 0.01809108851269618, 0.0342515014432013, 0.0018767744169617972, 0.025794254774784836, 0.019676790307680717, 0.01049930507802827, 0.014951131002091911, 0.007938898478149136, 0.0032549433434062264]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 330 	 Test accuracy: 86.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 331 	 Test accuracy: 86.61999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 332 	 Test accuracy: 85.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 333 	 Test accuracy: 87.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 334 	 Test accuracy: 85.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 383
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 335 	 Test accuracy: 86.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 336 	 Test accuracy: 85.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 337 	 Test accuracy: 85.50999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 338 	 Test accuracy: 86.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 339 	 Test accuracy: 84.83000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:22<00:44, 22.44s/it] 67%|██████▋   | 2/3 [00:41<00:20, 20.33s/it]100%|██████████| 3/3 [00:59<00:00, 19.42s/it]100%|██████████| 3/3 [00:59<00:00, 19.90s/it]


scaleA
 [0.022553611513349645, 0.008133857757712042, 0.00911558558025005, 0.01027310503736341, 0.009201124107514799, 0.008172400241959936, 0.005473435176741624, 0.010174294401994835, 0.002336977488711717, 0.0073069967762660545, 0.006037223647038718, 0.010576997085839972, 0.007678413282182296, 0.02064980917067757, 0.011088240653643071, 0.01395092048599877, 0.007333244422253468, 0.013547793056079087]
scaleW
 [0.11565832019190075, 0.11043818401249177, 0.12385293715679917, 0.06418505936956354, 0.1337474918765061, 0.08459014044743694, 0.05425560290626147, 0.05115486060767551, 0.03905471849310299, 0.03022380808274902, 0.0588571816003488, 0.03826463131026559, 0.032082833077529196, 0.03475816337571375, 0.02507575497427891, 0.021980334112671727, 0.017964853566381882, 0.012065909971299235]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 340 	 Test accuracy: 86.33 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 341 	 Test accuracy: 86.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 342 	 Test accuracy: 86.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 343 	 Test accuracy: 86.35000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 344 	 Test accuracy: 87.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 345 	 Test accuracy: 85.92999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 346 	 Test accuracy: 86.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 347 	 Test accuracy: 86.71 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 348 	 Test accuracy: 87.27000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 349 	 Test accuracy: 87.03999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:41, 20.76s/it] 67%|██████▋   | 2/3 [00:36<00:17, 18.00s/it]100%|██████████| 3/3 [00:55<00:00, 18.34s/it]100%|██████████| 3/3 [00:55<00:00, 18.53s/it]


scaleA
 [0.026677136994805634, 0.008231930727792871, 0.011872371612896329, 0.014804419350511569, 0.008687823468251291, 0.009842937400302365, 0.010700577225074781, 0.015174463658307158, 0.011937530005895555, 0.011965438547550023, 0.005734236537651027, 0.009153361685994697, 0.01108913493151612, 0.023874995754674774, 0.020695174447293022, 0.02176803936925299, 0.01453666017928506, 0.016711930336586217]
scaleW
 [0.1859082181653711, 0.14056421864411775, 0.1851911471265449, 0.13920786440983113, 0.212238416090647, 0.12002747548063515, 0.1303142559356817, 0.09192833872206833, 0.0821191903452828, 0.0459641364575025, 0.05587434429216657, 0.031097750913969633, 0.04640291498733567, 0.041945983438590066, 0.04812067030839882, 0.03571072188112783, 0.03546174480711494, 0.017627402357260437]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 350 	 Test accuracy: 86.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 351 	 Test accuracy: 86.57000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 352 	 Test accuracy: 87.02 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 353 	 Test accuracy: 87.4 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 354 	 Test accuracy: 86.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 355 	 Test accuracy: 86.98 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 356 	 Test accuracy: 87.1 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 357 	 Test accuracy: 87.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 358 	 Test accuracy: 87.6 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 359 	 Test accuracy: 87.58 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.28s/it] 67%|██████▋   | 2/3 [00:38<00:19, 19.10s/it]100%|██████████| 3/3 [00:53<00:00, 17.40s/it]100%|██████████| 3/3 [00:53<00:00, 18.00s/it]


scaleA
 [0.019387661674165797, 0.005486480235412597, 0.009321989653784049, 0.00879856833557139, 0.00607222865607765, 0.008145136526098133, 0.006455147232987561, 0.012712999353121111, 0.007214997431521521, 0.009000639380346169, 0.009950103786984637, 0.011125457433994112, 0.007877426746119425, 0.02167420610329557, 0.015722737946942778, 0.016373373922232575, 0.005111893764226748, 0.00961992384245819]
scaleW
 [0.11534991809496868, 0.10009168786695848, 0.17146677252636044, 0.11173067197622714, 0.1355214078214894, 0.09935810268009432, 0.07330208240442387, 0.06925297740466747, 0.050939235492453744, 0.03769454496111683, 0.06992338759659397, 0.039347292306708116, 0.03710237759725859, 0.03689703085739224, 0.03686291749667541, 0.024603514957657373, 0.014967860442954508, 0.007697060557628008]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 360 	 Test accuracy: 87.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 361 	 Test accuracy: 87.64999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 362 	 Test accuracy: 87.6 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 363 	 Test accuracy: 87.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 364 	 Test accuracy: 87.35000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 365 	 Test accuracy: 87.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 366 	 Test accuracy: 87.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 367 	 Test accuracy: 87.72999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 368 	 Test accuracy: 87.82 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 369 	 Test accuracy: 87.89 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:21<00:43, 21.93s/it] 67%|██████▋   | 2/3 [00:41<00:20, 20.72s/it]100%|██████████| 3/3 [01:03<00:00, 20.94s/it]100%|██████████| 3/3 [01:03<00:00, 21.02s/it]


scaleA
 [0.025774707609367144, 0.009721140987874646, 0.014028643976717861, 0.015090631108482596, 0.009988308670111261, 0.00943251439754164, 0.008067212463441957, 0.014243305599614653, 0.010049333087551066, 0.01241057428994427, 0.010636062040757921, 0.01527818649795457, 0.011454280742138404, 0.025985661955993344, 0.01488334941590415, 0.016702527161076435, 0.020166620638172206, 0.018763583108648677]
scaleW
 [0.16544665717345786, 0.17850026489902493, 0.20765438818496804, 0.1293998111081971, 0.16941797341568055, 0.10723195091413064, 0.10259451586937933, 0.08309933183192832, 0.06295984846023044, 0.05328757612433798, 0.09490078808541157, 0.05593265567857783, 0.05002401768452145, 0.04330116451374952, 0.03698944897263348, 0.029448940531372356, 0.04837448736192266, 0.016565116130891695]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 370 	 Test accuracy: 87.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 371 	 Test accuracy: 87.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 372 	 Test accuracy: 87.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 373 	 Test accuracy: 87.57000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 374 	 Test accuracy: 87.6 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 375 	 Test accuracy: 87.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 376 	 Test accuracy: 88.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 377 	 Test accuracy: 87.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 378 	 Test accuracy: 87.66000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 379 	 Test accuracy: 87.67 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.37s/it] 67%|██████▋   | 2/3 [00:40<00:20, 20.37s/it]100%|██████████| 3/3 [00:59<00:00, 19.63s/it]100%|██████████| 3/3 [00:59<00:00, 19.75s/it]


scaleA
 [0.0204412143916218, 0.007174024720581581, 0.011755606687197417, 0.013740852096255016, 0.01121375628586336, 0.011528423367258227, 0.00714261375379778, 0.011463581572267604, 0.013786987655273942, 0.013241704392170836, 0.010927122000945227, 0.01266692986111554, 0.009593623245157338, 0.023889772718416375, 0.008518185736475187, 0.01327976462497743, 0.009834328204338367, 0.010087932074384581]
scaleW
 [0.1718824152796529, 0.12073028635173803, 0.20701453571139117, 0.12508457276731968, 0.13744655452231577, 0.11347234735143001, 0.08347857502708789, 0.05857704509135964, 0.08454198317995028, 0.050048744991079606, 0.0733028662385331, 0.04197324341939578, 0.042894429874206386, 0.04475664849440605, 0.020855917054323946, 0.02433253109327918, 0.020032450292421945, 0.010418533800877419]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 380 	 Test accuracy: 87.96000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 381 	 Test accuracy: 87.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 382 	 Test accuracy: 87.96000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 383 	 Test accuracy: 87.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 384 	 Test accuracy: 87.9 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 385 	 Test accuracy: 87.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 386 	 Test accuracy: 87.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 387 	 Test accuracy: 87.82 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 388 	 Test accuracy: 87.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 389 	 Test accuracy: 87.72999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:31, 15.84s/it] 67%|██████▋   | 2/3 [00:33<00:17, 17.14s/it]100%|██████████| 3/3 [00:50<00:00, 16.95s/it]100%|██████████| 3/3 [00:50<00:00, 16.89s/it]


scaleA
 [0.03331489569649017, 0.010172648762978307, 0.013471017105401467, 0.01835846838732134, 0.014765174374059479, 0.013054368070142944, 0.009018590470251971, 0.016520114808514577, 0.01478149693334418, 0.01544493193556396, 0.014172783992698857, 0.017345621980973575, 0.012796802879772732, 0.02945251608331215, 0.01535418355433882, 0.01732676603569241, 0.012181072140481808, 0.01616507333863308]
scaleW
 [0.14946797082658897, 0.1501489220695129, 0.2362759511672442, 0.1808892823597614, 0.22248550466135905, 0.15038744941415016, 0.10707708550237206, 0.08602138033994294, 0.09707527315974286, 0.06554092225091775, 0.09783752865998395, 0.06723700680503968, 0.058565356379118305, 0.049894028459260546, 0.042407133576970256, 0.03038657731099376, 0.03118126111073795, 0.015925870277951674]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 390 	 Test accuracy: 87.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 391 	 Test accuracy: 87.83999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 392 	 Test accuracy: 88.03999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 393 	 Test accuracy: 87.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 394 	 Test accuracy: 87.98 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 395 	 Test accuracy: 88.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 396 	 Test accuracy: 87.98 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 397 	 Test accuracy: 87.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 398 	 Test accuracy: 87.87 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: False
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 399 	 Test accuracy: 88.05 %
The best checkpoint is loaded
Test accuracy: 88.11%
