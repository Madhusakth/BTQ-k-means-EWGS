dataset: cifar10	arch: resnet20_quant	num_workers: 4	seed: None	batch_size: 32	epochs: 400	optimizer_m: Adam	optimizer_q: Adam	lr_m: 0.001	lr_q: 1e-05	lr_m_end: 0.0	lr_q_end: 0.0	decay_schedule_m: 150-300	decay_schedule_q: 150-300	momentum: 0.9	weight_decay: 0.0001	lr_scheduler_m: cosine	lr_scheduler_q: cosine	gamma: 0.1	QWeightFlag: True	QActFlag: True	weight_levels: 256	act_levels: 256	baseline: False	bkwd_scaling_factorW: 0.0	bkwd_scaling_factorA: 0.0	use_hessian: True	update_every: 10	gpu_id: 0	log_dir: ../results/CIFAR10_ResNet50/W8A8_kmeans_comp_decomp_weighted_cv_12_pw_8/	load_pretrain: True	pretrain_path: ../results/ResNet20_CIFAR10/fp/checkpoint/best_checkpoint.pth	btq: True	training_flag: False	eval: False	weighted: True	cv_block_size: 12	pw_fc_block_size: 8	
Files already downloaded and verified
The number of parameters :  269940
Pretrained full precision weights are initialized
# total params: 269940
# model params: 269850
# quantizer params: 90
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): QBasicBlock(
      (conv1): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): QBasicBlock(
      (conv1): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 000 	 Test accuracy: 17.150000000000002 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 001 	 Test accuracy: 24.060000000000002 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 002 	 Test accuracy: 13.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 003 	 Test accuracy: 11.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 004 	 Test accuracy: 24.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 005 	 Test accuracy: 19.82 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 006 	 Test accuracy: 24.709999999999997 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 007 	 Test accuracy: 11.799999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 008 	 Test accuracy: 11.24 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 009 	 Test accuracy: 19.470000000000002 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:31, 15.61s/it] 67%|██████▋   | 2/3 [00:35<00:18, 18.39s/it]100%|██████████| 3/3 [00:49<00:00, 16.33s/it]100%|██████████| 3/3 [00:49<00:00, 16.62s/it]


scaleA
 [0.020597007824709343, 0.011398996221828201, 0.008061547215948492, 0.011370816559427427, 0.007263567518510986, 0.009362730813978482, 0.007116498174308421, 0.016447420146594283, 0.01152891205936899, 0.012770701017179526, 0.010699935752321687, 0.014287069843557683, 0.012324120910757283, 0.02540194713993416, 0.012863206338120955, 0.021210184820163836, 0.010304077021346206, 0.010023965689578194]
scaleW
 [0.1884620478859469, 0.16381281211347354, 0.1711739628802703, 0.10363116294601711, 0.19187112402567452, 0.09296019741115132, 0.08616311901473701, 0.08061379158340302, 0.07532268634486436, 0.04568919449840112, 0.07887331591700321, 0.04578102868841289, 0.048227772040285166, 0.04275747188232882, 0.032397185676282435, 0.03357126931301965, 0.020648213167011657, 0.0097769586557358]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 010 	 Test accuracy: 21.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 011 	 Test accuracy: 21.23 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 012 	 Test accuracy: 20.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 013 	 Test accuracy: 21.55 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 014 	 Test accuracy: 36.21 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 015 	 Test accuracy: 30.919999999999998 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 016 	 Test accuracy: 19.98 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 017 	 Test accuracy: 24.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 018 	 Test accuracy: 25.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 019 	 Test accuracy: 36.36 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.46s/it] 67%|██████▋   | 2/3 [00:30<00:14, 14.43s/it]100%|██████████| 3/3 [00:47<00:00, 15.65s/it]100%|██████████| 3/3 [00:47<00:00, 15.84s/it]


scaleA
 [0.018954202992536237, 0.010084186112411816, 0.009508996861986158, 0.012232929318019092, 0.006147141520738018, 0.00855804354688102, 0.006394145860819714, 0.014803027342881572, 0.009659991146143273, 0.013943644960609061, 0.011262952679290313, 0.012412199697517891, 0.010504041331733487, 0.02191700923465927, 0.01729478528059634, 0.015624264144170959, 0.007725911142173001, 0.007329526848126288]
scaleW
 [0.1818707833469572, 0.13450637032685234, 0.17280691795997924, 0.11179493924529764, 0.13960993301466654, 0.06212235061186432, 0.08401695951080212, 0.06630475986426708, 0.058315294875727564, 0.04011878481721343, 0.068164192741086, 0.03239997501702077, 0.03678702718039361, 0.02931848600230763, 0.02917212014061732, 0.019350380062278304, 0.012841318174020566, 0.006044117094011268]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 020 	 Test accuracy: 31.900000000000002 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 021 	 Test accuracy: 27.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 022 	 Test accuracy: 36.370000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 023 	 Test accuracy: 34.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 024 	 Test accuracy: 31.69 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 025 	 Test accuracy: 35.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 026 	 Test accuracy: 24.21 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 027 	 Test accuracy: 29.62 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 028 	 Test accuracy: 22.45 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 029 	 Test accuracy: 30.43 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:21<00:42, 21.48s/it] 67%|██████▋   | 2/3 [00:35<00:16, 16.82s/it]100%|██████████| 3/3 [00:53<00:00, 17.55s/it]100%|██████████| 3/3 [00:53<00:00, 17.83s/it]


scaleA
 [0.01744552993161268, 0.010499467821456358, 0.008279653306130466, 0.01234714511466614, 0.009145524918039495, 0.009818368461329443, 0.0063346384183197366, 0.012152153738288388, 0.007808170046871769, 0.011271490734386795, 0.005407992564295887, 0.010243698762590549, 0.01035368844837834, 0.02331552925541146, 0.012923930381094385, 0.016591360848904602, 0.018202574168152637, 0.013819346643518087]
scaleW
 [0.14480989699594268, 0.12682536331653765, 0.14762271320390838, 0.11936714146651169, 0.1608943117553333, 0.0798394087585252, 0.06256029613088819, 0.049466589429237685, 0.042100117780849135, 0.030962526548171537, 0.03970277896637057, 0.020241039363912777, 0.03586213031740607, 0.030778743748041543, 0.023097644964173575, 0.020607074701343635, 0.029194752511042615, 0.011710972754091534]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 030 	 Test accuracy: 22.470000000000002 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 031 	 Test accuracy: 32.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 032 	 Test accuracy: 29.470000000000002 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 033 	 Test accuracy: 24.69 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 034 	 Test accuracy: 35.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 035 	 Test accuracy: 33.07 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 036 	 Test accuracy: 28.77 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 037 	 Test accuracy: 31.330000000000002 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 038 	 Test accuracy: 37.480000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 039 	 Test accuracy: 43.85 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:30, 15.35s/it] 67%|██████▋   | 2/3 [00:32<00:16, 16.55s/it]100%|██████████| 3/3 [00:52<00:00, 17.79s/it]100%|██████████| 3/3 [00:52<00:00, 17.35s/it]


scaleA
 [0.01737383616091823, 0.00989874608059088, 0.007501983150267357, 0.011667091025349985, 0.005579227496634628, 0.00674501492455403, 0.006238106395603619, 0.012404722620258492, 0.01219082658298678, 0.015545560242079941, 0.011583653604506023, 0.016779174361705593, 0.009004194251221702, 0.022816241999363673, 0.010283423203861278, 0.01671895456379809, 0.01603388300367471, 0.013931890491303786]
scaleW
 [0.15128463250996374, 0.1381369362572975, 0.15261400558962945, 0.08281996051452371, 0.1287554722890003, 0.04574177796856813, 0.06933593542713137, 0.05352357463517928, 0.06526344418559273, 0.044738946888466656, 0.06938293128280457, 0.04241829079728456, 0.0314722368339081, 0.030039876504436725, 0.018634663818967057, 0.0182962579424594, 0.027403180185630944, 0.011985974852506373]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 040 	 Test accuracy: 33.29 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 041 	 Test accuracy: 40.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 042 	 Test accuracy: 42.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 043 	 Test accuracy: 42.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 044 	 Test accuracy: 28.24 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 045 	 Test accuracy: 34.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 046 	 Test accuracy: 36.370000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 047 	 Test accuracy: 21.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 048 	 Test accuracy: 29.659999999999997 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 049 	 Test accuracy: 28.7 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:30, 15.35s/it] 67%|██████▋   | 2/3 [00:29<00:14, 14.64s/it]100%|██████████| 3/3 [00:51<00:00, 18.11s/it]100%|██████████| 3/3 [00:51<00:00, 17.26s/it]


scaleA
 [0.01003252765729432, 0.005294577418463405, 0.006852151800500855, 0.008969095063747474, 0.002891413226319292, 0.004885552180983427, 0.004811336971547169, 0.008612040767443811, 0.0024633629969405438, 0.008907642306900145, 0.004415118161086485, 0.010343074932933159, 0.008116848121855461, 0.01756283236082498, 0.014020425299256506, 0.018767745677992113, 0.01179681865027462, 0.013507535716621248]
scaleW
 [0.0830604664177984, 0.0668335992827039, 0.13137048735331927, 0.06123405358311581, 0.07135635176012813, 0.03117969280998194, 0.04947930365261124, 0.03820390873766937, 0.02736857917477963, 0.023840853903594156, 0.027976119903809025, 0.020429517812350403, 0.023626859801509064, 0.023010010314282386, 0.024177262005742692, 0.01902144945900606, 0.01780340481380098, 0.01207750578129181]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 050 	 Test accuracy: 45.989999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 051 	 Test accuracy: 42.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 052 	 Test accuracy: 33.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 053 	 Test accuracy: 39.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 054 	 Test accuracy: 30.380000000000003 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 055 	 Test accuracy: 41.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 056 	 Test accuracy: 39.62 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 057 	 Test accuracy: 42.15 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 058 	 Test accuracy: 35.620000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 059 	 Test accuracy: 35.28 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:34, 17.17s/it] 67%|██████▋   | 2/3 [00:36<00:18, 18.21s/it]100%|██████████| 3/3 [00:55<00:00, 18.76s/it]100%|██████████| 3/3 [00:55<00:00, 18.52s/it]


scaleA
 [0.018771236999028173, 0.009611734139099713, 0.0062544207584787756, 0.01140559944584378, 0.004743621748215969, 0.00892607671333079, 0.006698801275490055, 0.012839029108359072, 0.007662406142995311, 0.010402665882552635, 0.009621069711032831, 0.011759831031387467, 0.010264836699608986, 0.02635110517119489, 0.016566331830564426, 0.019940687050954156, 0.015633253168834797, 0.01263222617436916]
scaleW
 [0.14744680473857588, 0.12232876459741782, 0.11215212519814066, 0.07067315047666438, 0.10283740622325381, 0.05337231368602994, 0.07185500064822116, 0.048481869171791314, 0.04020733689640296, 0.029076259478291122, 0.04609869176871362, 0.025393201143321886, 0.032929339138306084, 0.03138860598755896, 0.029231551113643048, 0.021470081862210402, 0.024203594178035807, 0.006131801406929233]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 060 	 Test accuracy: 35.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 061 	 Test accuracy: 44.57 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 062 	 Test accuracy: 38.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 063 	 Test accuracy: 49.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 064 	 Test accuracy: 40.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 065 	 Test accuracy: 43.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 066 	 Test accuracy: 44.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 067 	 Test accuracy: 50.64999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 068 	 Test accuracy: 54.120000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 069 	 Test accuracy: 44.96 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:31, 15.60s/it] 67%|██████▋   | 2/3 [00:33<00:16, 16.80s/it]100%|██████████| 3/3 [00:54<00:00, 18.70s/it]100%|██████████| 3/3 [00:54<00:00, 18.09s/it]


scaleA
 [0.017558739137272305, 0.00915475276652498, 0.009094460292635961, 0.013328743171480579, 0.006589814752549386, 0.008343337584235585, 0.005010704913363186, 0.01026531044451603, 0.006434967301212252, 0.006824415232925701, 0.005877579517444203, 0.009427790045520077, 0.008024489618701404, 0.01760207557257123, 0.012484379968757823, 0.02257519933103531, 0.019653460072024648, 0.017469010772963575]
scaleW
 [0.10574515457675408, 0.10330998504879206, 0.12904302731979725, 0.11779599312154454, 0.09979270200896688, 0.05509819668400189, 0.06025837002786829, 0.04316286519466994, 0.039422199928222025, 0.015147898481724204, 0.038865667300067804, 0.01980619691895256, 0.02125002373732778, 0.019504904190995594, 0.020815878094538682, 0.021765827636246227, 0.030519082511782203, 0.014892496220788838]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 070 	 Test accuracy: 35.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 071 	 Test accuracy: 47.410000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 072 	 Test accuracy: 36.74 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 073 	 Test accuracy: 41.3 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 074 	 Test accuracy: 48.51 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 075 	 Test accuracy: 35.589999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 076 	 Test accuracy: 48.82 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 077 	 Test accuracy: 32.440000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 078 	 Test accuracy: 50.71 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 079 	 Test accuracy: 47.14 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.21s/it] 67%|██████▋   | 2/3 [00:34<00:16, 16.63s/it]100%|██████████| 3/3 [00:50<00:00, 16.76s/it]100%|██████████| 3/3 [00:51<00:00, 17.00s/it]


scaleA
 [0.01407946335272194, 0.007853078888419534, 0.006929530601712751, 0.010775509534733973, 0.005526005914915933, 0.009462063581715238, 0.005327675803987436, 0.012330029435389814, 0.008580094199195967, 0.012491363277345005, 0.008403907322680855, 0.01540273742877842, 0.007721242953685703, 0.018298474728221232, 0.011973962650298616, 0.015122421650101145, 0.013305434434806728, 0.009261786148123681]
scaleW
 [0.10157161477801463, 0.10314966032241117, 0.12074881770322361, 0.08354592051697489, 0.10187341316283445, 0.06120862557990673, 0.05571084509574564, 0.04491156896150728, 0.045087130589283896, 0.03307559914310231, 0.0499866291982091, 0.034018090162779985, 0.02731182606182959, 0.021411774611179348, 0.02019267136172369, 0.016766995422010118, 0.019068795423289545, 0.007266524968679786]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 080 	 Test accuracy: 27.169999999999998 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 081 	 Test accuracy: 51.32 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 082 	 Test accuracy: 47.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 083 	 Test accuracy: 51.85999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 084 	 Test accuracy: 37.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 085 	 Test accuracy: 48.77 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 086 	 Test accuracy: 48.02 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 087 	 Test accuracy: 24.54 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 088 	 Test accuracy: 56.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 089 	 Test accuracy: 62.94 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:36, 18.22s/it] 67%|██████▋   | 2/3 [00:42<00:21, 21.59s/it]100%|██████████| 3/3 [01:00<00:00, 19.99s/it]100%|██████████| 3/3 [01:00<00:00, 20.10s/it]


scaleA
 [0.01139143870356249, 0.006069996448895838, 0.006699782217691887, 0.009501599084459968, 0.0013312727126583081, 0.005113924128304842, 0.0034699994841131654, 0.007832415747331423, 0.004841026729007364, 0.006952053251543109, 0.005106097054224379, 0.00907890761505017, 0.00856261380853386, 0.019684070193544248, 0.006611108187083262, 0.006497436745838303, 0.0013161002830086213, 0.00379830589118473]
scaleW
 [0.09579445301627583, 0.07535102960772808, 0.12070697325588836, 0.07963114086083233, 0.04953420720118993, 0.03201603420822539, 0.041770258672944226, 0.033999395487007575, 0.031993353663516515, 0.018898007068306848, 0.02944938516921657, 0.02027384533082543, 0.02776908937542255, 0.02500417844807511, 0.011961217200338548, 0.006521104620948324, 0.0, 0.0]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 090 	 Test accuracy: 38.440000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 091 	 Test accuracy: 53.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 092 	 Test accuracy: 46.32 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 093 	 Test accuracy: 42.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 094 	 Test accuracy: 50.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 095 	 Test accuracy: 55.67999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 096 	 Test accuracy: 52.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 097 	 Test accuracy: 56.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 098 	 Test accuracy: 63.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 099 	 Test accuracy: 28.96 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:22<00:44, 22.45s/it] 67%|██████▋   | 2/3 [00:38<00:18, 18.53s/it]100%|██████████| 3/3 [00:57<00:00, 18.75s/it]100%|██████████| 3/3 [00:57<00:00, 19.10s/it]


scaleA
 [0.010837589767697635, 0.006469995850153172, 0.005113590298494054, 0.009630867906707438, 0.004542019855270181, 0.007429698196119616, 0.003109541748107684, 0.0070318519565230895, 0.0046999749624812275, 0.005993886927936593, 0.0038189786999675694, 0.007429465869146141, 0.007202475042829719, 0.018996466429141438, 0.009021924478839373, 0.012959643709217905, 0.012396916231636482, 0.011574371319443963]
scaleW
 [0.09277469661083328, 0.09051343830613034, 0.08900111928036292, 0.07632932244485818, 0.09079253127653504, 0.05653091302128718, 0.03591034675651396, 0.033069051432210304, 0.025232964554177912, 0.01706043955618203, 0.025067198436680215, 0.017908053567137414, 0.023482997419341137, 0.02234145549962087, 0.01585745436405039, 0.01346450096210621, 0.01910824173939726, 0.008582708468567924]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 100 	 Test accuracy: 38.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 101 	 Test accuracy: 48.980000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 102 	 Test accuracy: 54.55 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 103 	 Test accuracy: 58.98 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 104 	 Test accuracy: 48.82 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 105 	 Test accuracy: 58.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 106 	 Test accuracy: 51.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 107 	 Test accuracy: 47.449999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 108 	 Test accuracy: 48.85 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 109 	 Test accuracy: 55.94 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.13s/it] 67%|██████▋   | 2/3 [00:36<00:17, 17.80s/it]100%|██████████| 3/3 [00:52<00:00, 17.03s/it]100%|██████████| 3/3 [00:52<00:00, 17.48s/it]


scaleA
 [0.016219349303552368, 0.009764821547819505, 0.00855512630435875, 0.0114909264915823, 0.00536994787695706, 0.007674372271199108, 0.005672996549627802, 0.010898812951290105, 0.006341001899497747, 0.007996967562411925, 0.007584290166926554, 0.012283458453054915, 0.009654649490769933, 0.023035719288528336, 0.011790773194139842, 0.01563864956170209, 0.017597297224883745, 0.01670730825652518]
scaleW
 [0.13443853160774336, 0.12749319345145885, 0.13536143297628825, 0.08129045014509902, 0.08981035312533558, 0.046700740829162236, 0.061241496420680996, 0.04512729422669806, 0.0367761467874671, 0.023125594745182425, 0.04700407916916299, 0.02827130769877137, 0.027954682316926573, 0.026271808684681968, 0.022057701417109, 0.016465709450821684, 0.026051875552481396, 0.01388740187069669]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 110 	 Test accuracy: 34.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 111 	 Test accuracy: 56.89999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 112 	 Test accuracy: 55.33 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 113 	 Test accuracy: 37.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 114 	 Test accuracy: 47.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 115 	 Test accuracy: 61.129999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 116 	 Test accuracy: 60.46 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 117 	 Test accuracy: 51.54 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 118 	 Test accuracy: 59.81999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 119 	 Test accuracy: 58.309999999999995 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.29s/it] 67%|██████▋   | 2/3 [00:42<00:21, 21.44s/it]100%|██████████| 3/3 [00:58<00:00, 18.97s/it]100%|██████████| 3/3 [00:58<00:00, 19.53s/it]


scaleA
 [0.010330662039005631, 0.0056717984737612, 0.006988554884925221, 0.009761163884032769, 0.004188714782516771, 0.006156385464901759, 0.0050626761656398156, 0.0113192866214806, 0.008620912139095521, 0.010584594237772438, 0.00956083047049504, 0.009884286861640997, 0.008743832630346622, 0.022848542342925538, 0.014062864932852482, 0.017863519357879793, 0.011942491264601209, 0.012554333756768976]
scaleW
 [0.08328129298926974, 0.07233970613448411, 0.10514349539280933, 0.05491575389582388, 0.08445992693376897, 0.041626933362783725, 0.05331265794530948, 0.04972114013143939, 0.05259306741984884, 0.03047222984362477, 0.05179083432895675, 0.019004377332068292, 0.026848163197174823, 0.026393231500559024, 0.02564783593625022, 0.01822844970332626, 0.01705239557028475, 0.010300883997970457]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 383
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 120 	 Test accuracy: 61.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 121 	 Test accuracy: 71.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 122 	 Test accuracy: 69.57 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 123 	 Test accuracy: 63.77 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 124 	 Test accuracy: 46.839999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 125 	 Test accuracy: 54.17999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 126 	 Test accuracy: 54.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 127 	 Test accuracy: 55.85 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 128 	 Test accuracy: 46.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 129 	 Test accuracy: 61.14000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.74s/it] 67%|██████▋   | 2/3 [00:33<00:16, 16.21s/it]100%|██████████| 3/3 [00:52<00:00, 17.66s/it]100%|██████████| 3/3 [00:52<00:00, 17.54s/it]


scaleA
 [0.009392946266750675, 0.004141864484901195, 0.004615301532388688, 0.007919449725632082, 0.0, 0.004512288289130526, 0.004549726756728378, 0.007963735499068885, 0.0023637324946930703, 0.006697425900804695, 0.002973474611449818, 0.0046014270661692384, 0.008975980684224337, 0.021259562055685837, 0.011810577268899622, 0.014886488239236528, 0.008453088433914768, 0.011336599123143202]
scaleW
 [0.07653656653597661, 0.06456524682015148, 0.08502247088300097, 0.06620929979693901, 0.03535761457442262, 0.026125631853166867, 0.04969426999419652, 0.03261626550351068, 0.013479422255864806, 0.01944867067947332, 0.024275572570689477, 0.006833961060933744, 0.031445193607109005, 0.02629732394427793, 0.01910945527733572, 0.01541176108279462, 0.013069213117596193, 0.006699166371125772]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 130 	 Test accuracy: 53.94 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 131 	 Test accuracy: 66.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 132 	 Test accuracy: 63.77 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 133 	 Test accuracy: 59.589999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 134 	 Test accuracy: 59.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 135 	 Test accuracy: 65.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 136 	 Test accuracy: 58.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 137 	 Test accuracy: 54.379999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 138 	 Test accuracy: 54.85 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 139 	 Test accuracy: 61.919999999999995 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:36, 18.04s/it] 67%|██████▋   | 2/3 [00:33<00:16, 16.74s/it]100%|██████████| 3/3 [00:54<00:00, 18.42s/it]100%|██████████| 3/3 [00:54<00:00, 18.11s/it]


scaleA
 [0.013259796575907241, 0.006701972720782225, 0.006930368940116813, 0.008369076426536065, 0.004248297010354664, 0.006153796777407922, 0.005554282943277235, 0.010083273185402525, 0.008704826641040596, 0.009260282900864808, 0.007059639430575103, 0.0065532357543950015, 0.0077028306653656375, 0.013547109557775413, 0.012250448708039484, 0.01841638844723464, 0.010718315939400957, 0.009376822898828215]
scaleW
 [0.08312269285428582, 0.0894584482519785, 0.10837159163190402, 0.0546483754705537, 0.069294175731685, 0.04259594827706145, 0.05803766994512758, 0.04704986093443964, 0.045904640487016125, 0.020340789929713457, 0.0334928314196982, 0.013750755868837332, 0.024248309040173752, 0.017007754639565276, 0.019006143151153027, 0.015808834406958787, 0.017176349604633403, 0.006239778443852523]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 140 	 Test accuracy: 59.089999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 141 	 Test accuracy: 66.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 142 	 Test accuracy: 61.57 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 143 	 Test accuracy: 57.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 144 	 Test accuracy: 62.57 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 145 	 Test accuracy: 60.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 146 	 Test accuracy: 61.839999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 147 	 Test accuracy: 56.67 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 148 	 Test accuracy: 65.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 149 	 Test accuracy: 64.75999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:14<00:28, 14.11s/it] 67%|██████▋   | 2/3 [00:33<00:16, 16.96s/it]100%|██████████| 3/3 [00:51<00:00, 17.69s/it]100%|██████████| 3/3 [00:51<00:00, 17.22s/it]


scaleA
 [0.014445527715308036, 0.007211799398823264, 0.007299241017962965, 0.009871493063352286, 0.0030026804771578295, 0.005834237336442282, 0.005391927975172908, 0.008852868784244199, 0.009662364262358754, 0.010305919890053567, 0.011252877954848242, 0.015495190681215612, 0.0063898492535234795, 0.015187141432947707, 0.012847600568551958, 0.018915279683271898, 0.010684205048587246, 0.011642194413918049]
scaleW
 [0.10285915484053454, 0.08512550826997821, 0.12815974820801798, 0.07608856575988665, 0.08208252953788817, 0.03549285073556414, 0.054744900668988426, 0.03621390473096872, 0.04594836660018364, 0.03176513624213315, 0.054925582010115014, 0.03489405353374419, 0.021195586468863825, 0.018999813234768802, 0.02460629038957461, 0.020409082435827692, 0.017598084363435355, 0.009206657303155933]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 150 	 Test accuracy: 64.23 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 151 	 Test accuracy: 58.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 152 	 Test accuracy: 56.93 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 153 	 Test accuracy: 70.45 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 383
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 154 	 Test accuracy: 46.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 155 	 Test accuracy: 59.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 156 	 Test accuracy: 58.77 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 157 	 Test accuracy: 60.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 158 	 Test accuracy: 66.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 159 	 Test accuracy: 55.63 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:31, 15.90s/it] 67%|██████▋   | 2/3 [00:34<00:17, 17.54s/it]100%|██████████| 3/3 [00:49<00:00, 16.51s/it]100%|██████████| 3/3 [00:49<00:00, 16.63s/it]


scaleA
 [0.011378760314341048, 0.005228033767703033, 0.005605806298286769, 0.009216928801157601, 0.002138685189649816, 0.005611529640057508, 0.0043238555725708915, 0.008082398778251109, 0.002801570365463831, 0.006001233586774971, 0.00935163639842457, 0.014726403794280063, 0.007579764974439918, 0.017395471614521592, 0.008560863975228858, 0.007514120631685423, 0.001984697583469464, 0.0011184546614465337]
scaleW
 [0.09139708449895767, 0.07784882762393584, 0.10442119104299619, 0.06719842793456682, 0.0693174185155442, 0.04219542352331471, 0.046410478038424276, 0.03612951477762911, 0.027512774673201675, 0.016282806778516692, 0.05129362780721048, 0.03194250125274057, 0.02536414692784317, 0.018834066780124368, 0.013853691372874581, 0.00675005732461647, 0.0035863124320489174, 0.0]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 160 	 Test accuracy: 64.01 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 161 	 Test accuracy: 55.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 162 	 Test accuracy: 68.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 163 	 Test accuracy: 62.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 164 	 Test accuracy: 46.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 165 	 Test accuracy: 55.66 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 166 	 Test accuracy: 63.51 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 167 	 Test accuracy: 67.77 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 168 	 Test accuracy: 58.720000000000006 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 169 	 Test accuracy: 57.230000000000004 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.75s/it] 67%|██████▋   | 2/3 [00:32<00:16, 16.02s/it]100%|██████████| 3/3 [00:48<00:00, 15.91s/it]100%|██████████| 3/3 [00:48<00:00, 16.22s/it]


scaleA
 [0.015734195029453054, 0.008029826369795762, 0.006781124874075818, 0.009956265605262539, 0.008164650063182824, 0.008241943568219346, 0.004797113247655718, 0.008656842986983194, 0.009627003334607588, 0.012383096277365536, 0.004803415644698887, 0.006368420438154647, 0.0056546047403264466, 0.012975720554275413, 0.010238618030140268, 0.008257570758693612, 0.0031986784047480475, 0.011135419004912253]
scaleW
 [0.1518061407080711, 0.1088562280732878, 0.11605318662099329, 0.08170043244161558, 0.11410870707747485, 0.05946991278927951, 0.0476328790977141, 0.03359133904105177, 0.04593424301132092, 0.037351040179338414, 0.03528276083732342, 0.010091667538618093, 0.017013740387263717, 0.017213496918684772, 0.018743148361596264, 0.009286902753124902, 0.0047745919441050146, 0.007839619826166579]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 170 	 Test accuracy: 50.74999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 171 	 Test accuracy: 68.58999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 172 	 Test accuracy: 61.419999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 173 	 Test accuracy: 59.830000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 174 	 Test accuracy: 65.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 175 	 Test accuracy: 64.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 176 	 Test accuracy: 59.589999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 177 	 Test accuracy: 52.12 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 178 	 Test accuracy: 72.11999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 179 	 Test accuracy: 50.01 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.80s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.49s/it]100%|██████████| 3/3 [00:55<00:00, 18.56s/it]100%|██████████| 3/3 [00:55<00:00, 18.42s/it]


scaleA
 [0.025564453494826066, 0.010971698734331433, 0.010028498555536836, 0.015998268363373345, 0.010048470302004247, 0.011590085325822862, 0.01074123978279314, 0.017789771237371018, 0.01280068700905658, 0.016088304669906385, 0.013951844893517473, 0.021596389508080002, 0.011854179813015878, 0.030975923518922904, 0.01643798465212784, 0.021083445096048734, 0.020604986485266635, 0.015652682026307107]
scaleW
 [0.16993455668782745, 0.1577905981439409, 0.18168849642883952, 0.1342669672603611, 0.15590641616154785, 0.0849309805234017, 0.10561949449421916, 0.06996173457322764, 0.06959422864043767, 0.048008486810462055, 0.08385212055061098, 0.048849985424482434, 0.039067548373878436, 0.03813392671849775, 0.029253437287143167, 0.025631832910559548, 0.03073088300265263, 0.011102025684953684]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 180 	 Test accuracy: 70.07 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 181 	 Test accuracy: 69.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 182 	 Test accuracy: 63.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 183 	 Test accuracy: 62.9 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 184 	 Test accuracy: 68.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 185 	 Test accuracy: 71.71 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 186 	 Test accuracy: 64.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 187 	 Test accuracy: 67.15 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 188 	 Test accuracy: 68.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 189 	 Test accuracy: 57.53 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:30, 15.02s/it] 67%|██████▋   | 2/3 [00:31<00:15, 15.92s/it]100%|██████████| 3/3 [00:51<00:00, 17.97s/it]100%|██████████| 3/3 [00:52<00:00, 17.34s/it]


scaleA
 [0.014315105425665805, 0.008566194954003625, 0.008156824637867589, 0.009910089042139893, 0.004639141629319257, 0.008290278247372765, 0.006689177639270082, 0.01180114704222382, 0.008884770730983574, 0.010232175203020472, 0.003551951833033983, 0.006185926550868106, 0.008836380961205868, 0.022059604013685796, 0.01254029708520901, 0.01646286278790775, 0.017565105898211475, 0.013098923812980818]
scaleW
 [0.13045795503427934, 0.10081022749864471, 0.13716061007841404, 0.07021517079021229, 0.08696867525968682, 0.05470252480411745, 0.07431369387682944, 0.05644001352676368, 0.056499579234247, 0.03310157486644468, 0.03436034100357036, 0.014599120603414608, 0.032860444454268944, 0.02909048946799195, 0.021157860163600144, 0.016589439876274256, 0.02720665533864755, 0.009755007063062995]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 190 	 Test accuracy: 65.84 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 191 	 Test accuracy: 70.54 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 192 	 Test accuracy: 58.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 193 	 Test accuracy: 67.35 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 194 	 Test accuracy: 66.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 195 	 Test accuracy: 61.12 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 196 	 Test accuracy: 66.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 197 	 Test accuracy: 73.32 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 198 	 Test accuracy: 69.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 199 	 Test accuracy: 63.53 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:23<00:46, 23.07s/it] 67%|██████▋   | 2/3 [00:37<00:17, 17.96s/it]100%|██████████| 3/3 [00:53<00:00, 16.89s/it]100%|██████████| 3/3 [00:53<00:00, 17.70s/it]


scaleA
 [0.02107825525786575, 0.009003083449585244, 0.009799614002777124, 0.013931742393345417, 0.007446168823512764, 0.009841375671436552, 0.006541775328386515, 0.011083264704870774, 0.009265308909386491, 0.009755907740281134, 0.006875085400243629, 0.007492006752418404, 0.009570026048495066, 0.021433217290820396, 0.015146604304656565, 0.021221263804796536, 0.010052368149280247, 0.007750309578592965]
scaleW
 [0.1632580272206684, 0.12063102067908327, 0.1512745976926064, 0.10826029308508311, 0.10783768636237255, 0.07437165583572959, 0.06732105718644488, 0.05010052635632278, 0.050232520189982734, 0.028221327931352416, 0.04916206119384728, 0.014444451245339185, 0.03257045769303255, 0.02744118293543067, 0.026670306498899458, 0.02195094903390941, 0.01860934499539604, 0.004580328594773853]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 200 	 Test accuracy: 64.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 201 	 Test accuracy: 66.10000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 202 	 Test accuracy: 63.85999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 203 	 Test accuracy: 72.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 204 	 Test accuracy: 56.71000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 205 	 Test accuracy: 72.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 206 	 Test accuracy: 62.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 207 	 Test accuracy: 60.260000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 208 	 Test accuracy: 80.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 209 	 Test accuracy: 73.17 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.08s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.32s/it]100%|██████████| 3/3 [00:59<00:00, 20.44s/it]100%|██████████| 3/3 [00:59<00:00, 19.89s/it]


scaleA
 [0.012851966323551406, 0.006000197058710753, 0.006914189093130072, 0.009537995079482326, 0.0034029201263335294, 0.0057347565908853725, 0.004859423710844236, 0.008267477614687742, 0.009424025762722667, 0.014488245851670523, 0.007879354260401905, 0.012973027403172665, 0.007195731926365367, 0.019361289406554984, 0.00773263853358935, 0.01493738753097489, 0.013381338315222924, 0.014272184238336663]
scaleW
 [0.1228915411889907, 0.07868966085380909, 0.11583157734217532, 0.07697968012412199, 0.07695785053824904, 0.04936693001193509, 0.05446109441952022, 0.02792709335183503, 0.04613812498662684, 0.046505935897564334, 0.05053186852687216, 0.03430421280414188, 0.023677768560834107, 0.01945848192733073, 0.01497606030667835, 0.017731975953381607, 0.02307717191373417, 0.011422342502059363]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 210 	 Test accuracy: 70.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 211 	 Test accuracy: 68.35 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 212 	 Test accuracy: 72.53 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 213 	 Test accuracy: 71.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 214 	 Test accuracy: 78.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 215 	 Test accuracy: 68.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 216 	 Test accuracy: 77.98 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 217 	 Test accuracy: 67.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 218 	 Test accuracy: 67.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 219 	 Test accuracy: 76.72 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:08<00:16,  8.37s/it] 67%|██████▋   | 2/3 [00:30<00:16, 16.21s/it]100%|██████████| 3/3 [00:46<00:00, 16.24s/it]100%|██████████| 3/3 [00:46<00:00, 15.46s/it]


scaleA
 [0.017552609310872287, 0.0067668272904130786, 0.007467507359554363, 0.01091452243034196, 0.004835122294195944, 0.005520334120992808, 0.005486650360230115, 0.008627574925579804, 0.009619136073867789, 0.009445853142359512, 0.005706102377919874, 0.010313290015153118, 0.007621880360268421, 0.01562348167452402, 0.008847381401231098, 0.011111510332676378, 0.006315861413655278, 0.010681338931052642]
scaleW
 [0.12326764878328907, 0.08987033689293039, 0.13302684301508796, 0.07658776134530818, 0.10018884796098033, 0.04348726482651397, 0.05747192644851306, 0.04328348991171851, 0.052473466789088076, 0.02784651758129329, 0.03271594403941982, 0.02247856375570539, 0.02633465327590719, 0.0200525130930393, 0.014642134040501064, 0.011878813064131202, 0.012331293719362119, 0.0081527260898903]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 220 	 Test accuracy: 72.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 221 	 Test accuracy: 74.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 222 	 Test accuracy: 76.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 223 	 Test accuracy: 67.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 224 	 Test accuracy: 71.55 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 225 	 Test accuracy: 74.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 226 	 Test accuracy: 64.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 227 	 Test accuracy: 71.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 228 	 Test accuracy: 77.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 229 	 Test accuracy: 71.69 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:39, 19.70s/it] 67%|██████▋   | 2/3 [00:36<00:18, 18.26s/it]100%|██████████| 3/3 [00:52<00:00, 17.16s/it]100%|██████████| 3/3 [00:52<00:00, 17.62s/it]


scaleA
 [0.019196220784432044, 0.01054972438566736, 0.010982534248541571, 0.013484150532034707, 0.004792088820365311, 0.007172578063174387, 0.007133203851189249, 0.010938542609684456, 0.008497169600220148, 0.009886350852259146, 0.009634282210398958, 0.013342563901977744, 0.009554887039726208, 0.021745628949517638, 0.011850364230651944, 0.019409152609672405, 0.014491301375631703, 0.0121657908082733]
scaleW
 [0.16041300883367363, 0.13824808566620153, 0.1746820760330423, 0.10651837378601232, 0.1124652025555319, 0.06390526990268354, 0.0769725681735172, 0.05364553486841983, 0.05409069493677754, 0.030732900449988266, 0.0515866963009452, 0.03565659843478916, 0.03675027898426995, 0.03376966473905003, 0.025749887004608955, 0.021213447090283933, 0.026678730940371046, 0.009342061220500502]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 230 	 Test accuracy: 75.62 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 231 	 Test accuracy: 73.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 232 	 Test accuracy: 68.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 233 	 Test accuracy: 73.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 234 	 Test accuracy: 72.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 235 	 Test accuracy: 79.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 236 	 Test accuracy: 74.53 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 237 	 Test accuracy: 73.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 238 	 Test accuracy: 72.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 239 	 Test accuracy: 76.42999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.72s/it] 67%|██████▋   | 2/3 [00:38<00:19, 19.57s/it]100%|██████████| 3/3 [00:58<00:00, 19.60s/it]100%|██████████| 3/3 [00:58<00:00, 19.52s/it]


scaleA
 [0.012363898306830509, 0.005296325815089411, 0.00591621194606957, 0.009369395874329006, 0.003062302422381227, 0.004181868210876356, 0.005728917503132817, 0.010835083158982607, 0.005973136221270264, 0.00676704270882469, 0.007264026328669485, 0.009202456009345626, 0.008656186058266707, 0.018230948991561125, 0.007556431382578654, 0.011622943056929532, 0.006209718007470395, 0.010432425932317057]
scaleW
 [0.09553404595667002, 0.08079805747386692, 0.11249824658448343, 0.08318397087839426, 0.08394088480446078, 0.037017777969210644, 0.06054431841571745, 0.051646443870632275, 0.03978825300813282, 0.023439434332821543, 0.0435465398779373, 0.021196093337091947, 0.03102127987588967, 0.020278086166019563, 0.018080639167072952, 0.011238026323834355, 0.013121989590611218, 0.008223752947157794]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 240 	 Test accuracy: 76.12 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 241 	 Test accuracy: 65.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 242 	 Test accuracy: 73.9 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 243 	 Test accuracy: 73.94 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 244 	 Test accuracy: 75.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 245 	 Test accuracy: 75.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 246 	 Test accuracy: 75.44999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 247 	 Test accuracy: 75.12 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 248 	 Test accuracy: 79.25999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 249 	 Test accuracy: 72.39 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:36, 18.08s/it] 67%|██████▋   | 2/3 [00:37<00:19, 19.13s/it]100%|██████████| 3/3 [00:54<00:00, 18.13s/it]100%|██████████| 3/3 [00:54<00:00, 18.30s/it]


scaleA
 [0.014952736731754799, 0.006485070355866364, 0.008596294004845776, 0.010903933132130124, 0.006173034260110348, 0.007748931733286124, 0.00481529488978911, 0.009095900025215644, 0.0074116172451864385, 0.010167771432694813, 0.01051207479045744, 0.014176619348289086, 0.009667535973516378, 0.025852894072009535, 0.010414477167575301, 0.020002019292335315, 0.020048424892362634, 0.019369656024487838]
scaleW
 [0.14381216181776216, 0.11070559876464026, 0.1205240331253908, 0.11482070799104338, 0.13243954154700796, 0.058161391779003556, 0.07122724351893518, 0.05087509732742085, 0.05317902335698599, 0.03519369991221089, 0.06722616974715018, 0.03603564494200071, 0.036786831076937455, 0.03535959118395248, 0.027867372342124146, 0.022705835932421797, 0.0378874401973145, 0.018015279235786184]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 250 	 Test accuracy: 74.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 251 	 Test accuracy: 76.4 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 252 	 Test accuracy: 76.34 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 253 	 Test accuracy: 75.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 254 	 Test accuracy: 76.96 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 255 	 Test accuracy: 74.77000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 256 	 Test accuracy: 72.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 257 	 Test accuracy: 75.35 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 258 	 Test accuracy: 78.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 259 	 Test accuracy: 73.61999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.21s/it] 67%|██████▋   | 2/3 [00:40<00:20, 20.16s/it]100%|██████████| 3/3 [00:58<00:00, 19.16s/it]100%|██████████| 3/3 [00:58<00:00, 19.45s/it]


scaleA
 [0.01462716039887218, 0.00659489798250426, 0.008304616036322444, 0.011101214904433275, 0.005631769988541594, 0.008762709768678344, 0.007237407602067684, 0.009955766122857637, 0.0099667141339433, 0.013854352871672733, 0.007575697592171043, 0.007479408923807968, 0.00954802714905705, 0.02189657641942608, 0.014604282961802885, 0.01768141566406192, 0.016844698401192414, 0.01556355507593407]
scaleW
 [0.09462248189081451, 0.09340856494493925, 0.13875815950072082, 0.10011434320402184, 0.13059730358450858, 0.07107121713708517, 0.08327692200072069, 0.06279196687890097, 0.06687508061575999, 0.04753500857005999, 0.052252638353237346, 0.021286143577608496, 0.035673698607956154, 0.029928338288288184, 0.027584585098931674, 0.021164085548100054, 0.028323151220217797, 0.014575536826801438]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 260 	 Test accuracy: 78.97999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 261 	 Test accuracy: 71.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 262 	 Test accuracy: 75.87 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 263 	 Test accuracy: 72.69 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 264 	 Test accuracy: 79.9 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 265 	 Test accuracy: 81.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 266 	 Test accuracy: 75.51 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 267 	 Test accuracy: 77.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 268 	 Test accuracy: 79.12 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 269 	 Test accuracy: 76.17 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:39, 19.92s/it] 67%|██████▋   | 2/3 [00:39<00:19, 19.56s/it]100%|██████████| 3/3 [00:56<00:00, 18.44s/it]100%|██████████| 3/3 [00:56<00:00, 18.79s/it]


scaleA
 [0.01511303544716582, 0.005819130981644358, 0.009545806994323688, 0.01171743916944902, 0.004577098278763817, 0.006862351645000171, 0.006280955924125679, 0.008752525323133774, 0.006860918687805528, 0.006910586176133868, 0.010530708426581064, 0.01274827480063298, 0.008754966484697107, 0.019781098772560134, 0.009000669237785974, 0.006568373026577534, 0.007807034875703503, 0.007251803174840535]
scaleW
 [0.11880023575455705, 0.06700450680509203, 0.12593974320836177, 0.07578786647459061, 0.10148666026197355, 0.06049511449075373, 0.06851419885957662, 0.04722818305641555, 0.04238011900421491, 0.022906935332229438, 0.061493380878254233, 0.03445011054649731, 0.03415694533282238, 0.028915234205104768, 0.019346162912357228, 0.013919391268830697, 0.012265796797112448, 0.006692899548602228]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 270 	 Test accuracy: 80.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 271 	 Test accuracy: 79.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 272 	 Test accuracy: 72.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 273 	 Test accuracy: 74.7 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 274 	 Test accuracy: 68.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 275 	 Test accuracy: 80.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 276 	 Test accuracy: 77.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 277 	 Test accuracy: 75.84 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 278 	 Test accuracy: 78.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 279 	 Test accuracy: 80.28999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:22<00:45, 22.89s/it] 67%|██████▋   | 2/3 [00:47<00:23, 23.76s/it]100%|██████████| 3/3 [01:08<00:00, 22.64s/it]100%|██████████| 3/3 [01:08<00:00, 22.87s/it]


scaleA
 [0.013269474223318012, 0.005997418710077071, 0.008421978267612996, 0.010345157898478048, 0.005464890358654348, 0.006303486269395575, 0.00534056957797138, 0.0086709639550224, 0.005031388056863756, 0.008600985120751694, 0.008365221035396275, 0.010343490032300106, 0.009706596009603318, 0.022877874477436708, 0.010265199316657593, 0.012947035808761255, 0.010667813785901502, 0.0107430321753195]
scaleW
 [0.14071099654469543, 0.10818838722498703, 0.17266500028748225, 0.11503153899493294, 0.1082073607995035, 0.05152814992715932, 0.06598650918527242, 0.0479813782409844, 0.034505624299045246, 0.0312730350727037, 0.06080002545208262, 0.032519200763192084, 0.03659201488605644, 0.032585557935722355, 0.0249212462864729, 0.016838019672628615, 0.01954865275828954, 0.0065600065075083385]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 280 	 Test accuracy: 81.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 281 	 Test accuracy: 80.53 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 282 	 Test accuracy: 77.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 283 	 Test accuracy: 70.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 284 	 Test accuracy: 77.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 285 	 Test accuracy: 81.08999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 286 	 Test accuracy: 76.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 287 	 Test accuracy: 83.07 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 288 	 Test accuracy: 80.66 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 289 	 Test accuracy: 77.25999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.20s/it] 67%|██████▋   | 2/3 [00:39<00:19, 19.74s/it]100%|██████████| 3/3 [00:57<00:00, 19.08s/it]100%|██████████| 3/3 [00:57<00:00, 19.32s/it]


scaleA
 [0.015603372493425137, 0.005521477344022969, 0.00827117875342222, 0.010942482533876363, 0.005688485081922712, 0.00735954616364726, 0.005983238170745732, 0.011314764527697462, 0.009658786475037586, 0.012199480586285914, 0.006959268806766048, 0.008880614238827323, 0.00915589381343242, 0.01843108827357994, 0.008135650033754696, 0.014002798159771053, 0.013615222148192933, 0.014579304269734888]
scaleW
 [0.11611588979911264, 0.0898362639306739, 0.1523369794401647, 0.07355401899820364, 0.11275314624981707, 0.057675248898581076, 0.06872897516535571, 0.05343353372704448, 0.07136096156514642, 0.04188661720009587, 0.0514654232344233, 0.025108413272501597, 0.035333347512319806, 0.031359840496021134, 0.01916193298789948, 0.018461612476059253, 0.030748241396103094, 0.014620967074531463]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 290 	 Test accuracy: 83.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 291 	 Test accuracy: 81.28999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 292 	 Test accuracy: 80.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 293 	 Test accuracy: 83.33 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 294 	 Test accuracy: 82.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 295 	 Test accuracy: 83.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 296 	 Test accuracy: 79.54 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 297 	 Test accuracy: 79.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 298 	 Test accuracy: 74.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 299 	 Test accuracy: 82.21000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:31, 15.88s/it] 67%|██████▋   | 2/3 [00:33<00:16, 16.95s/it]100%|██████████| 3/3 [00:51<00:00, 17.50s/it]100%|██████████| 3/3 [00:51<00:00, 17.26s/it]


scaleA
 [0.019321960218156967, 0.007932976879669644, 0.010756959241126606, 0.01177958533054606, 0.013218471640725253, 0.010925585987643581, 0.005911254580847634, 0.010990315102449888, 0.008165069905969413, 0.012517390617681262, 0.009196452858211456, 0.010537489526167655, 0.00876595184036674, 0.01468995211661298, 0.008796995403199124, 0.006811911133345685, 0.007353503680727201, 0.00864971339675846]
scaleW
 [0.11775968565743873, 0.10495777709782554, 0.12707617557716752, 0.10579226049438321, 0.19174837624842433, 0.10631668436277185, 0.06737128899646254, 0.04853738307863834, 0.05662044639940155, 0.0465702763936832, 0.056672974404998494, 0.030349327990195126, 0.03551368048579489, 0.02568201102053645, 0.018278484485272077, 0.012378037881661677, 0.01850380256714555, 0.007322879685932419]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 300 	 Test accuracy: 82.16 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 301 	 Test accuracy: 81.62 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 302 	 Test accuracy: 83.94 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 303 	 Test accuracy: 81.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 304 	 Test accuracy: 80.32000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 305 	 Test accuracy: 81.35 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 306 	 Test accuracy: 84.3 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 307 	 Test accuracy: 85.02 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 308 	 Test accuracy: 80.33 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 309 	 Test accuracy: 84.44 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:16<00:33, 16.93s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.74s/it]100%|██████████| 3/3 [00:54<00:00, 18.54s/it]100%|██████████| 3/3 [00:54<00:00, 18.26s/it]


scaleA
 [0.026695147941682044, 0.010644501583785384, 0.01401460093660264, 0.016323738748166852, 0.006446224305381737, 0.009443435138291639, 0.008788409956046668, 0.015506955035927023, 0.013810835304106915, 0.014337992855175499, 0.010154596636432646, 0.012861842813304068, 0.011934154542727103, 0.02094754046850943, 0.018762566621869075, 0.025853563551712977, 0.015203833145326175, 0.010791013778444235]
scaleW
 [0.1930528954661064, 0.17459033875445995, 0.22265682618123694, 0.13850662380029002, 0.15018799250219803, 0.07107302782708966, 0.09510115291778369, 0.07977359547990819, 0.07743051767789612, 0.04721292583638794, 0.06857281161071566, 0.03371428215791781, 0.048688115492436124, 0.033125535778836236, 0.041736758099306166, 0.032080447770588244, 0.03470380608758359, 0.009169974854498759]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 310 	 Test accuracy: 84.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 311 	 Test accuracy: 82.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 312 	 Test accuracy: 84.54 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 313 	 Test accuracy: 83.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 314 	 Test accuracy: 84.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 315 	 Test accuracy: 81.32000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 316 	 Test accuracy: 83.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 317 	 Test accuracy: 81.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 318 	 Test accuracy: 84.78999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 319 	 Test accuracy: 85.54 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.39s/it] 67%|██████▋   | 2/3 [00:40<00:20, 20.47s/it]100%|██████████| 3/3 [00:56<00:00, 18.35s/it]100%|██████████| 3/3 [00:56<00:00, 18.93s/it]


scaleA
 [0.01940938807722112, 0.006961481287164668, 0.008214063845973542, 0.012970955312433148, 0.00930003105066093, 0.008951695546292241, 0.006755051311571046, 0.011940268748216654, 0.010348241948821231, 0.011920694077243702, 0.009553642686370347, 0.009517163390507464, 0.007903004059198039, 0.014338847935344763, 0.010489680005339501, 0.01450620995326686, 0.014717851347009828, 0.012381097169547781]
scaleW
 [0.11775590694345613, 0.11215082611455547, 0.15040584114208266, 0.11048129221576693, 0.14498433308640873, 0.0843453486364333, 0.08252016202584661, 0.060194032039586724, 0.06791512797063472, 0.04264443357580349, 0.06134439349264511, 0.028076005178131653, 0.030579740012323314, 0.02463795330584494, 0.026678207466098895, 0.0197603753330065, 0.031147426171591035, 0.00983768697397465]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 320 	 Test accuracy: 83.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 321 	 Test accuracy: 83.7 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 322 	 Test accuracy: 85.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 323 	 Test accuracy: 81.99 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 324 	 Test accuracy: 83.91999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 325 	 Test accuracy: 84.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 326 	 Test accuracy: 85.87 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 327 	 Test accuracy: 85.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 328 	 Test accuracy: 85.74000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 329 	 Test accuracy: 85.14 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:41, 20.96s/it] 67%|██████▋   | 2/3 [00:43<00:21, 21.95s/it]100%|██████████| 3/3 [00:59<00:00, 19.34s/it]100%|██████████| 3/3 [00:59<00:00, 19.96s/it]


scaleA
 [0.019157091706104426, 0.006980055686174586, 0.011792723128307888, 0.014688167002042028, 0.008557829221324148, 0.008462528182452685, 0.007986693923462565, 0.013134771064163277, 0.008204641244061188, 0.008711757337693844, 0.011955293050322979, 0.01721918240404575, 0.00932458876865015, 0.018121156996657218, 0.013235635636647277, 0.01406193975155689, 0.013531663637880364, 0.01511871389406847]
scaleW
 [0.14448485056343174, 0.11982719154269757, 0.19760496687907633, 0.15396461002625184, 0.1619033769807794, 0.07514245251103935, 0.07720328220817306, 0.06633289408551483, 0.04492320273535264, 0.0305716484422891, 0.0754005319576175, 0.05253986527753052, 0.039001245015181644, 0.03179121777467118, 0.030678558025799454, 0.02252205749766617, 0.025014971764219306, 0.011765410393569457]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 330 	 Test accuracy: 86.53999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 331 	 Test accuracy: 86.50999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 332 	 Test accuracy: 84.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 333 	 Test accuracy: 84.45 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 334 	 Test accuracy: 85.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 335 	 Test accuracy: 85.02 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 336 	 Test accuracy: 86.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 337 	 Test accuracy: 84.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 338 	 Test accuracy: 86.53 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 339 	 Test accuracy: 84.46000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:41, 20.95s/it] 67%|██████▋   | 2/3 [00:36<00:17, 17.89s/it]100%|██████████| 3/3 [00:57<00:00, 19.10s/it]100%|██████████| 3/3 [00:57<00:00, 19.09s/it]


scaleA
 [0.01723084296490403, 0.006982779995402594, 0.012634689156273199, 0.014510530022178315, 0.006697768441634722, 0.0063236591961302645, 0.00621806447233261, 0.010867461693664029, 0.005969140451646937, 0.00800455957067628, 0.011043161427216772, 0.01376987648637327, 0.009017950760206459, 0.021726105236421708, 0.011491166700995684, 0.014226331181860952, 0.007964801382212483, 0.008267985875602837]
scaleW
 [0.1664305156942225, 0.12102549653646864, 0.21468971071872664, 0.14579487704059202, 0.12393818081052731, 0.056893396916090695, 0.08301232211985342, 0.06131232260812456, 0.04902290303659548, 0.026460597721210354, 0.0754110660532946, 0.03852029704784136, 0.04334279882199732, 0.03750406810770644, 0.029569665159923902, 0.0223459922311532, 0.020514927753875097, 0.006313296177196659]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 340 	 Test accuracy: 85.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 341 	 Test accuracy: 86.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 342 	 Test accuracy: 85.6 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 343 	 Test accuracy: 86.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 344 	 Test accuracy: 85.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 345 	 Test accuracy: 85.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 346 	 Test accuracy: 86.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 347 	 Test accuracy: 86.74 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 348 	 Test accuracy: 86.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 349 	 Test accuracy: 85.91 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.80s/it] 67%|██████▋   | 2/3 [00:39<00:19, 19.86s/it]100%|██████████| 3/3 [00:57<00:00, 19.18s/it]100%|██████████| 3/3 [00:57<00:00, 19.27s/it]


scaleA
 [0.02166611722183084, 0.007395544896304051, 0.012216585316863279, 0.01365430237194431, 0.010039892397729185, 0.009695391321009985, 0.010135403790836361, 0.016210001350516152, 0.014100531336859406, 0.014583677268244244, 0.012431990619343816, 0.020214126290835775, 0.009851144837639056, 0.020994260254028077, 0.01263497582165112, 0.018005245884719, 0.015569528591196083, 0.020894447541046163]
scaleW
 [0.1677659274853437, 0.1292361385326305, 0.18876185304314194, 0.142967918591768, 0.18768584906050167, 0.0931678783406213, 0.11784311847477554, 0.0865043628618799, 0.08296017720457287, 0.059964984039653835, 0.08863954513099559, 0.06043094060827018, 0.04462249056767559, 0.03560535032305322, 0.03348838115411565, 0.028394291169108025, 0.041220618600646, 0.022123526744422594]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 350 	 Test accuracy: 86.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 351 	 Test accuracy: 87.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 352 	 Test accuracy: 86.42999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 353 	 Test accuracy: 86.8 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 354 	 Test accuracy: 87.07000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 355 	 Test accuracy: 86.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 356 	 Test accuracy: 87.21 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 357 	 Test accuracy: 86.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 358 	 Test accuracy: 87.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 359 	 Test accuracy: 86.99 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.17s/it] 67%|██████▋   | 2/3 [00:38<00:19, 19.18s/it]100%|██████████| 3/3 [00:56<00:00, 18.73s/it]100%|██████████| 3/3 [00:56<00:00, 18.86s/it]


scaleA
 [0.025867548221836914, 0.009380097883918718, 0.012139176551036768, 0.012805749073453348, 0.008646609065192023, 0.009634690372797962, 0.007571999028935458, 0.014042669976127813, 0.009692898027503144, 0.011922194343180299, 0.009062097743774138, 0.01489759163433805, 0.010533078077300436, 0.022751100397691307, 0.012954057045196914, 0.017841682567465836, 0.016740694853056935, 0.013513863509094705]
scaleW
 [0.1807987027607609, 0.14517200724012438, 0.2017699745757731, 0.13628121043632893, 0.1543542976743042, 0.09703507245957566, 0.08977931908027424, 0.07402283540278964, 0.06495562902150463, 0.04514645205115697, 0.07236859483618104, 0.041917823762866645, 0.04176898342366966, 0.03868434525094454, 0.03284061273745642, 0.0241342960965016, 0.0364518450658683, 0.01303140314518351]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 360 	 Test accuracy: 87.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 361 	 Test accuracy: 87.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 362 	 Test accuracy: 87.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 363 	 Test accuracy: 87.13 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 364 	 Test accuracy: 87.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 365 	 Test accuracy: 87.36 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 366 	 Test accuracy: 87.45 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 367 	 Test accuracy: 87.39 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 368 	 Test accuracy: 87.39 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 369 	 Test accuracy: 87.46000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:41, 20.82s/it] 67%|██████▋   | 2/3 [00:37<00:18, 18.62s/it]100%|██████████| 3/3 [00:59<00:00, 20.03s/it]100%|██████████| 3/3 [00:59<00:00, 19.88s/it]


scaleA
 [0.01893279435062057, 0.007626613333270971, 0.008712208214595627, 0.010648974830266868, 0.006870444183190074, 0.00768067160842032, 0.005794429435354544, 0.009558916862851683, 0.011730002899879981, 0.010629050679958984, 0.0075603543658964946, 0.007829222498128204, 0.007745907987877509, 0.015946725963283025, 0.011235061568016335, 0.014416297450444123, 0.00880269531882775, 0.007807736028892836]
scaleW
 [0.14578250832477127, 0.12729984244705125, 0.16387320498012528, 0.10082391325616603, 0.13333567452030903, 0.08710383286319201, 0.06801899444555226, 0.04935133906720728, 0.07488405395451805, 0.04319249051015988, 0.053673178869029003, 0.024937609024706667, 0.029723296861022885, 0.02865825522657745, 0.029801116246308743, 0.01876708083465345, 0.01798936098798187, 0.006803728067023407]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 370 	 Test accuracy: 87.05000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 371 	 Test accuracy: 87.39 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 372 	 Test accuracy: 87.67 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 373 	 Test accuracy: 87.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 374 	 Test accuracy: 87.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 375 	 Test accuracy: 87.64999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 376 	 Test accuracy: 87.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 377 	 Test accuracy: 87.72999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 378 	 Test accuracy: 87.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 379 	 Test accuracy: 87.51 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.23s/it] 67%|██████▋   | 2/3 [00:40<00:20, 20.18s/it]100%|██████████| 3/3 [01:02<00:00, 21.18s/it]100%|██████████| 3/3 [01:02<00:00, 20.93s/it]


scaleA
 [0.022534833412355227, 0.007061753484709612, 0.01003929689311051, 0.009864118387177488, 0.004656773268642636, 0.005735424721776569, 0.00646016810090138, 0.011787468902862063, 0.0027414915539822394, 0.002971500260434075, 0.0064245738210071185, 0.0083750413409277, 0.01006276975729692, 0.019960649366372724, 0.012762620560321297, 0.02089806549081258, 0.005182950824265277, 0.005487141015334471]
scaleW
 [0.16632908403279315, 0.12256348544166817, 0.1691096714067033, 0.11632694856407684, 0.09669195910273233, 0.0628435116882959, 0.09123921449094956, 0.06425960819317132, 0.03323346797360182, 0.011982954050895514, 0.03769859275876511, 0.02176419829975398, 0.043139772976961775, 0.02927920792007675, 0.02861401660635796, 0.029057529586855552, 0.006531642781600924, 0.003602959330886201]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 380 	 Test accuracy: 87.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 381 	 Test accuracy: 87.92999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 382 	 Test accuracy: 87.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 383 	 Test accuracy: 87.53 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 384 	 Test accuracy: 87.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 385 	 Test accuracy: 87.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 386 	 Test accuracy: 87.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 387 	 Test accuracy: 87.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 388 	 Test accuracy: 87.64999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 389 	 Test accuracy: 87.69 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:40, 20.01s/it] 67%|██████▋   | 2/3 [00:36<00:18, 18.22s/it]100%|██████████| 3/3 [01:00<00:00, 20.62s/it]100%|██████████| 3/3 [01:00<00:00, 20.16s/it]


scaleA
 [0.021417998722887938, 0.00794845998723545, 0.010612443422797555, 0.011593301439932105, 0.005900504622462051, 0.008454919578104524, 0.0062067338416822585, 0.00965966859517134, 0.009303891499622503, 0.010131455263578627, 0.008099012225970564, 0.01365079534797871, 0.00945963216928714, 0.02273527005024412, 0.014282808077191025, 0.018940795766540043, 0.013301675927101861, 0.014281380861221627]
scaleW
 [0.17038920119533765, 0.13075706142364804, 0.16286727604775392, 0.08984244474230507, 0.1520861779219027, 0.06753106645994349, 0.06719843738571196, 0.05221603823352281, 0.07515975353756289, 0.03716387451972581, 0.06540105894550648, 0.04315179748455165, 0.037285282413912595, 0.036831378903899516, 0.03457987351324469, 0.027185618298536208, 0.03137047962799703, 0.014033184714441276]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 390 	 Test accuracy: 87.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 391 	 Test accuracy: 87.53999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 392 	 Test accuracy: 87.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 393 	 Test accuracy: 87.64999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 394 	 Test accuracy: 87.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 395 	 Test accuracy: 87.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 396 	 Test accuracy: 87.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 397 	 Test accuracy: 87.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 398 	 Test accuracy: 87.67 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 399 	 Test accuracy: 87.77000000000001 %
The best checkpoint is loaded
Test accuracy: 87.92999999999999%
