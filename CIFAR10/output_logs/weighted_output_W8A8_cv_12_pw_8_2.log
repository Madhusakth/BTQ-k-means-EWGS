dataset: cifar10	arch: resnet20_quant	num_workers: 4	seed: None	batch_size: 32	epochs: 400	optimizer_m: Adam	optimizer_q: Adam	lr_m: 0.001	lr_q: 1e-05	lr_m_end: 0.0	lr_q_end: 0.0	decay_schedule_m: 150-300	decay_schedule_q: 150-300	momentum: 0.9	weight_decay: 0.0001	lr_scheduler_m: cosine	lr_scheduler_q: cosine	gamma: 0.1	QWeightFlag: True	QActFlag: True	weight_levels: 256	act_levels: 256	baseline: False	bkwd_scaling_factorW: 0.0	bkwd_scaling_factorA: 0.0	use_hessian: True	update_every: 10	gpu_id: 0	log_dir: ../results/CIFAR10_ResNet50/W8A8_kmeans_comp_decomp_weighted_cv_12_pw_8_2/	load_pretrain: True	pretrain_path: ../results/ResNet20_CIFAR10/fp/checkpoint/best_checkpoint.pth	btq: True	training_flag: False	eval: False	weighted: True	cv_block_size: 12	pw_fc_block_size: 8	
Files already downloaded and verified
The number of parameters :  269940
Pretrained full precision weights are initialized
# total params: 269940
# model params: 269850
# quantizer params: 90
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): QBasicBlock(
      (conv1): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): QBasicBlock(
      (conv1): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 000 	 Test accuracy: 11.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 001 	 Test accuracy: 17.82 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 002 	 Test accuracy: 18.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 003 	 Test accuracy: 16.5 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 004 	 Test accuracy: 20.119999999999997 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 005 	 Test accuracy: 17.51 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 006 	 Test accuracy: 26.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 007 	 Test accuracy: 21.77 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 008 	 Test accuracy: 23.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 009 	 Test accuracy: 22.3 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.11s/it] 67%|██████▋   | 2/3 [00:37<00:18, 18.77s/it]100%|██████████| 3/3 [00:58<00:00, 19.58s/it]100%|██████████| 3/3 [00:58<00:00, 19.41s/it]


scaleA
 [0.011618745340213996, 0.00750720617694163, 0.0049867492841851775, 0.006676407446572013, 0.0027991540092866286, 0.005646844168185838, 0.005878948705998486, 0.012000747799529648, 0.007241218449625608, 0.008379211119782593, 0.00859593713982016, 0.009385032125336654, 0.009129108601958648, 0.020308282913630227, 0.013837804854591212, 0.015205844481610824, 0.006364646379692424, 0.010181050671303043]
scaleW
 [0.1528599593746667, 0.12966352036944306, 0.10293591371491023, 0.051058540144966934, 0.09100245866349632, 0.056163407318266224, 0.07635869579610237, 0.06338230334478923, 0.05128035847491885, 0.028606727887013267, 0.06598644124023335, 0.02430015842349026, 0.03569969460848504, 0.0328311904536538, 0.03203498990158106, 0.021916100011990864, 0.014795835953379285, 0.010086667740216973]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 010 	 Test accuracy: 27.01 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 011 	 Test accuracy: 26.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 012 	 Test accuracy: 18.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 013 	 Test accuracy: 21.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 014 	 Test accuracy: 23.74 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 015 	 Test accuracy: 19.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 016 	 Test accuracy: 38.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 017 	 Test accuracy: 26.169999999999998 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 018 	 Test accuracy: 18.12 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 019 	 Test accuracy: 22.58 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:12<00:24, 12.38s/it] 67%|██████▋   | 2/3 [00:26<00:13, 13.33s/it]100%|██████████| 3/3 [00:44<00:00, 15.69s/it]100%|██████████| 3/3 [00:44<00:00, 14.98s/it]


scaleA
 [0.017742492313759094, 0.010116667516553, 0.008037266438717466, 0.010444906943486647, 0.006357995865609819, 0.006494901411236378, 0.006694753334266256, 0.011420738035755731, 0.007005044002786583, 0.008108272049319, 0.0071385961669029495, 0.01066773037060334, 0.009978285723803725, 0.02198337974226929, 0.012691672222887238, 0.01678232435261046, 0.011734395113954571, 0.00779445160314264]
scaleW
 [0.16726032698155066, 0.12306066253303637, 0.15494720532710818, 0.09481716162537789, 0.12292450585403185, 0.05576612949269074, 0.07634266956184947, 0.05173325783800826, 0.040005238136084705, 0.02670865799700066, 0.04793482549363445, 0.022957971571176263, 0.034956607704643074, 0.028878442394073823, 0.02413500367640298, 0.01975044013218572, 0.020270183380157205, 0.006257438793750862]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 020 	 Test accuracy: 28.1 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 021 	 Test accuracy: 50.980000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 022 	 Test accuracy: 23.93 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 023 	 Test accuracy: 30.349999999999998 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 024 	 Test accuracy: 20.549999999999997 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 025 	 Test accuracy: 37.04 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 026 	 Test accuracy: 39.410000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 027 	 Test accuracy: 47.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 028 	 Test accuracy: 32.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 029 	 Test accuracy: 14.610000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:14<00:28, 14.32s/it] 67%|██████▋   | 2/3 [00:31<00:15, 15.89s/it]100%|██████████| 3/3 [00:50<00:00, 17.43s/it]100%|██████████| 3/3 [00:50<00:00, 16.88s/it]


scaleA
 [0.008038570597768134, 0.003836361818644888, 0.00256284247750658, 0.005200814919158062, 0.003407206172144133, 0.00609883433815686, 0.00418808324548607, 0.006040516590189939, 0.002701440005456963, 0.006920889513479166, 0.005074337249685407, 0.007670210986130444, 0.006346217931944793, 0.013161204964903783, 0.009147804957816455, 0.015290877235722729, 0.007161526184495441, 0.0117555381109252]
scaleW
 [0.05422665096260898, 0.05879875131387019, 0.05312459918858692, 0.045124347885952244, 0.06444332957498045, 0.04332171984643479, 0.044315996804177214, 0.03189949069173036, 0.02277571420093913, 0.017732316684103314, 0.0315272589221158, 0.01884919068413259, 0.01943406090430687, 0.01584248901558114, 0.016918780289961483, 0.019086025930609266, 0.011890203520360026, 0.012247318387762404]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 030 	 Test accuracy: 36.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 031 	 Test accuracy: 41.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 032 	 Test accuracy: 31.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 033 	 Test accuracy: 48.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 034 	 Test accuracy: 37.940000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 035 	 Test accuracy: 33.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 036 	 Test accuracy: 37.480000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 037 	 Test accuracy: 32.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 038 	 Test accuracy: 27.93 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 039 	 Test accuracy: 32.09 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:35, 17.73s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.58s/it]100%|██████████| 3/3 [00:54<00:00, 18.24s/it]100%|██████████| 3/3 [00:54<00:00, 18.09s/it]


scaleA
 [0.014513499239128253, 0.00829918778873457, 0.01046684920023658, 0.014690973066084571, 0.004054027146305647, 0.0075525839668714465, 0.007940143662628097, 0.014587120930696603, 0.009736126028344012, 0.012175274406151545, 0.013990173771227715, 0.0191096539795885, 0.011777082142350884, 0.0239161952017047, 0.018653854772291985, 0.023662276526664708, 0.016396882824266972, 0.01265840694826566]
scaleW
 [0.13151206454340217, 0.10479773666723897, 0.17828415114444027, 0.11679604308820069, 0.08718643140263871, 0.06045269689954761, 0.07782960731766274, 0.06505307096542805, 0.05344315237734031, 0.03665275774390766, 0.08052200422286811, 0.04702796242337557, 0.03625003156255482, 0.02861111692634663, 0.034364615329589794, 0.026746448048702427, 0.026740967309828043, 0.010886134973795638]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 040 	 Test accuracy: 23.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 041 	 Test accuracy: 41.589999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 042 	 Test accuracy: 24.55 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 043 	 Test accuracy: 28.84 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 044 	 Test accuracy: 18.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 045 	 Test accuracy: 21.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 046 	 Test accuracy: 22.12 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 047 	 Test accuracy: 30.869999999999997 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 048 	 Test accuracy: 38.04 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 049 	 Test accuracy: 49.79 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:24<00:48, 24.35s/it] 67%|██████▋   | 2/3 [00:41<00:20, 20.36s/it]100%|██████████| 3/3 [00:55<00:00, 17.41s/it]100%|██████████| 3/3 [00:55<00:00, 18.62s/it]


scaleA
 [0.014949072941300804, 0.008154676139213071, 0.008067984607064737, 0.012685747049204478, 0.007788239701500649, 0.006988313815097148, 0.004920192723968119, 0.010837348499925842, 0.011034472130220853, 0.013947244209532675, 0.011914641572848083, 0.016223474086706567, 0.007702363921153768, 0.01709906617267867, 0.0073841553725370645, 0.007740892543457337, 0.009057921871314802, 0.009298663286352291]
scaleW
 [0.11430392505287491, 0.09201602520788855, 0.15169872431173323, 0.09049986311300505, 0.11125697975356301, 0.06033287687093786, 0.05443390042277543, 0.04493107825742496, 0.053186169965246, 0.04238260817555778, 0.059552286844712976, 0.04369464648503416, 0.024108147790168916, 0.020359962901854742, 0.0123457570090255, 0.007679326924824613, 0.013657333418009796, 0.007613933363155352]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 050 	 Test accuracy: 32.33 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 051 	 Test accuracy: 31.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 052 	 Test accuracy: 50.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 053 	 Test accuracy: 50.82 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 054 	 Test accuracy: 36.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 055 	 Test accuracy: 32.269999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 056 	 Test accuracy: 44.440000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 057 	 Test accuracy: 43.29 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 058 	 Test accuracy: 48.29 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 059 	 Test accuracy: 28.58 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:14<00:29, 14.96s/it] 67%|██████▋   | 2/3 [00:35<00:18, 18.30s/it]100%|██████████| 3/3 [00:53<00:00, 18.13s/it]100%|██████████| 3/3 [00:53<00:00, 17.86s/it]


scaleA
 [0.01572808198921852, 0.008287457878581112, 0.006377115586694915, 0.010644339418688795, 0.006705538181375496, 0.007928142344927903, 0.005333384188545044, 0.010922363805129185, 0.010922526037390115, 0.010868361671597914, 0.010705079092291294, 0.012847643585641078, 0.009072043191953202, 0.019680574093150865, 0.00874244297351304, 0.009536139894542007, 0.01132279167889338, 0.01420480941965969]
scaleW
 [0.10586222033055519, 0.08923065718924243, 0.11495012006772574, 0.08150078627423885, 0.10627343350985469, 0.06838780391206052, 0.05739356088476971, 0.04771907879621446, 0.054496973558954505, 0.033367784950412586, 0.057136552316027135, 0.025892816377591863, 0.029516777979725014, 0.026483806210983063, 0.016387205987062264, 0.011412679069668101, 0.015913744467078328, 0.011321583146418365]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 060 	 Test accuracy: 43.580000000000005 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 061 	 Test accuracy: 41.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 062 	 Test accuracy: 30.709999999999997 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 063 	 Test accuracy: 42.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 064 	 Test accuracy: 37.059999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 065 	 Test accuracy: 20.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 066 	 Test accuracy: 56.55 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 067 	 Test accuracy: 50.660000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 068 	 Test accuracy: 57.220000000000006 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 069 	 Test accuracy: 38.25 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:13<00:26, 13.42s/it] 67%|██████▋   | 2/3 [00:30<00:15, 15.81s/it]100%|██████████| 3/3 [00:45<00:00, 15.37s/it]100%|██████████| 3/3 [00:45<00:00, 15.27s/it]


scaleA
 [0.014744457250916816, 0.0073600447596207695, 0.00827547615839973, 0.012812588078362505, 0.0028356315033673577, 0.006519247144298364, 0.0051033946974057285, 0.011092938127559342, 0.007386878029833537, 0.00969880984849931, 0.008142922595595396, 0.0127450324955282, 0.009398253648715495, 0.022855365987391203, 0.010337404790851677, 0.0172242565656008, 0.008448065455784966, 0.008604166271377034]
scaleW
 [0.11260054273555098, 0.09771559668472929, 0.15583392861851184, 0.10516843309614225, 0.0485843364810263, 0.05676866109397231, 0.05719002320372212, 0.04684019939308697, 0.0411740950740283, 0.027265561532117098, 0.049347549793582045, 0.028828340978983954, 0.02960950989745309, 0.028117785916154294, 0.01953493365000834, 0.017023192558220667, 0.01580415659690014, 0.006020900779204921]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 070 	 Test accuracy: 45.82 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 071 	 Test accuracy: 20.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 072 	 Test accuracy: 36.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 073 	 Test accuracy: 36.4 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 074 	 Test accuracy: 53.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 075 	 Test accuracy: 42.34 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 076 	 Test accuracy: 36.39 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 077 	 Test accuracy: 47.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 078 	 Test accuracy: 33.07 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 079 	 Test accuracy: 36.66 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:35, 17.81s/it] 67%|██████▋   | 2/3 [00:40<00:20, 20.48s/it]100%|██████████| 3/3 [00:56<00:00, 18.38s/it]100%|██████████| 3/3 [00:56<00:00, 18.69s/it]


scaleA
 [0.012708539738938629, 0.0064590066895782354, 0.007647980133527649, 0.010857687934593482, 0.0009792043610296448, 0.005610514682847275, 0.0052256968408222505, 0.01113978152249877, 0.00797435741661654, 0.01066684936791945, 0.009829791396352464, 0.014143844619815703, 0.009751522183420134, 0.02363831079960857, 0.01654085686940097, 0.023355940633435535, 0.015561034866733455, 0.01034701890565696]
scaleW
 [0.09896375519708601, 0.07965187738742031, 0.13786495986381997, 0.07742700684043193, 0.05827899885591506, 0.027930424537626643, 0.04876214351846908, 0.04402308226433688, 0.04416314049791781, 0.02801541073732743, 0.057291070381685794, 0.034663095462753875, 0.03225580232878549, 0.029466155180373935, 0.03081458662892211, 0.021008652263757633, 0.02586230173044141, 0.007730663596064058]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 080 	 Test accuracy: 41.23 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 081 	 Test accuracy: 46.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 082 	 Test accuracy: 48.949999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 083 	 Test accuracy: 37.36 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 084 	 Test accuracy: 44.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 085 	 Test accuracy: 55.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 086 	 Test accuracy: 56.16 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 087 	 Test accuracy: 39.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 088 	 Test accuracy: 47.77 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 089 	 Test accuracy: 35.06 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:23<00:46, 23.45s/it] 67%|██████▋   | 2/3 [00:42<00:21, 21.05s/it]100%|██████████| 3/3 [01:00<00:00, 19.72s/it]100%|██████████| 3/3 [01:00<00:00, 20.33s/it]


scaleA
 [0.012600930674159308, 0.006855158889086101, 0.006754242092662108, 0.009104480637882635, 0.00377336825882487, 0.006023306842269688, 0.005969826680577225, 0.01029126177879657, 0.008430938919031314, 0.010779182815932242, 0.007920832976566879, 0.015456456213216951, 0.009307612249279082, 0.02008860271322856, 0.0163738595098953, 0.015541579182707098, 0.011111873358464844, 0.01207042161196329]
scaleW
 [0.12720020910713933, 0.09935009850671406, 0.13900002862637584, 0.05943017538643162, 0.07452627340951735, 0.05111567242008041, 0.0623193479782222, 0.04730797104101425, 0.04590764202973183, 0.02983026460493719, 0.04689016597078601, 0.031149509582498305, 0.02840416580116707, 0.02542184451531279, 0.029087908415974157, 0.016968232020692732, 0.01808705879535773, 0.009591744781207187]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 090 	 Test accuracy: 38.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 091 	 Test accuracy: 35.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 092 	 Test accuracy: 49.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 093 	 Test accuracy: 46.489999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 094 	 Test accuracy: 59.040000000000006 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 095 	 Test accuracy: 55.410000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 096 	 Test accuracy: 50.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 097 	 Test accuracy: 53.5 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 098 	 Test accuracy: 40.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 099 	 Test accuracy: 48.71 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:16<00:32, 16.40s/it] 67%|██████▋   | 2/3 [00:33<00:16, 16.62s/it]100%|██████████| 3/3 [00:51<00:00, 17.43s/it]100%|██████████| 3/3 [00:51<00:00, 17.20s/it]


scaleA
 [0.011332329711423852, 0.005989347765919716, 0.00580788871907769, 0.008716154200256933, 0.004496826633863258, 0.006300122094890465, 0.004526008390739982, 0.009498237713633666, 0.007647129383930868, 0.007340734725713918, 0.006460269314211928, 0.01119840825787378, 0.007290094816098364, 0.017559260757127753, 0.009283385637908802, 0.01005660926599875, 0.00041618700986449913, 0.006967787413366525]
scaleW
 [0.08667778080478655, 0.06857155368396593, 0.1191205857749225, 0.05690728378992313, 0.08851604021003147, 0.03980022573135164, 0.040933049021152, 0.039162435854169966, 0.03971462098773259, 0.02419771873398958, 0.03883092895361451, 0.022678556688644796, 0.023218946317642316, 0.021536335974415097, 0.017398180281985986, 0.01049443147787378, 0.004671221266955775, 0.0039982721570607505]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 100 	 Test accuracy: 55.45 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 101 	 Test accuracy: 38.74 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 102 	 Test accuracy: 39.93 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 103 	 Test accuracy: 38.98 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 104 	 Test accuracy: 60.38 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 105 	 Test accuracy: 41.82 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 106 	 Test accuracy: 55.98 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 107 	 Test accuracy: 66.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 108 	 Test accuracy: 48.94 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 109 	 Test accuracy: 30.14 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:39, 19.86s/it] 67%|██████▋   | 2/3 [00:38<00:18, 18.97s/it]100%|██████████| 3/3 [00:53<00:00, 17.51s/it]100%|██████████| 3/3 [00:54<00:00, 18.01s/it]


scaleA
 [0.017213830075050545, 0.008646176747115252, 0.007179601081682874, 0.011209436525433812, 0.006949112322188349, 0.008523079323189806, 0.007315586863920466, 0.012611653802203998, 0.006643570476656105, 0.00802550442384022, 0.006666743491486001, 0.008930468564925069, 0.009443178125689587, 0.02393348878249456, 0.014816692906735547, 0.02206101803353216, 0.017464022448001364, 0.018836772781887303]
scaleW
 [0.11012054611046178, 0.10751106042169961, 0.12961042379214563, 0.06684856954928116, 0.10752030394012153, 0.07209067900675509, 0.064129078309014, 0.05572290394660451, 0.03800692130471497, 0.020991970846070008, 0.0447174361926315, 0.016673970107298857, 0.030166452579226278, 0.03136919851667442, 0.026700613007660426, 0.023051363508554152, 0.02813565981353264, 0.017414971891895795]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 110 	 Test accuracy: 59.8 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 111 	 Test accuracy: 47.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 112 	 Test accuracy: 43.99 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 113 	 Test accuracy: 60.699999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 114 	 Test accuracy: 48.1 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 383
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 115 	 Test accuracy: 58.29 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 116 	 Test accuracy: 43.54 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 117 	 Test accuracy: 51.68000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 118 	 Test accuracy: 58.76 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 119 	 Test accuracy: 59.019999999999996 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.01s/it] 67%|██████▋   | 2/3 [00:36<00:18, 18.11s/it]100%|██████████| 3/3 [00:51<00:00, 16.48s/it]100%|██████████| 3/3 [00:51<00:00, 17.02s/it]


scaleA
 [0.01679342261771354, 0.00836919737926628, 0.009226240252910684, 0.01185121571465691, 0.008555175712672584, 0.0091009813822122, 0.006001367057286595, 0.011924950438844749, 0.013606016152276837, 0.016667486115965493, 0.009230091083092857, 0.014122836694790567, 0.009778294945682697, 0.02037798583161551, 0.01919684943149159, 0.025855644793743086, 0.014432648232085071, 0.01445658544352387]
scaleW
 [0.10803174771650771, 0.10038512688773737, 0.1530921829324899, 0.06698637571073882, 0.11540941534715922, 0.07225166059750186, 0.05369947253259299, 0.05133138045480575, 0.06417458283188836, 0.04661473211172776, 0.04912025754632173, 0.026560778837500635, 0.028230035246736607, 0.024063047921417013, 0.03171432139102815, 0.02674378123095997, 0.02302872470752257, 0.01052721833689139]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 120 	 Test accuracy: 46.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 121 	 Test accuracy: 58.879999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 122 	 Test accuracy: 47.13 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 123 	 Test accuracy: 47.65 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 124 	 Test accuracy: 61.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 125 	 Test accuracy: 45.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 126 	 Test accuracy: 55.46 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 127 	 Test accuracy: 45.46 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 128 	 Test accuracy: 55.15 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 129 	 Test accuracy: 48.14 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.77s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.72s/it]100%|██████████| 3/3 [00:59<00:00, 20.59s/it]100%|██████████| 3/3 [00:59<00:00, 19.94s/it]


scaleA
 [0.013126687578855998, 0.005334266252962522, 0.007848682227030999, 0.013271171757735184, 0.006356136231666614, 0.006096265787178846, 0.006176967184659036, 0.011081419797792922, 0.005372512060366544, 0.004923780095745117, 0.009438030317579504, 0.018056944641897592, 0.007270102857601606, 0.01760807607385521, 0.009473982747464653, 0.01138811216786826, 0.01231477939515998, 0.014454358471570422]
scaleW
 [0.07902130786882872, 0.05473344784759657, 0.11342918935462239, 0.08218475120997447, 0.08741779164603808, 0.0451804856784529, 0.05265624992932063, 0.04662119296114895, 0.027013857474458215, 0.009638545946756066, 0.05242474175057272, 0.0402925793739939, 0.023218782148562992, 0.017586440784382058, 0.0165677726558611, 0.009736176541049628, 0.01923747698561208, 0.01120187662667068]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 130 	 Test accuracy: 51.6 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 131 	 Test accuracy: 43.07 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 132 	 Test accuracy: 55.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 133 	 Test accuracy: 52.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 134 	 Test accuracy: 33.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 135 	 Test accuracy: 66.9 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 136 	 Test accuracy: 52.559999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 137 	 Test accuracy: 47.38 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 138 	 Test accuracy: 35.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 139 	 Test accuracy: 46.81 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.38s/it] 67%|██████▋   | 2/3 [00:40<00:20, 20.32s/it]100%|██████████| 3/3 [00:57<00:00, 19.00s/it]100%|██████████| 3/3 [00:57<00:00, 19.28s/it]


scaleA
 [0.014584114840859566, 0.0074980169037734195, 0.006058666828334713, 0.009429115851578991, 0.003357564816583287, 0.005064983030349211, 0.005167908158038387, 0.008942869696881385, 0.0061732394851526625, 0.0068030144894695955, 0.0068782328430274445, 0.011258724450026007, 0.0077934152867152095, 0.018722446553764413, 0.012387017067210565, 0.016182845285673764, 0.013118607457327893, 0.009216872441154015]
scaleW
 [0.12548206631498285, 0.08727655745774403, 0.10492807799071496, 0.05839855343216469, 0.06566459596958402, 0.03808138453966861, 0.04960322395723788, 0.04348825142634934, 0.039481814392988125, 0.020699124675419633, 0.043355084904120024, 0.02461572130643695, 0.025550569533799358, 0.023601105028310216, 0.02217949180812392, 0.017148417554491716, 0.019748918760733494, 0.006587874886116022]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 140 	 Test accuracy: 56.69 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 141 	 Test accuracy: 46.93 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 142 	 Test accuracy: 56.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 143 	 Test accuracy: 40.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 144 	 Test accuracy: 29.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 145 	 Test accuracy: 58.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 146 	 Test accuracy: 42.57 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 147 	 Test accuracy: 62.1 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 148 	 Test accuracy: 57.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 149 	 Test accuracy: 46.489999999999995 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.77s/it] 67%|██████▋   | 2/3 [00:34<00:16, 16.87s/it]100%|██████████| 3/3 [00:48<00:00, 15.78s/it]100%|██████████| 3/3 [00:48<00:00, 16.28s/it]


scaleA
 [0.021773661457802324, 0.011592876666687013, 0.009218298835991907, 0.015327093880611764, 0.00796210769662596, 0.01107276624257371, 0.006630903293071987, 0.013375097513975491, 0.012869335354676112, 0.016319375995520347, 0.011014236463125042, 0.015977000670807776, 0.011131982202676458, 0.023781569854041753, 0.012549216756190406, 0.018171470628859866, 0.017934976870012057, 0.016497637525247234]
scaleW
 [0.17619365147827784, 0.14600953456468221, 0.15684110951316552, 0.1072857117634702, 0.12194716817873918, 0.08948630801340664, 0.06225278323867587, 0.052291412417181056, 0.06033000381946487, 0.045486382706876834, 0.061492913788798065, 0.03572093617455256, 0.035891176487952925, 0.028791247887344107, 0.021120512806121802, 0.015247230940921688, 0.02554141897507578, 0.012902169614541261]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 150 	 Test accuracy: 61.650000000000006 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 151 	 Test accuracy: 57.93000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 152 	 Test accuracy: 59.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 153 	 Test accuracy: 70.3 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 154 	 Test accuracy: 52.75 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 155 	 Test accuracy: 70.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 156 	 Test accuracy: 73.29 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 157 	 Test accuracy: 65.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 158 	 Test accuracy: 48.93 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 159 	 Test accuracy: 67.57 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:34, 17.36s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.62s/it]100%|██████████| 3/3 [00:50<00:00, 16.52s/it]100%|██████████| 3/3 [00:50<00:00, 16.80s/it]


scaleA
 [0.008275903144149452, 0.0037036990825466184, 0.005338449707052303, 0.0065263062569126664, 0.004667204990707377, 0.005761827934709841, 0.003439695001996687, 0.007718493181155713, 0.0027680246593779216, 0.0064540659959607255, 0.004076094068806749, 0.009429468277955303, 0.005907083705353408, 0.012011249512960521, 0.009620494946719871, 0.011764698054928725, 0.004484254261715402, 0.007821277071530222]
scaleW
 [0.05490631862026082, 0.054899467597426, 0.07640366481484175, 0.04690036816274207, 0.0768448396576977, 0.0471606864883616, 0.039656238758634464, 0.0361236546748274, 0.026368343513083443, 0.023565886517908186, 0.03185419140023937, 0.020788963710966182, 0.018295063267514667, 0.013442883356681526, 0.016331055271298217, 0.01282483801929783, 0.004530755629538866, 0.0057172418838915525]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 160 	 Test accuracy: 60.64000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 161 	 Test accuracy: 62.239999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 162 	 Test accuracy: 68.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 163 	 Test accuracy: 46.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 164 	 Test accuracy: 59.53000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 165 	 Test accuracy: 66.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 383
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 166 	 Test accuracy: 65.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 167 	 Test accuracy: 61.660000000000004 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 168 	 Test accuracy: 70.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 169 	 Test accuracy: 70.46 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.85s/it] 67%|██████▋   | 2/3 [00:39<00:20, 20.20s/it]100%|██████████| 3/3 [00:58<00:00, 19.39s/it]100%|██████████| 3/3 [00:58<00:00, 19.48s/it]


scaleA
 [0.019173428121559106, 0.009693070109453692, 0.008996211852662863, 0.01369125891982459, 0.009242748769394942, 0.00791915463857641, 0.0065398590944570996, 0.01122067605100778, 0.011905021970283343, 0.013157277385064635, 0.00825935338553028, 0.013188441303750261, 0.01113609636669471, 0.025779717088097703, 0.013213139795784949, 0.01905316840398516, 0.008872889450980248, 0.009660250288679405]
scaleW
 [0.14393922487231978, 0.10781574882401102, 0.15614030938650622, 0.11535632170584216, 0.1433797696875259, 0.0640913898028768, 0.06597098885185322, 0.04842928102535357, 0.06017226486659991, 0.039519782643173934, 0.05192696281952946, 0.02656386514129454, 0.0351763073775523, 0.03233801899041374, 0.023789323981964493, 0.02038189090692844, 0.014536549285221674, 0.004233458413028873]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 170 	 Test accuracy: 63.46000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 171 	 Test accuracy: 69.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 172 	 Test accuracy: 55.53 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 173 	 Test accuracy: 68.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 174 	 Test accuracy: 67.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 175 	 Test accuracy: 50.6 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 176 	 Test accuracy: 66.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 177 	 Test accuracy: 60.77 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 178 	 Test accuracy: 55.989999999999995 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 179 	 Test accuracy: 57.76 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:21<00:43, 21.87s/it] 67%|██████▋   | 2/3 [00:38<00:18, 18.51s/it]100%|██████████| 3/3 [00:54<00:00, 17.69s/it]100%|██████████| 3/3 [00:54<00:00, 18.26s/it]


scaleA
 [0.015779130831712857, 0.008331634084551356, 0.004586365875520633, 0.00808089287163373, 0.007482161265834556, 0.0074602143311846255, 0.005011988518495226, 0.008635914991616749, 0.0057151246881812015, 0.00760743682117606, 0.004076201509290805, 0.007036432761338509, 0.007879505924072777, 0.01774292286100548, 0.014028808199731487, 0.024259662501580747, 0.005860425528143643, 0.014356560901679883]
scaleW
 [0.11676839735689526, 0.10975964031278422, 0.10767682571549508, 0.06119095762478185, 0.12046880385428198, 0.06347403321696342, 0.06078736652865684, 0.043932126563496564, 0.03768597876302152, 0.021728524298058913, 0.03498051521913647, 0.01692348973733926, 0.02959492779423015, 0.021920347894637784, 0.02907977793653756, 0.02449838555257963, 0.009705196949527244, 0.011169493398305303]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 180 	 Test accuracy: 68.38 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 181 	 Test accuracy: 68.89999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 182 	 Test accuracy: 70.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 183 	 Test accuracy: 73.38 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 184 	 Test accuracy: 63.29 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 185 	 Test accuracy: 58.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 186 	 Test accuracy: 59.199999999999996 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 187 	 Test accuracy: 62.96000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 188 	 Test accuracy: 61.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 189 	 Test accuracy: 63.6 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:35, 17.98s/it] 67%|██████▋   | 2/3 [00:36<00:18, 18.25s/it]100%|██████████| 3/3 [00:52<00:00, 17.08s/it]100%|██████████| 3/3 [00:52<00:00, 17.38s/it]


scaleA
 [0.013682498544945581, 0.007520819661814903, 0.007168837239315919, 0.01015208804151601, 0.0020657637535099562, 0.005919902659174479, 0.0067182606717448, 0.011162379366892296, 0.007598171913161977, 0.007859216660736036, 0.006249808882721749, 0.013619665980895578, 0.01177224800794993, 0.02985341866834408, 0.01603048764368328, 0.02181263565834857, 0.015434516965285708, 0.015689709545880785]
scaleW
 [0.1120095416785372, 0.10196032504081488, 0.14196193378774352, 0.06667359066609431, 0.0706375197079238, 0.041620806401284655, 0.0760276308372998, 0.05581995334901265, 0.04511727631190427, 0.024600204553961207, 0.046864200891892804, 0.03294702761725607, 0.04026255993979378, 0.036536085309726546, 0.032162235986312813, 0.023165678443144776, 0.024842423958353812, 0.014225177444421838]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 190 	 Test accuracy: 73.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 191 	 Test accuracy: 65.25999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 192 	 Test accuracy: 71.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 193 	 Test accuracy: 70.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 194 	 Test accuracy: 64.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 195 	 Test accuracy: 68.51 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 196 	 Test accuracy: 72.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 197 	 Test accuracy: 70.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 198 	 Test accuracy: 68.74 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 199 	 Test accuracy: 70.41 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.53s/it] 67%|██████▋   | 2/3 [00:34<00:17, 17.25s/it]100%|██████████| 3/3 [00:51<00:00, 17.00s/it]100%|██████████| 3/3 [00:51<00:00, 17.21s/it]


scaleA
 [0.020949397602365177, 0.008615181911201702, 0.008901350058310145, 0.014555900928951102, 0.009188311283431698, 0.008955516127498077, 0.008352343505663133, 0.01365972419096934, 0.011401902563230397, 0.013349008992638958, 0.009700159311921917, 0.015634506425904374, 0.01249132491611342, 0.028084755369657544, 0.02029265711021829, 0.025579758074851397, 0.01517803787201745, 0.01310096637089623]
scaleW
 [0.1455065152853704, 0.11745322158825351, 0.1709836253038147, 0.10545697816490124, 0.14245743644404382, 0.07061978102745582, 0.08688146981703203, 0.06073627622175681, 0.06700798258687557, 0.04228806931312857, 0.06165524156232549, 0.03942209120645712, 0.03499837675883335, 0.03468190709891427, 0.03697124545280633, 0.024308951336240846, 0.027109509033583844, 0.01085409791632398]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 200 	 Test accuracy: 73.16 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 201 	 Test accuracy: 61.29 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 202 	 Test accuracy: 72.7 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 203 	 Test accuracy: 72.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 204 	 Test accuracy: 73.02 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 205 	 Test accuracy: 73.61 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 206 	 Test accuracy: 71.93 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 207 	 Test accuracy: 62.25000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 208 	 Test accuracy: 75.37 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 383
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 209 	 Test accuracy: 64.46 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.43s/it] 67%|██████▋   | 2/3 [00:36<00:18, 18.21s/it]100%|██████████| 3/3 [00:57<00:00, 19.41s/it]100%|██████████| 3/3 [00:57<00:00, 19.22s/it]


scaleA
 [0.018928966650284717, 0.008272527165998151, 0.010489706583354928, 0.013260727133274483, 0.010539303381528359, 0.009006170531762125, 0.005993584983698604, 0.012219271864965383, 0.010664485305102339, 0.011263950774988539, 0.008847141295516116, 0.013728438505660476, 0.010685764386882566, 0.02361970221985891, 0.015155707598725443, 0.023962419580168842, 0.01183823123190053, 0.011775931572517696]
scaleW
 [0.13101231709829617, 0.1096521995370613, 0.1774316191483557, 0.12158556749556976, 0.13937888355812242, 0.08472125765914695, 0.062307866559713404, 0.052962904250083355, 0.05432355691545979, 0.033056831612170295, 0.055194046071709524, 0.027795680574587357, 0.037314800482974225, 0.031459848739144876, 0.029086309799565974, 0.02733824302908393, 0.02013409463971583, 0.008687631907107004]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 210 	 Test accuracy: 71.91 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 211 	 Test accuracy: 74.89 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 212 	 Test accuracy: 75.57000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 213 	 Test accuracy: 70.67999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 214 	 Test accuracy: 66.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 215 	 Test accuracy: 70.17999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 216 	 Test accuracy: 80.51 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 217 	 Test accuracy: 70.33 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 218 	 Test accuracy: 76.53999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 383
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 219 	 Test accuracy: 65.86 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:21<00:42, 21.28s/it] 67%|██████▋   | 2/3 [00:42<00:21, 21.37s/it]100%|██████████| 3/3 [00:58<00:00, 18.94s/it]100%|██████████| 3/3 [00:58<00:00, 19.60s/it]


scaleA
 [0.007376723852941548, 0.004290149983855968, 0.004364661550073586, 0.00437183965636857, 0.0007207093307713764, 0.004818800600476416, 0.004599339573504981, 0.007492751398014694, 0.004941334140696959, 0.007524268109469545, 0.004726957388083358, 0.008025933989184638, 0.0049035335138404934, 0.009914961792119628, 0.011739221454674232, 0.015419739524224435, 0.014595736562179785, 0.015748824094045533]
scaleW
 [0.08850520052683021, 0.06804145965235513, 0.1018404748727781, 0.035561960789299574, 0.042476678115734995, 0.031293409910699295, 0.042875058444768514, 0.02983829957710107, 0.03781039623348245, 0.02670631128990765, 0.023228996872231622, 0.01578425601021309, 0.01808799338165328, 0.012306149125056487, 0.023022550969019475, 0.018255100929859464, 0.02542056275642801, 0.0144601556295616]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 220 	 Test accuracy: 64.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 221 	 Test accuracy: 75.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 222 	 Test accuracy: 73.14 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 223 	 Test accuracy: 68.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 224 	 Test accuracy: 78.67 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 225 	 Test accuracy: 71.32 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 226 	 Test accuracy: 80.4 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 227 	 Test accuracy: 61.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 228 	 Test accuracy: 70.30999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 229 	 Test accuracy: 74.13 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.21s/it] 67%|██████▋   | 2/3 [00:32<00:15, 15.88s/it]100%|██████████| 3/3 [00:52<00:00, 17.71s/it]100%|██████████| 3/3 [00:52<00:00, 17.56s/it]


scaleA
 [0.01371006294820252, 0.006262522112377461, 0.008602031686026452, 0.010378846614053085, 0.008794332320991768, 0.008409980887031675, 0.006726545495348184, 0.013293685889152014, 0.011785264452436469, 0.013348522610316617, 0.008357343142707759, 0.011548206180384985, 0.00793791023750012, 0.018572702258975917, 0.010362795336863231, 0.014938383557020768, 0.009172100806874776, 0.01275125465370464]
scaleW
 [0.09059212725224763, 0.08028851624917638, 0.18399503287564797, 0.08001104731551235, 0.14799305256480821, 0.07226586793513898, 0.07968857489075991, 0.06256366025181577, 0.06253610709851347, 0.04279422121173224, 0.05403794262213821, 0.027866303700078005, 0.024962764154539973, 0.027277943666055654, 0.02225241429424063, 0.019627928870715624, 0.01779438411742734, 0.009722641196986813]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 230 	 Test accuracy: 79.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 231 	 Test accuracy: 74.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 232 	 Test accuracy: 76.21 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 233 	 Test accuracy: 77.35 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 234 	 Test accuracy: 76.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 235 	 Test accuracy: 76.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 236 	 Test accuracy: 79.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 237 	 Test accuracy: 77.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 238 	 Test accuracy: 74.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 239 	 Test accuracy: 78.5 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:21<00:43, 21.85s/it] 67%|██████▋   | 2/3 [00:39<00:19, 19.25s/it]100%|██████████| 3/3 [00:56<00:00, 18.31s/it]100%|██████████| 3/3 [00:56<00:00, 18.84s/it]


scaleA
 [0.015516314180776558, 0.007220313337131422, 0.010474948711518809, 0.012528504420151479, 0.007723101848051438, 0.008299510997178933, 0.00669604101976851, 0.01102107254770282, 0.008109173420201893, 0.00989440778814902, 0.003003122957657529, 0.008538915362589853, 0.0062334319141353805, 0.009495350682852606, 0.008749102717678566, 0.01678514353074699, 0.0087845807346766, 0.012375261036907984]
scaleW
 [0.11793022938983429, 0.091351329245472, 0.1744155954525385, 0.09978863004764534, 0.13060671104429408, 0.06919974792600406, 0.06196216966002952, 0.05330469425560924, 0.04702597177861029, 0.031104983893072563, 0.033518418430171046, 0.01793936348273058, 0.019210219200765637, 0.012469349964836186, 0.016551327772473253, 0.01801008158641984, 0.014029483287366896, 0.009825019637282564]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 240 	 Test accuracy: 79.7 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 241 	 Test accuracy: 80.08999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 242 	 Test accuracy: 80.82000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 243 	 Test accuracy: 81.46 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 244 	 Test accuracy: 79.47999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 245 	 Test accuracy: 74.88 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 246 	 Test accuracy: 77.03 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 247 	 Test accuracy: 74.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 248 	 Test accuracy: 75.51 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 249 	 Test accuracy: 81.58999999999999 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:34, 17.27s/it] 67%|██████▋   | 2/3 [00:38<00:19, 19.65s/it]100%|██████████| 3/3 [00:53<00:00, 17.67s/it]100%|██████████| 3/3 [00:53<00:00, 17.98s/it]


scaleA
 [0.015560373468370052, 0.007073253455864191, 0.01046834181645251, 0.013301228331939375, 0.0051518520215760935, 0.004896320047183333, 0.006111873193119173, 0.010719272586252502, 0.009560188580439118, 0.010300396000792892, 0.012618387443041274, 0.01487660315558343, 0.009172988607249518, 0.022312434674977896, 0.014956072260803479, 0.018575761374047706, 0.014571273245620624, 0.01996381387240803]
scaleW
 [0.12027248193805162, 0.12278302977200221, 0.1640304353131732, 0.12163951850493766, 0.08328029301665486, 0.03673746423000596, 0.07334831182764161, 0.05836884307901782, 0.06199026932087259, 0.03796736814635069, 0.06630553347252867, 0.03981373920908559, 0.03520001382050993, 0.03081894049506617, 0.031206080388992943, 0.020532620646755526, 0.027152033024000728, 0.015288102669454578]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 250 	 Test accuracy: 78.38000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 251 	 Test accuracy: 78.58000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 252 	 Test accuracy: 76.38000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 253 	 Test accuracy: 76.03999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 254 	 Test accuracy: 77.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 255 	 Test accuracy: 78.53999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 256 	 Test accuracy: 79.66 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 257 	 Test accuracy: 74.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 258 	 Test accuracy: 80.73 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 259 	 Test accuracy: 78.64 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:20<00:41, 20.55s/it] 67%|██████▋   | 2/3 [00:35<00:17, 17.06s/it]100%|██████████| 3/3 [00:55<00:00, 18.59s/it]100%|██████████| 3/3 [00:55<00:00, 18.54s/it]


scaleA
 [0.020889869193687544, 0.008950299258207868, 0.009512609500964667, 0.013593209703902981, 0.009028798987358222, 0.009749249591869994, 0.007556234250939335, 0.01433078835294113, 0.011587784879632322, 0.012407483112004458, 0.00875645676331042, 0.015468926983151282, 0.010160720382899821, 0.026690057979970996, 0.011160390547930702, 0.016582126147261, 0.012423823909616626, 0.011649543837644593]
scaleW
 [0.14856374431691796, 0.1145863533239427, 0.18004216347706337, 0.10689303067849715, 0.1391514603780362, 0.08073510232394811, 0.0809475895867928, 0.07397710374898357, 0.06647230553565334, 0.042690035945727206, 0.056421527221432406, 0.03328971683542869, 0.03868925659295477, 0.036373507673198226, 0.023452178931630745, 0.01973553380610788, 0.024555692294744285, 0.006692529359195114]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 260 	 Test accuracy: 80.10000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 261 	 Test accuracy: 77.49000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 262 	 Test accuracy: 82.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 263 	 Test accuracy: 81.19 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 264 	 Test accuracy: 81.04 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 265 	 Test accuracy: 75.26 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 266 	 Test accuracy: 79.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 267 	 Test accuracy: 80.77 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 383
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 268 	 Test accuracy: 80.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 269 	 Test accuracy: 83.02000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:14<00:28, 14.18s/it] 67%|██████▋   | 2/3 [00:29<00:14, 14.98s/it]100%|██████████| 3/3 [00:45<00:00, 15.53s/it]100%|██████████| 3/3 [00:45<00:00, 15.31s/it]


scaleA
 [0.020243550380363528, 0.0066054590460029915, 0.009741668697891392, 0.01159518467945127, 0.004083053389676429, 0.005838902691017137, 0.006282435707267702, 0.010243742221929393, 0.009618399603831502, 0.01245011055922464, 0.007792944694096236, 0.013231599681086096, 0.009761092319527693, 0.023875868989299134, 0.015451315972632445, 0.01795893196439921, 0.013405392877769326, 0.012911407814784259]
scaleW
 [0.12738603041509433, 0.095166330914684, 0.1850578647023932, 0.10213303537404333, 0.07942639991290852, 0.051300991558967425, 0.07567826733345791, 0.05583599239108559, 0.06211750060203176, 0.042100383504930707, 0.061557366229479465, 0.030190048829905152, 0.033802943076845095, 0.033811099783957806, 0.03460503557371918, 0.022202353106310104, 0.024105499780563866, 0.011371971627444126]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 270 	 Test accuracy: 75.11 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 271 	 Test accuracy: 84.04 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 272 	 Test accuracy: 78.79 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 273 	 Test accuracy: 81.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 274 	 Test accuracy: 75.51 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 275 	 Test accuracy: 78.85 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 276 	 Test accuracy: 82.54 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 277 	 Test accuracy: 82.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 278 	 Test accuracy: 83.7 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 279 	 Test accuracy: 79.60000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:16<00:33, 16.93s/it] 67%|██████▋   | 2/3 [00:35<00:18, 18.14s/it]100%|██████████| 3/3 [00:54<00:00, 18.50s/it]100%|██████████| 3/3 [00:54<00:00, 18.30s/it]


scaleA
 [0.026561461885506513, 0.010160534523977255, 0.014698073352359604, 0.017573623440618833, 0.00908943431616436, 0.008650639503021858, 0.007811528374403469, 0.014501746972070123, 0.014906562262346901, 0.014297389126243275, 0.006970560789050683, 0.016327978293598944, 0.009868326811534196, 0.02376812189091258, 0.016346854685584934, 0.023889592692147816, 0.012900683172253721, 0.015911306492695915]
scaleW
 [0.1844086799917891, 0.15371425923464246, 0.22190610897923702, 0.14556139762811607, 0.14179711739603754, 0.08175995550699122, 0.07419028971121668, 0.06759071482031892, 0.07683643187841964, 0.05094341832426997, 0.06531656350114863, 0.038644014220631566, 0.04104293801872939, 0.0327793601973226, 0.03649604130570586, 0.030814064310208694, 0.026302375825867346, 0.015432925289915375]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 280 	 Test accuracy: 79.67999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 281 	 Test accuracy: 83.39999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 383
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 282 	 Test accuracy: 79.69000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 283 	 Test accuracy: 83.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 284 	 Test accuracy: 84.56 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 285 	 Test accuracy: 80.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 286 	 Test accuracy: 82.41000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 287 	 Test accuracy: 80.99 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 288 	 Test accuracy: 84.06 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 289 	 Test accuracy: 80.85 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:21<00:42, 21.23s/it] 67%|██████▋   | 2/3 [00:45<00:22, 22.82s/it]100%|██████████| 3/3 [01:04<00:00, 21.13s/it]100%|██████████| 3/3 [01:04<00:00, 21.44s/it]


scaleA
 [0.014961446955756902, 0.005228381239004744, 0.009119740843614627, 0.010668852915398722, 0.005523397158557527, 0.006737426736841054, 0.006529260218625752, 0.010942335089328334, 0.001993297415811213, 0.004108221552451704, 0.007912121912993087, 0.00760919631759444, 0.007385263754098508, 0.010892131049744189, 0.0108454819462361, 0.012338014234482346, 0.010753297564774325, 0.012105664964239872]
scaleW
 [0.10682648473308642, 0.0906387835819258, 0.14462061795171702, 0.10255236311573934, 0.11862586774305754, 0.06353939097342427, 0.05976313316995266, 0.05331589030349398, 0.023585620221335566, 0.017745831392884444, 0.055275119963878884, 0.018205204399675882, 0.027387151021992226, 0.015153855636091127, 0.025184370622703612, 0.01795925381816937, 0.021285414175197234, 0.01073704328667754]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 290 	 Test accuracy: 79.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 291 	 Test accuracy: 82.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 292 	 Test accuracy: 84.31 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 293 	 Test accuracy: 82.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 294 	 Test accuracy: 83.23 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 295 	 Test accuracy: 84.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 296 	 Test accuracy: 81.05 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 297 	 Test accuracy: 83.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 298 	 Test accuracy: 85.11999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 299 	 Test accuracy: 84.55 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:21<00:42, 21.34s/it] 67%|██████▋   | 2/3 [00:42<00:21, 21.16s/it]100%|██████████| 3/3 [01:02<00:00, 20.58s/it]100%|██████████| 3/3 [01:02<00:00, 20.77s/it]


scaleA
 [0.016519303319659052, 0.006411189636570297, 0.007951463307607622, 0.010675198713655501, 0.006862114821979687, 0.008852041804138183, 0.0061113955783570996, 0.012349358574890333, 0.011150114361878967, 0.010668051163121082, 0.008053882306797584, 0.009300560365872826, 0.00857615857821597, 0.01714343039277658, 0.011881770489503346, 0.015422564878527273, 0.01090307499733176, 0.013124880041266468]
scaleW
 [0.1308227451052221, 0.10398424303426139, 0.14188279561257325, 0.07923154119408514, 0.12317864549762951, 0.08016631533590703, 0.06684139325036226, 0.056107726791993405, 0.06888451060966255, 0.03625667786670425, 0.05748781964559163, 0.025361408501956683, 0.032602081827841384, 0.027881706335752127, 0.027548089991808297, 0.02308812738238404, 0.02567482045575196, 0.013284413609036066]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 300 	 Test accuracy: 84.00999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 383
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 301 	 Test accuracy: 81.78 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 302 	 Test accuracy: 85.11999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 303 	 Test accuracy: 83.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 304 	 Test accuracy: 84.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 305 	 Test accuracy: 84.57000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 306 	 Test accuracy: 83.72 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 307 	 Test accuracy: 84.78999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 308 	 Test accuracy: 85.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 309 	 Test accuracy: 85.68 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:16<00:32, 16.42s/it] 67%|██████▋   | 2/3 [00:33<00:16, 16.78s/it]100%|██████████| 3/3 [00:51<00:00, 17.57s/it]100%|██████████| 3/3 [00:51<00:00, 17.33s/it]


scaleA
 [0.02233268384071792, 0.009341167738345063, 0.011256799445085112, 0.013449305986786925, 0.010908956271863855, 0.01002099430072709, 0.008186904599843515, 0.012313255769894496, 0.01091340118517232, 0.010509526561816107, 0.007938961507182166, 0.013146705459168476, 0.010449209410074637, 0.022077256401158263, 0.009420155059883683, 0.013140476438316473, 0.008543345293877704, 0.007660619175403258]
scaleW
 [0.19250368415950717, 0.14825721992944185, 0.2133019666276952, 0.1277263971550852, 0.16458526031886875, 0.1012916486099627, 0.08530728268464265, 0.06753251543433812, 0.059419316464460165, 0.04136646313944057, 0.0630715041059212, 0.03340903478108475, 0.0374987164856171, 0.0336256288294206, 0.02447710233064628, 0.017029665657811412, 0.021048447759203514, 0.004221933759664909]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 310 	 Test accuracy: 84.69 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 311 	 Test accuracy: 84.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 312 	 Test accuracy: 85.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 313 	 Test accuracy: 84.98 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 314 	 Test accuracy: 84.81 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 315 	 Test accuracy: 85.22999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 316 	 Test accuracy: 83.43 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 317 	 Test accuracy: 85.46000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 318 	 Test accuracy: 84.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 319 	 Test accuracy: 84.97 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:37, 18.93s/it] 67%|██████▋   | 2/3 [00:39<00:20, 20.17s/it]100%|██████████| 3/3 [00:59<00:00, 19.79s/it]100%|██████████| 3/3 [00:59<00:00, 19.79s/it]


scaleA
 [0.011351316631807287, 0.004641686698273664, 0.009066497778008609, 0.009977756734486367, 0.006212152191668677, 0.006218191248452955, 0.005123615225538068, 0.008700013434090666, 0.0073963519193729925, 0.007471742483852119, 0.006029530700176258, 0.008474618452279212, 0.007994433669901036, 0.018272195104064772, 0.0052965329261089366, 0.009846366711334107, 0.009465481359787066, 0.010876662645232932]
scaleW
 [0.09387310012294751, 0.07974591595208042, 0.18154634690889715, 0.09130060631289481, 0.09308200766049607, 0.0646201479455224, 0.05238450487113646, 0.061803090341961874, 0.046971539412450365, 0.03136697314154937, 0.04970282089592501, 0.029341433536391376, 0.035821173176712996, 0.032157745239363655, 0.014479880198429948, 0.015163628547951202, 0.021801404153916095, 0.012718435083864589]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 320 	 Test accuracy: 86.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 321 	 Test accuracy: 85.83 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 322 	 Test accuracy: 86.28 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 323 	 Test accuracy: 85.0 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 324 	 Test accuracy: 86.02 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 325 	 Test accuracy: 85.57000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 326 	 Test accuracy: 85.6 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 327 	 Test accuracy: 85.86 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 328 	 Test accuracy: 86.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 329 	 Test accuracy: 85.96000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:23<00:46, 23.02s/it] 67%|██████▋   | 2/3 [00:42<00:20, 20.83s/it]100%|██████████| 3/3 [01:00<00:00, 19.65s/it]100%|██████████| 3/3 [01:00<00:00, 20.20s/it]


scaleA
 [0.016219667521967407, 0.006242688536263613, 0.010391519028456251, 0.009336685888750395, 0.006543440911718916, 0.007474884650293793, 0.005393492169140358, 0.009586058850447035, 0.008739508217325177, 0.00600546812763194, 0.0019062528838225505, 0.00506840259754687, 0.007470527922710152, 0.013582259986618469, 0.009501649956978124, 0.014281875610493237, 0.007103530181386282, 0.008137813015444788]
scaleW
 [0.10780470463237683, 0.089261461074211, 0.15262765900924982, 0.09327778852779905, 0.0915493090747152, 0.07328910962296985, 0.05160675270806673, 0.04935603138773775, 0.04304207351892365, 0.028780956925473698, 0.02869349620916283, 0.01603770593189073, 0.028274405249756034, 0.022336745628973104, 0.02307641898203037, 0.016566809235836585, 0.016878150412362264, 0.006087787742436836]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 330 	 Test accuracy: 86.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 331 	 Test accuracy: 86.25 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 332 	 Test accuracy: 86.5 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 333 	 Test accuracy: 86.27 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 334 	 Test accuracy: 86.41 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 335 	 Test accuracy: 86.44 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 336 	 Test accuracy: 85.98 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 337 	 Test accuracy: 85.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 338 	 Test accuracy: 86.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 339 	 Test accuracy: 86.42 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:19<00:38, 19.42s/it] 67%|██████▋   | 2/3 [00:38<00:19, 19.46s/it]100%|██████████| 3/3 [00:56<00:00, 18.70s/it]100%|██████████| 3/3 [00:56<00:00, 18.91s/it]


scaleA
 [0.01755150082080994, 0.007302250522472732, 0.012142359825420218, 0.013408260111570211, 0.010978089542191953, 0.009783897647434316, 0.008609401897692569, 0.013920773926451899, 0.012929681105806957, 0.01342402014429146, 0.010305071198901098, 0.012665733190647538, 0.009880654075783424, 0.0201649183658177, 0.012749106814987055, 0.016756999030419707, 0.015796085516810828, 0.015588526166385902]
scaleW
 [0.10939036246538349, 0.11179668499044638, 0.19596486652638903, 0.11965171137626607, 0.15521350558025923, 0.08615969275256759, 0.08397815715235242, 0.07028773779506409, 0.07372246877448745, 0.04673387708900256, 0.06712479831851113, 0.04311156523505092, 0.04064816997064075, 0.03367908914393929, 0.02839739050690591, 0.023164880219266343, 0.03386254968697114, 0.01394972120971136]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 340 	 Test accuracy: 85.97 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 341 	 Test accuracy: 86.32 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 342 	 Test accuracy: 86.67 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 343 	 Test accuracy: 86.99 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 344 	 Test accuracy: 86.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 345 	 Test accuracy: 86.66 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 346 	 Test accuracy: 85.94000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 347 	 Test accuracy: 85.96000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 348 	 Test accuracy: 86.92999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 349 	 Test accuracy: 86.85000000000001 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:17<00:34, 17.00s/it] 67%|██████▋   | 2/3 [00:30<00:14, 14.94s/it]100%|██████████| 3/3 [00:46<00:00, 15.38s/it]100%|██████████| 3/3 [00:46<00:00, 15.48s/it]


scaleA
 [0.02318503440790964, 0.008733103576709238, 0.011351723548504613, 0.013019120209720639, 0.01067778589556305, 0.009545757313846623, 0.00768616554000756, 0.012213850899066984, 0.010672362713816504, 0.011788364859724806, 0.00924868577502805, 0.012956856227919497, 0.01130088337231711, 0.02281578599523279, 0.012324407442303833, 0.015938218700458827, 0.014038850162652737, 0.0140900334114517]
scaleW
 [0.18001969576003163, 0.1683599341891867, 0.21156977509248157, 0.12886829094506222, 0.16434714563517686, 0.11045206578467, 0.09118331524894674, 0.0686382291246837, 0.07302236065079247, 0.04378936547162454, 0.07972936994199896, 0.045803866273391856, 0.04936326328554328, 0.03786197744809453, 0.031590045995655854, 0.026765942779757412, 0.032319115145077404, 0.013436257377469627]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 350 	 Test accuracy: 86.64 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 351 	 Test accuracy: 86.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 352 	 Test accuracy: 86.46000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 353 	 Test accuracy: 86.66 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 354 	 Test accuracy: 86.83999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 355 	 Test accuracy: 86.52 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 356 	 Test accuracy: 87.16000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 357 	 Test accuracy: 87.08 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 358 	 Test accuracy: 87.09 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 359 	 Test accuracy: 87.06 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:15<00:30, 15.07s/it] 67%|██████▋   | 2/3 [00:32<00:16, 16.25s/it]100%|██████████| 3/3 [00:48<00:00, 16.42s/it]100%|██████████| 3/3 [00:48<00:00, 16.27s/it]


scaleA
 [0.024707508720085394, 0.007607617458027866, 0.011571657441401033, 0.01443031169817337, 0.008883622008735425, 0.008383061274644825, 0.00616671358672093, 0.009553693062592777, 0.01139151884042366, 0.013575454332177378, 0.012400030878743246, 0.014634903679038948, 0.012759525864995494, 0.026474507674682766, 0.012738096003484354, 0.018586167551334645, 0.011405969755674964, 0.011846910684878115]
scaleW
 [0.12746222801824372, 0.12798924606830264, 0.19275091392177926, 0.14139714562449138, 0.17482423482999246, 0.09387410035258216, 0.07205987396688364, 0.05272974168337957, 0.0820324513375989, 0.05224436846686201, 0.08478080911627593, 0.04553546896109962, 0.04013768455512881, 0.04408898333309907, 0.033967111564919786, 0.027052793011509674, 0.0270647569964196, 0.010838708240136746]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 360 	 Test accuracy: 86.92 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 361 	 Test accuracy: 86.9 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 362 	 Test accuracy: 87.22 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 363 	 Test accuracy: 86.95 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 364 	 Test accuracy: 87.17 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 365 	 Test accuracy: 87.2 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 366 	 Test accuracy: 87.46000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 367 	 Test accuracy: 87.27000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 368 	 Test accuracy: 87.33 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 369 	 Test accuracy: 87.37 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:23<00:47, 23.94s/it] 67%|██████▋   | 2/3 [00:43<00:21, 21.48s/it]100%|██████████| 3/3 [01:06<00:00, 22.03s/it]100%|██████████| 3/3 [01:06<00:00, 22.14s/it]


scaleA
 [0.01657737062802286, 0.007151132112931539, 0.010462088051009948, 0.009886181003781452, 0.004450601576653161, 0.0065717159138823185, 0.007691527004630637, 0.013444214365141973, 0.010483751978841804, 0.0067576492235794094, 0.0064560561222579875, 0.008893900379684279, 0.012432008767549794, 0.028240447670287164, 0.0193752375477949, 0.027535609585086288, 0.012495229931964674, 0.015532207709033736]
scaleW
 [0.16818585725012705, 0.16007965842208596, 0.24722362132788925, 0.09270943939195538, 0.12293813708898564, 0.059631604578949594, 0.09531512373463485, 0.0770338043977483, 0.06261556542995511, 0.031157016297157242, 0.06340100510215545, 0.023042477349260983, 0.05124685780792537, 0.05080592893559524, 0.05130686077230279, 0.041015697924377585, 0.03325719067839706, 0.017740353121656904]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 370 	 Test accuracy: 87.24 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 371 	 Test accuracy: 87.45 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 372 	 Test accuracy: 87.58 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 373 	 Test accuracy: 87.33999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 374 	 Test accuracy: 87.42 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 383
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 383
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 375 	 Test accuracy: 87.66000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 376 	 Test accuracy: 87.55 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 377 	 Test accuracy: 87.46000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 378 	 Test accuracy: 87.36 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 379 	 Test accuracy: 87.55 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:18<00:36, 18.39s/it] 67%|██████▋   | 2/3 [00:37<00:19, 19.08s/it]100%|██████████| 3/3 [00:56<00:00, 18.78s/it]100%|██████████| 3/3 [00:56<00:00, 18.81s/it]


scaleA
 [0.014582034953237052, 0.0055079919174270894, 0.00450996764683095, 0.005861075107551741, 0.0029700876338325396, 0.005456539578090189, 0.0031472279312992468, 0.006059150511689298, 0.002884793495225229, 0.003153506915059953, 0.005151670470049339, 0.004797008323816426, 0.006816484673405267, 0.012119003428810678, 0.011329266711490824, 0.012785947211226596, 0.0076012674235319926, 0.011207388736669016]
scaleW
 [0.1117928333652397, 0.0813516852136985, 0.1328516365258902, 0.04598593354679334, 0.04715448961385416, 0.06050803714229739, 0.029544468733144886, 0.03699267328330791, 0.028018419401603364, 0.01756665392985714, 0.03729907711354625, 0.009575690326268397, 0.023453512724967512, 0.02060774998424762, 0.026488481155216143, 0.021085987644650774, 0.016902312079800946, 0.009341381864242495]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 380 	 Test accuracy: 87.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 381 	 Test accuracy: 87.18 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 382 	 Test accuracy: 87.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 383 	 Test accuracy: 87.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 384 	 Test accuracy: 87.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 385 	 Test accuracy: 87.69 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 386 	 Test accuracy: 87.46000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 387 	 Test accuracy: 87.35000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 388 	 Test accuracy: 87.51 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 389 	 Test accuracy: 87.37 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:24<00:48, 24.05s/it] 67%|██████▋   | 2/3 [00:43<00:21, 21.59s/it]100%|██████████| 3/3 [01:05<00:00, 21.41s/it]100%|██████████| 3/3 [01:05<00:00, 21.72s/it]


scaleA
 [0.0159216319229312, 0.005786583389284286, 0.005690014504364831, 0.010500850527904367, 0.010645709486369453, 0.0074317988583636335, 0.006205855645510444, 0.009926547316475963, 0.011438987267780731, 0.010463799804599558, 0.0022452707459335113, 0.005142197760351673, 0.008623139684921741, 0.017177169553911572, 0.0, 0.0014504966876411334, 0.006372891111329553, 0.01033551805992705]
scaleW
 [0.13119039336608684, 0.08692030142895742, 0.151433718036271, 0.11437014107088217, 0.1619490446226534, 0.08050199410153765, 0.07020330683263287, 0.05728978907183225, 0.06447971031789747, 0.04398901561382823, 0.04517152825562421, 0.010092939036118612, 0.03465342877682998, 0.034292475925707985, 0.004853141586095394, 0.010685099232334792, 0.016922534603531145, 0.009283911689429691]

layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 390 	 Test accuracy: 87.48 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 391 	 Test accuracy: 87.47 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 392 	 Test accuracy: 87.68 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 393 	 Test accuracy: 87.63 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 394 	 Test accuracy: 87.49 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 395 	 Test accuracy: 87.59 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 383
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 396 	 Test accuracy: 87.42999999999999 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 397 	 Test accuracy: 87.66000000000001 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 398 	 Test accuracy: 87.38 %
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.0.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.1.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv1.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer1.2.conv2.weight
torch.Size([12, 192]) (192, 12) 384
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv1.weight
torch.Size([12, 384]) (384, 12) 384
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.0.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.1.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv1.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer2.2.conv2.weight
torch.Size([12, 768]) (768, 12) 384
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv1.weight
torch.Size([12, 1536]) (1536, 12) 384
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.0.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.1.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv1.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
weighted k-means: True
product quantization with block_size:  12 layer3.2.conv2.weight
torch.Size([12, 3072]) (3072, 12) 384
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.49184263169593245
Current epoch: 399 	 Test accuracy: 87.61 %
The best checkpoint is loaded
Test accuracy: 87.69%
