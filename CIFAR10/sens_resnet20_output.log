dataset: cifar10	arch: resnet20_quant	num_workers: 4	seed: None	batch_size: 256	epochs: 400	optimizer_m: Adam	optimizer_q: Adam	lr_m: 0.004	lr_q: 4e-05	lr_m_end: 0.0	lr_q_end: 0.0	decay_schedule_m: 150-300	decay_schedule_q: 150-300	momentum: 0.9	weight_decay: 0.0001	lr_scheduler_m: cosine	lr_scheduler_q: cosine	gamma: 0.1	QWeightFlag: True	QActFlag: True	weight_levels: 256	act_levels: 256	baseline: False	bkwd_scaling_factorW: 0.0	bkwd_scaling_factorA: 0.0	use_hessian: True	update_every: 10	gpu_id: 0	log_dir: test_4_partition_equal_5_bits/	load_pretrain: True	pretrain_path: ../results/ResNet20_CIFAR10/fp/checkpoint/best_checkpoint.pth	btq: True	training_flag: False	eval: False	weighted: False	bits: 5	cv_block_size: 6	pw_fc_block_size: 4	sensitivity: True	
Files already downloaded and verified
The number of parameters :  269940
Pretrained full precision weights are initialized
# total params: 269940
# model params: 269850
# quantizer params: 90
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): QBasicBlock(
      (conv1): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): QBasicBlock(
      (conv1): QConv(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): QBasicBlock(
      (conv1): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): QBasicBlock(
      (conv1): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): QConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 000 	 Test accuracy: 14.44 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 001 	 Test accuracy: 15.07 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 002 	 Test accuracy: 12.5 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 003 	 Test accuracy: 13.15 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 004 	 Test accuracy: 16.009999999999998 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 005 	 Test accuracy: 15.42 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 006 	 Test accuracy: 14.280000000000001 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 007 	 Test accuracy: 13.16 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 008 	 Test accuracy: 18.55 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 009 	 Test accuracy: 16.72 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [01:15<02:31, 75.94s/it] 67%|██████▋   | 2/3 [02:23<01:10, 70.92s/it]100%|██████████| 3/3 [03:23<00:00, 65.80s/it]100%|██████████| 3/3 [03:23<00:00, 67.69s/it]


scaleA
 [0.011179213415555186, 0.008021495286641967, 0.006073678605588645, 0.00901444628125069, 0.004974680979936555, 0.006470435537228425, 0.004672641395563874, 0.010791505036803728, 0.008060883713138694, 0.010145372343878474, 0.006629256977999599, 0.00952702856880686, 0.008479633762471636, 0.01816143243359598, 0.008850005613972482, 0.009603121464684214, 0.005031928797559864, 0.003706819377884477]
scaleW
 [0.3784392031753665, 0.354447693613122, 0.5149081050290593, 0.21713821769919903, 0.311115225891488, 0.15632095961738107, 0.1860534814173941, 0.14125836716288484, 0.1298104536304466, 0.09380755868979103, 0.13644394436251864, 0.0733130396668269, 0.08333983762567858, 0.06803719119256034, 0.05255653617503731, 0.039598242509083746, 0.0312195490425696, 0.01042551489229985]

conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 010 	 Test accuracy: 19.2 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 011 	 Test accuracy: 16.66 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 012 	 Test accuracy: 10.459999999999999 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 013 	 Test accuracy: 14.580000000000002 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 014 	 Test accuracy: 13.320000000000002 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 015 	 Test accuracy: 13.13 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 016 	 Test accuracy: 11.09 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 017 	 Test accuracy: 10.7 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 018 	 Test accuracy: 15.0 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 019 	 Test accuracy: 10.94 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [01:13<02:27, 73.72s/it] 67%|██████▋   | 2/3 [02:27<01:13, 73.81s/it]100%|██████████| 3/3 [03:49<00:00, 77.65s/it]100%|██████████| 3/3 [03:49<00:00, 76.62s/it]


scaleA
 [0.011287300867896281, 0.008288454239700928, 0.0052703664406600495, 0.009423693667923875, 0.004438968907698017, 0.005912355522322767, 0.005064176229725342, 0.010475592208219586, 0.007771730269222613, 0.008654125897774029, 0.006593290267855736, 0.008568054783372957, 0.0077330007111901635, 0.016055619017778012, 0.007574172424913118, 0.009428589921040648, 0.00672118856863328, 0.005371558175090306]
scaleW
 [0.3155401389613434, 0.3127002366776797, 0.36369592688109287, 0.2134210613540163, 0.27711135164383277, 0.12756608046863352, 0.1548044083819556, 0.11973040604241802, 0.11273339502245495, 0.07020395592337855, 0.1085948157427196, 0.05490148322718241, 0.07121704176054577, 0.05009332495396849, 0.0390077442364918, 0.03290922043558944, 0.03559610905018202, 0.013443331443531263]

conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 020 	 Test accuracy: 16.08 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 021 	 Test accuracy: 15.07 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 022 	 Test accuracy: 14.64 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 023 	 Test accuracy: 13.530000000000001 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 024 	 Test accuracy: 19.53 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 025 	 Test accuracy: 20.21 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 026 	 Test accuracy: 11.42 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 027 	 Test accuracy: 13.87 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 028 	 Test accuracy: 14.99 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 029 	 Test accuracy: 11.35 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [01:19<02:38, 79.27s/it] 67%|██████▋   | 2/3 [02:36<01:18, 78.11s/it]100%|██████████| 3/3 [03:44<00:00, 73.54s/it]100%|██████████| 3/3 [03:44<00:00, 74.90s/it]


scaleA
 [0.0108316778673688, 0.008564251993928544, 0.006497943121490654, 0.010681649306341153, 0.0046528173274025635, 0.006683667365069412, 0.005411273948478974, 0.01104734253393822, 0.007497033015090073, 0.010855914316788742, 0.007196060663497552, 0.011056192004089702, 0.008811531820717934, 0.018763785796847395, 0.008972341454393568, 0.012199433202868879, 0.007759318276252903, 0.008322364324712353]
scaleW
 [0.3212005520512164, 0.3185422973361806, 0.3692979685225651, 0.20854578653395542, 0.2710052773089919, 0.14659866314509787, 0.16728579746890473, 0.12327095156819867, 0.12243858980383389, 0.07542712240767341, 0.11791910434964825, 0.05861149879116349, 0.07278890267954506, 0.0548572546981852, 0.04452322382416208, 0.03907474703473923, 0.034725404357628636, 0.019370975925280032]

conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 030 	 Test accuracy: 17.77 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 031 	 Test accuracy: 20.04 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 032 	 Test accuracy: 12.94 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 033 	 Test accuracy: 15.040000000000001 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 034 	 Test accuracy: 20.330000000000002 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 035 	 Test accuracy: 23.400000000000002 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 036 	 Test accuracy: 14.45 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 037 	 Test accuracy: 15.120000000000001 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 038 	 Test accuracy: 12.08 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 039 	 Test accuracy: 18.18 %
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [01:18<02:37, 78.78s/it] 67%|██████▋   | 2/3 [02:02<00:58, 58.15s/it]100%|██████████| 3/3 [03:15<00:00, 64.77s/it]100%|██████████| 3/3 [03:15<00:00, 65.06s/it]


scaleA
 [0.013396378480218534, 0.009866942800836833, 0.006460130302645942, 0.010534015355159918, 0.005386311699849752, 0.006673642190693584, 0.005395521210494088, 0.01140679224648256, 0.008586000895127384, 0.01051242262693687, 0.00870758041556386, 0.011918307627136082, 0.008722871220299029, 0.02075007737466486, 0.008931115523671136, 0.012071613636849143, 0.006831481830329316, 0.008726591193182894]
scaleW
 [0.3484913484930958, 0.32046356594676206, 0.3674793493789117, 0.207798055813484, 0.3238481548533478, 0.13068459571712976, 0.16006666024114433, 0.12342979678939425, 0.11377789613826828, 0.07099554060599637, 0.12864086553899545, 0.07361049612735877, 0.07457415886892992, 0.06546273094278073, 0.045398937076704136, 0.03433787795974521, 0.02980403949316096, 0.021499972725655046]

conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 040 	 Test accuracy: 15.290000000000001 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 041 	 Test accuracy: 15.770000000000001 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 042 	 Test accuracy: 14.89 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 043 	 Test accuracy: 16.05 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 044 	 Test accuracy: 10.95 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 045 	 Test accuracy: 12.889999999999999 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 046 	 Test accuracy: 15.040000000000001 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 047 	 Test accuracy: 14.59 %
conv1.weight torch.Size([16, 3, 3, 3])
Quantizing weight: conv1.weight torch.Size([16, 3, 3, 3])
Skipping weights: conv1.weight
k-means on skipped weights (1, 432)
final weight shape: torch.Size([16, 3, 3, 3])
layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.0.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.0.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.1.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.1.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv1.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv1.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
Quantizing weight: layer1.2.conv2.weight torch.Size([16, 16, 3, 3])
product quantization with block_size:  6 layer1.2.conv2.weight
Partition k-means
torch.Size([6, 384]) (384, 6) 120
final weight shape: torch.Size([16, 16, 3, 3])
layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
Quantizing weight: layer2.0.conv1.weight torch.Size([32, 16, 3, 3])
product quantization with block_size:  6 layer2.0.conv1.weight
Partition k-means
torch.Size([6, 768]) (768, 6) 120
final weight shape: torch.Size([32, 16, 3, 3])
layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.0.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.0.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.1.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.1.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv1.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv1.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
Quantizing weight: layer2.2.conv2.weight torch.Size([32, 32, 3, 3])
product quantization with block_size:  6 layer2.2.conv2.weight
Partition k-means
torch.Size([6, 1536]) (1536, 6) 120
final weight shape: torch.Size([32, 32, 3, 3])
layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
Quantizing weight: layer3.0.conv1.weight torch.Size([64, 32, 3, 3])
product quantization with block_size:  6 layer3.0.conv1.weight
Partition k-means
torch.Size([6, 3072]) (3072, 6) 120
final weight shape: torch.Size([64, 32, 3, 3])
layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.0.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.0.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.1.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.1.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv1.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv1.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
Quantizing weight: layer3.2.conv2.weight torch.Size([64, 64, 3, 3])
product quantization with block_size:  6 layer3.2.conv2.weight
Partition k-means
torch.Size([6, 6144]) (6144, 6) 120
final weight shape: torch.Size([64, 64, 3, 3])
Bit ratio for compressed layers: 0.9043787508335186
Current epoch: 048 	 Test accuracy: 11.129999999999999 %
